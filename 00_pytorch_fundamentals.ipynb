{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4fc0dd78",
      "metadata": {
        "id": "4fc0dd78"
      },
      "source": [
        "# 00. PyTorch Fundamentals\n",
        "\n",
        "Resource notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "lPFlzguQxkpT",
      "metadata": {
        "id": "lPFlzguQxkpT",
        "outputId": "2de93a81-aa4e-4ee9-f8cf-4acae9f60679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.7.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ec2e70",
      "metadata": {
        "id": "14ec2e70"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "Link: https://docs.pytorch.org/docs/stable/tensors.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3453f99",
      "metadata": {
        "id": "f3453f99"
      },
      "source": [
        "### Creating tensors\n",
        "\n",
        "PyTorch tensors are created using torch.Tensor() = https://pytorch.org/docs/stable/tensors.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a656c38f",
      "metadata": {
        "id": "a656c38f",
        "outputId": "2271c607-d2e0-4a46-962d-03f15ea2f1db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9d3c0f2a",
      "metadata": {
        "id": "9d3c0f2a",
        "outputId": "1120479b-3d0d-43fe-ea41-6679256fe84a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2cab8a71",
      "metadata": {
        "id": "2cab8a71",
        "outputId": "b458001f-746c-4c78-ba94-0ff4545a74b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get tensor back as Python int\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0b533209",
      "metadata": {
        "id": "0b533209",
        "outputId": "91ea7352-e678-4e37-daa5-a67024fc6e33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4ba0f64f",
      "metadata": {
        "id": "4ba0f64f",
        "outputId": "7f0fe2da-31fc-45ef-f9d6-b1ca10e19796"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4d17002f",
      "metadata": {
        "id": "4d17002f",
        "outputId": "6e61953d-16cd-43df-b32a-050f9caf33fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e20164c2",
      "metadata": {
        "id": "e20164c2",
        "outputId": "dc60fbee-047d-47f5-e5e5-b453976b939a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix\n",
        "matrix = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ea5c2415",
      "metadata": {
        "id": "ea5c2415",
        "outputId": "19ea1129-857b-4999-cc18-171fdfe59d8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a2c06e5e",
      "metadata": {
        "id": "a2c06e5e",
        "outputId": "c5294214-93a7-4adb-e8f6-a84f0f30caa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2cf9dc21",
      "metadata": {
        "id": "2cf9dc21",
        "outputId": "aecbf236-290a-45a8-e057-8c0bab9ccd5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 8])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0551008d",
      "metadata": {
        "id": "0551008d",
        "outputId": "7fca83f4-3967-4b1e-e41e-27a42beaec77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9, 10])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "21b0f8f9",
      "metadata": {
        "id": "21b0f8f9",
        "outputId": "f01b2651-6437-4f64-b8cd-a37f18e361fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensor\n",
        "tensor = torch.tensor([[[1, 2, 3],\n",
        "                        [4, 5, 6],\n",
        "                        [7, 8, 9]]])\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c85f3790",
      "metadata": {
        "id": "c85f3790",
        "outputId": "bbe5ebcd-4c11-493d-ea89-9e2e0b62bbff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a0478769",
      "metadata": {
        "id": "a0478769",
        "outputId": "68f831a5-2ed2-4095-fcd6-2f5edcdf14d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ff639039",
      "metadata": {
        "id": "ff639039",
        "outputId": "0da9859b-9a1d-43c8-954b-6bfa702f8ea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fa03ef7e",
      "metadata": {
        "id": "fa03ef7e",
        "outputId": "ff3d2846-e2a2-4ea1-fbf2-4bd9fc16b031"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([4, 5, 6])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9688222e",
      "metadata": {
        "id": "9688222e",
        "outputId": "180459f3-e7b9-431e-c5e4-7f5ae6241039"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor[0][1][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aec46f5",
      "metadata": {
        "id": "7aec46f5"
      },
      "source": [
        "### Random tensors\n",
        "\n",
        "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers\n",
        "\n",
        "Torch random tensors - https://pytorch.org/docs/stable/generated/torch.rand.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "78ad7f59",
      "metadata": {
        "id": "78ad7f59",
        "outputId": "d50e0037-2c97-4d47-8bfd-4e0d0c9961bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2105, 0.6644, 0.2312, 0.5239],\n",
              "        [0.8002, 0.9629, 0.7550, 0.2121],\n",
              "        [0.6954, 0.2267, 0.1422, 0.2061]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor of size / shape (3, 4)\n",
        "random_tensor = torch.rand(3, 4)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "59136206",
      "metadata": {
        "id": "59136206",
        "outputId": "950e3a4b-3a5a-496e-8171-90c6c76a60e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "37f8d1c4",
      "metadata": {
        "id": "37f8d1c4",
        "outputId": "d5d19e7f-8acd-467b-f796-21bf3779ee5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.4745, 0.3935, 0.4855],\n",
              "         [0.9720, 0.9430, 0.7347],\n",
              "         [0.4860, 0.1493, 0.8200]],\n",
              "\n",
              "        [[0.1396, 0.1112, 0.8863],\n",
              "         [0.6445, 0.7300, 0.2712],\n",
              "         [0.3801, 0.2679, 0.7729]],\n",
              "\n",
              "        [[0.0839, 0.1112, 0.7340],\n",
              "         [0.6669, 0.0267, 0.9945],\n",
              "         [0.8615, 0.6843, 0.4656]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor = torch.rand(3, 3, 3)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3464bac6",
      "metadata": {
        "id": "3464bac6",
        "outputId": "774fc96b-8476-46de-f156-cffb5d0b4518"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.9869, 0.1881, 0.9063],\n",
              "         [0.5757, 0.1852, 0.6344]]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(size=(1, 2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ce7dc199",
      "metadata": {
        "id": "ce7dc199",
        "outputId": "ed7d923d-8c5e-4bf8-ecf4-b993c7b7ab34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # height, width, colour channels (R, G, B\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06297596",
      "metadata": {
        "id": "06297596"
      },
      "source": [
        "### Zeros and ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "3a3a3028",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a random tensor of size / shape (3, 4)\n",
        "random_tensor = torch.rand(3, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a0cd91a0",
      "metadata": {
        "id": "a0cd91a0",
        "outputId": "aa9a403b-745d-4c2c-92e6-b76825bacc8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "bce9348e",
      "metadata": {
        "id": "bce9348e",
        "outputId": "bebd4372-1a99-4f72-a973-d3a1918b5779"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros * random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4dd6e0fc",
      "metadata": {
        "id": "4dd6e0fc"
      },
      "outputs": [],
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "32cc9743",
      "metadata": {
        "id": "32cc9743",
        "outputId": "4e3dc9d9-b2aa-4ebe-beb7-c91f70ede350"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ones.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c94d96cf",
      "metadata": {
        "id": "c94d96cf",
        "outputId": "4dfaf11f-4736-41a1-b61e-e1bc39bab8bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5207, 0.3133, 0.1329, 0.4848],\n",
              "        [0.1975, 0.4487, 0.0189, 0.3238],\n",
              "        [0.5146, 0.5702, 0.6372, 0.5092]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ones * random_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d70153",
      "metadata": {
        "id": "46d70153"
      },
      "source": [
        "### Creating a range of tensors and tensors-like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "447e3045",
      "metadata": {
        "id": "447e3045",
        "outputId": "4bb46e3d-28d9-48c2-8c77-d1b2f20929f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hz/kv51gkp17hd22cn05cv5whww0000gn/T/ipykernel_23486/2340538228.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  torch.range(2, 8)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([2., 3., 4., 5., 6., 7., 8.])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use torch.range() and get deprecated message, use torch.arange()\n",
        "torch.range(2, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "43d2ac48",
      "metadata": {
        "id": "43d2ac48",
        "outputId": "ecb723dd-fde8-49f2-9548-1df76a076620"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.arange(0, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "69814b7f",
      "metadata": {
        "id": "69814b7f"
      },
      "outputs": [],
      "source": [
        "one_to_ten = torch.arange(1, 11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d6377683",
      "metadata": {
        "id": "d6377683",
        "outputId": "391ba3e1-498f-4d5c-8447-e4cad5926556"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  0,  99, 198, 297, 396, 495, 594, 693, 792, 891, 990])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.arange(start=0, end=1000, step=99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "25104565",
      "metadata": {
        "id": "25104565",
        "outputId": "a0f6c540-7c78-4831-8423-406d1338cfe4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating tensors like\n",
        "ten_zeres = torch.zeros_like(input=one_to_ten)\n",
        "ten_zeres"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b3d0f7",
      "metadata": {
        "id": "d8b3d0f7"
      },
      "source": [
        "### Tensor datatypes\n",
        "\n",
        "**Note**: Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
        "\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device\n",
        "\n",
        "Precision in computing - https://en.wikipedia.org/wiki/Precision_(computer_science)#:~:text=In%20computer%20science%2C%20the%20precision,used%20to%20express%20a%20value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "77313d3b",
      "metadata": {
        "id": "77313d3b",
        "outputId": "99737f52-a323-4950-efa7-2b82ccfb14c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.tensor(\n",
        "    [3.0, 6.0, 9.0],\n",
        "    dtype=None, # what datatype is the tensor (e.g. float32 or float16)\n",
        "    device=None, # What device is your tensor on\n",
        "    requires_grad=False # whether or not to track gradients with this tensors operations\n",
        ")\n",
        "\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5dfa9e2b",
      "metadata": {
        "id": "5dfa9e2b",
        "outputId": "9806c543-b572-4c5c-ef25-d26620a75874"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_16_tensor = torch.tensor(\n",
        "    [3.0 , 6.0, 9.0],\n",
        "    dtype=torch.float16,\n",
        "    device=\"mps\",\n",
        "    requires_grad=False\n",
        ")\n",
        "\n",
        "float_16_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c6a5df81",
      "metadata": {
        "id": "c6a5df81",
        "outputId": "d3813a33-3361-4caa-bbd7-c85152a81def"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float64)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_64_tensor = float_32_tensor.type(torch.float64)\n",
        "float_64_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5e19a2a1",
      "metadata": {
        "id": "5e19a2a1",
        "outputId": "1c5e21d6-077a-4419-c729-55f8375cf41d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3]), device(type='mps', index=0), torch.float16)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_16_tensor.shape, float_16_tensor.device, float_16_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "5aaee2d8",
      "metadata": {
        "id": "5aaee2d8",
        "outputId": "9367f1d0-f1d5-4529-fe97-e9214e451cdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.], dtype=torch.float64)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_64_tensor * float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "fa28bef5",
      "metadata": {
        "id": "fa28bef5",
        "outputId": "397e9c20-a80b-43e1-d2e4-634846e3d4ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.], dtype=torch.float64)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor * float_64_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e73ac400",
      "metadata": {
        "id": "e73ac400",
        "outputId": "3681e14e-cc11-4183-baf0-e649308c08bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], dtype=torch.int32)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)\n",
        "int_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "32d10e0f",
      "metadata": {
        "id": "32d10e0f",
        "outputId": "70bc29fa-c6a3-4f71-b351-fef20fbfa472"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor * int_32_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add022b5",
      "metadata": {},
      "source": [
        "### Getting information from tensors (tensor attributes)\n",
        "\n",
        "1. Tensors not right datatype - to do get datatype from a tensor, can use tensor.dtype\n",
        "2. Tensors not right shape - to get shape from a tensor, can use tensor.shape\n",
        "3. Tensors not on the right device - to get device from a tensor, can use tensor.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "357c73bf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2128, 0.3069, 0.2069, 0.1393],\n",
              "        [0.5390, 0.0108, 0.4026, 0.7381],\n",
              "        [0.7512, 0.2466, 0.2654, 0.5745]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "some_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "8d250d72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2128, 0.3069, 0.2069, 0.1393],\n",
            "        [0.5390, 0.0108, 0.4026, 0.7381],\n",
            "        [0.7512, 0.2466, 0.2654, 0.5745]])\n",
            "Datatype of tensor: torch.float32\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Device tensor is on: cpu\n"
          ]
        }
      ],
      "source": [
        "# Find out details about some tensor\n",
        "print(some_tensor)\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Device tensor is on: {some_tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c06c4e3",
      "metadata": {
        "id": "2c06c4e3"
      },
      "source": [
        "### Manipulating tensors\n",
        "\n",
        "Tensor opertions include:\n",
        "\n",
        "- Addition\n",
        "- Subtraction\n",
        "- Multiplication (element-wise)\n",
        "- Division\n",
        "- Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "1636ab5d",
      "metadata": {
        "id": "1636ab5d"
      },
      "outputs": [],
      "source": [
        "a = torch.rand(size=(3, 3))\n",
        "b = torch.rand(size=(3, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "7ba10590",
      "metadata": {
        "id": "7ba10590",
        "outputId": "f03239b5-6c68-42f2-9da4-584761003d8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8819, 0.0372, 0.8463],\n",
              "        [0.8925, 0.7164, 0.4614],\n",
              "        [0.2305, 0.9800, 0.8495]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "33c87f63",
      "metadata": {
        "id": "33c87f63",
        "outputId": "b5a505ac-4e53-470f-b988-5840c25d0c89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4872, 0.0709, 0.6761],\n",
              "        [0.7933, 0.8996, 0.7780],\n",
              "        [0.6484, 0.6954, 0.5058]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "ab278826",
      "metadata": {
        "id": "ab278826",
        "outputId": "d036ecaa-89c3-400c-9108-204dd2ef66fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[20.8819, 20.0372, 20.8463],\n",
              "         [20.8925, 20.7164, 20.4614],\n",
              "         [20.2305, 20.9800, 20.8495]]),\n",
              " tensor([[10.8819, 10.0372, 10.8463],\n",
              "         [10.8925, 10.7164, 10.4614],\n",
              "         [10.2305, 10.9800, 10.8495]]))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add 10 to tensor\n",
        "a + 20, torch.add(a, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "7dd5729d",
      "metadata": {
        "id": "7dd5729d",
        "outputId": "71a412d1-92dd-4d36-90e4-e16c136cf2c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.3691, 0.1081, 1.5224],\n",
              "        [1.6858, 1.6160, 1.2394],\n",
              "        [0.8789, 1.6754, 1.3552]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "97b3cfa1",
      "metadata": {
        "id": "97b3cfa1",
        "outputId": "0f61dadc-72e1-4954-ce9c-db98162cfb9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-9.1181, -9.9628, -9.1537],\n",
              "         [-9.1075, -9.2836, -9.5386],\n",
              "         [-9.7695, -9.0200, -9.1505]]),\n",
              " tensor([[-9.1181, -9.9628, -9.1537],\n",
              "         [-9.1075, -9.2836, -9.5386],\n",
              "         [-9.7695, -9.0200, -9.1505]]))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subtract 10 to tensor\n",
        "a - 10, torch.sub(a, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "f28404fa",
      "metadata": {
        "id": "f28404fa",
        "outputId": "f96b5974-9de2-4f4d-f2e5-75d4ff66cfd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.3947, -0.0336,  0.1702],\n",
              "        [ 0.0992, -0.1832, -0.3165],\n",
              "        [-0.4180,  0.2845,  0.3437]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a - b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "d98b7b96",
      "metadata": {
        "id": "d98b7b96",
        "outputId": "e17cfa06-0b4f-43e9-cbb1-b531fa79650c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[8.8194, 0.3724, 8.4628],\n",
              "         [8.9252, 7.1636, 4.6144],\n",
              "         [2.3046, 9.7999, 8.4946]]),\n",
              " tensor([[8.8194, 0.3724, 8.4628],\n",
              "         [8.9252, 7.1636, 4.6144],\n",
              "         [2.3046, 9.7999, 8.4946]]))"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiply tensor by 10\n",
        "a * 10, torch.mul(a, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "5b45e2d2",
      "metadata": {
        "id": "5b45e2d2",
        "outputId": "343c74c6-9668-4e13-ee97-7d485460bf5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4297, 0.0026, 0.5722],\n",
              "        [0.7080, 0.6444, 0.3590],\n",
              "        [0.1494, 0.6815, 0.4296]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a * b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "665e5f0f",
      "metadata": {
        "id": "665e5f0f",
        "outputId": "dde8c985-fa1f-40b4-a18d-80e9b6ff7cb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0882, 0.0037, 0.0846],\n",
              "         [0.0893, 0.0716, 0.0461],\n",
              "         [0.0230, 0.0980, 0.0849]]),\n",
              " tensor([[0.0882, 0.0037, 0.0846],\n",
              "         [0.0893, 0.0716, 0.0461],\n",
              "         [0.0230, 0.0980, 0.0849]]))"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Divide tensor by 10\n",
        "a / 10, torch.div(a, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "1653d99c",
      "metadata": {
        "id": "1653d99c",
        "outputId": "40b12c7a-e86e-4845-e5dc-0c9a9758442a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.8102, 0.5254, 1.2517],\n",
              "        [1.1251, 0.7963, 0.5931],\n",
              "        [0.3554, 1.4092, 1.6795]])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a / b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a76dc5",
      "metadata": {},
      "source": [
        "### Matrix multiplication\n",
        "\n",
        "Two main ways of performing multiplication in neural networks and deep learning:\n",
        "\n",
        "1. Element-wise multiplication\n",
        "2. Matrix mutliplication (dot product)\n",
        "\n",
        "More information on multiplying matrices - https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
        "\n",
        "There are two main rules that performing matrix mutliplication needs to satisfy:\n",
        "\n",
        "1. The **inner dimensions** must match:\n",
        "\n",
        "- (3, 2) @ (3, 2) won't work\n",
        "- (2, 3) @ (3, 2) will work\n",
        "- (3, 2) @ (2, 3) will work\n",
        "\n",
        "2. The resulting matrix has the shape of the **outer dimensions**:\n",
        "- (2, 3) @ (3, 2) -> (2, 2)\n",
        "- (3, 2) @ (2, 3) -> (3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "fbd568cc",
      "metadata": {
        "id": "fbd568cc",
        "outputId": "1b588aaa-5ab7-41b8-9ff1-f21ac3d0dc00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1.0080, 0.6846, 1.0533],\n",
              "         [1.3023, 1.0286, 1.3941],\n",
              "         [1.4405, 1.4887, 1.3478]]),\n",
              " tensor([[1.0080, 0.6846, 1.0533],\n",
              "         [1.3023, 1.0286, 1.3941],\n",
              "         [1.4405, 1.4887, 1.3478]]))"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiply tensor by tensor\n",
        "torch.matmul(a, b), a @ b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "3f93cbcc",
      "metadata": {
        "id": "3f93cbcc",
        "outputId": "92b629cf-fcbd-407e-8d54-3163d110b0cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.7778, 0.0014, 0.7162],\n",
              "        [0.7966, 0.5132, 0.2129],\n",
              "        [0.0531, 0.9604, 0.7216]])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Raise tensor to the power of 2\n",
        "a ** 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "a4e3e5ba",
      "metadata": {
        "id": "a4e3e5ba",
        "outputId": "2c9c3603-d1e3-49a6-ceb0-c52c47af6fbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.9391, 0.1930, 0.9199],\n",
              "        [0.9447, 0.8464, 0.6793],\n",
              "        [0.4801, 0.9899, 0.9217]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Raise tensor to the power of 1 / 2\n",
        "a ** (1 / 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "6ad63876",
      "metadata": {
        "id": "6ad63876"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([1, 2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "dc8d9aa5",
      "metadata": {
        "id": "dc8d9aa5",
        "outputId": "b029f5e9-e9c0-4d6d-f324-e757462dea60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 315 μs, sys: 171 μs, total: 486 μs\n",
            "Wall time: 334 μs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += a[i] + b[i]\n",
        "value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "d5d13809",
      "metadata": {
        "id": "d5d13809",
        "outputId": "e3456cd6-5599-4277-8312-ebf2d956c170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 536 μs, sys: 644 μs, total: 1.18 ms\n",
            "Wall time: 717 μs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "85141c6b",
      "metadata": {
        "id": "85141c6b",
        "outputId": "d69b750c-e2e0-426d-9b8a-1f696608c682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 180 μs, sys: 57 μs, total: 237 μs\n",
            "Wall time: 235 μs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "a @ b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db654b09",
      "metadata": {},
      "source": [
        "One of the most common errors in deep learning: shape errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "425a416d",
      "metadata": {
        "id": "425a416d",
        "outputId": "2790efce-f0b3-4a49-c14c-3e6f26f50be1"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "torch.rand([3, 2]) @ torch.rand([3, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9142bc01",
      "metadata": {},
      "source": [
        "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "52d34f7c",
      "metadata": {
        "id": "52d34f7c",
        "outputId": "ef15bdc9-26f4-48b3-8ace-ef7c97819618"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.7308, 0.2095, 0.6549],\n",
              "        [0.3451, 0.0858, 0.5605],\n",
              "        [0.4752, 0.1304, 0.5361]])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand([3, 2]) @ torch.rand([2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "bf9f7044",
      "metadata": {
        "id": "bf9f7044",
        "outputId": "ac34496c-3ad6-432a-96d5-34ce62097493"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4945, 0.5409],\n",
              "        [0.3827, 0.7132]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand([2, 3]) @ torch.rand([3, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "20bc2ad6",
      "metadata": {
        "id": "20bc2ad6",
        "outputId": "d577150d-d880-4b77-a89b-3dd2950ee19a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8532, 0.8794, 0.9250],\n",
              "        [0.9727, 0.6706, 0.5596],\n",
              "        [0.4046, 0.8069, 0.0235],\n",
              "        [0.7902, 0.2215, 0.3293]])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.rand([4, 3])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "2832483a",
      "metadata": {
        "id": "2832483a",
        "outputId": "98a1ff68-3f77-49fc-a94e-4fb2595c3f90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8532, 0.9727, 0.4046, 0.7902],\n",
              "        [0.8794, 0.6706, 0.8069, 0.2215],\n",
              "        [0.9250, 0.5596, 0.0235, 0.3293]])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = a.T\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "01be1ab5",
      "metadata": {
        "id": "01be1ab5",
        "outputId": "0f886745-963d-416e-b632-a03f8cee6a0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 3]), torch.Size([3, 4]))"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.shape, b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "e6945ac7",
      "metadata": {
        "id": "e6945ac7",
        "outputId": "d8b596cd-aaef-4843-8509-f19191563edd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8532, 0.8794, 0.9250],\n",
              "        [0.9727, 0.6706, 0.5596],\n",
              "        [0.4046, 0.8069, 0.0235],\n",
              "        [0.7902, 0.2215, 0.3293]])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "58e9bfc2",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tensor_A' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# The matrix multiplication operation works when tensor_B is transposed\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal shapes: tensor_A = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtensor_A\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, tensor_B = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_B.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNew shapes: tensor_A = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_A.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (same shape as above), tensor_B.T = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_B.T.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMultiplying: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_A.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m @ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_B.T.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m <- inner dimensions must match\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'tensor_A' is not defined"
          ]
        }
      ],
      "source": [
        "# The matrix multiplication operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}\")\n",
        "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(a, b.T)\n",
        "print(output) \n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "d79228bb",
      "metadata": {
        "id": "d79228bb",
        "outputId": "5c7d35c8-7acb-4b56-87ae-deca334ba494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.3570, 1.9373, 1.0766, 1.1736],\n",
              "        [1.9373, 1.7090, 0.9478, 1.1014],\n",
              "        [1.0766, 0.9478, 0.8153, 0.5062],\n",
              "        [1.1736, 1.1014, 0.5062, 0.7819]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mm(a, a.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "754c64e0",
      "metadata": {
        "id": "754c64e0"
      },
      "source": [
        "### Finding the min, max, mean, sum, etc (tensor aggregation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "3f87267f",
      "metadata": {
        "id": "3f87267f",
        "outputId": "87b500dc-9a33-4d14-f3ae-2adb8d77d2fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.arange(0, 100, 10)\n",
        "tensor, tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "717c6517",
      "metadata": {
        "id": "717c6517",
        "outputId": "3d3696b8-76f5-4df8-84f4-bfb63912ef9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the min\n",
        "torch.min(tensor), tensor.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "9e7f8f6f",
      "metadata": {
        "id": "9e7f8f6f",
        "outputId": "01830c76-7c14-4c32-9ff3-ac304c8349e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(90), tensor(90))"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the max\n",
        "torch.max(tensor), tensor.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "3bb0d792",
      "metadata": {
        "id": "3bb0d792",
        "outputId": "8e56abd1-8ff6-45e2-a260-b4a7c12b2bb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(45.), tensor(45.))"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the mean - note: the torch.mean() function requires a tensor of float32 datatype to work\n",
        "torch.mean(tensor.type(torch.float32)), tensor.type(torch.float32).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "fbcab4d0",
      "metadata": {
        "id": "fbcab4d0",
        "outputId": "8663da33-4efb-48b4-979b-34709371c20c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(450), tensor(450))"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the sum\n",
        "torch.sum(tensor), tensor.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9de58966",
      "metadata": {
        "id": "9de58966"
      },
      "source": [
        "### Finding the positional min and max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "d23e2613",
      "metadata": {
        "id": "d23e2613",
        "outputId": "2c29e412-7908-41ff-8074-5f65cd2b4426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "529ff8fd",
      "metadata": {
        "id": "529ff8fd",
        "outputId": "36bf3360-56ec-485b-b178-0b47d832cccb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(9), tensor(9))"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the position in tensor that has the minimum value with argmin() -> returns index position of targt tensor where the minimum value occurs \n",
        "torch.argmax(tensor), tensor.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "34f4e5f6",
      "metadata": {
        "id": "34f4e5f6",
        "outputId": "94295fde-d508-41ca-fc11-9cf2c5034ac5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(90)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the position in tensor that has the maximum value with argmax()\n",
        "tensor[tensor.argmax()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "ac164153",
      "metadata": {
        "id": "ac164153",
        "outputId": "436683d5-c4d1-4070-bfc5-38debaa2f5aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.argmin(tensor), tensor.argmin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "1b8c6536",
      "metadata": {
        "id": "1b8c6536",
        "outputId": "6bd3b0c1-1c93-42b6-a656-4b8d8ffbcd4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor[torch.argmin(tensor)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a497aae",
      "metadata": {
        "id": "6a497aae"
      },
      "source": [
        "### Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "- Reshaping - reshapes an input tensor to a defined shape\n",
        "- View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "- Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
        "- Squeeze - removes all `1` dimensions from a tensor\n",
        "- Unsqueeze - add a `1` dimension to a target tensor\n",
        "- Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "22b4c43f",
      "metadata": {
        "id": "22b4c43f",
        "outputId": "9c754006-b465-4091-adb4-050b1ae76d45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4868, 0.6040, 0.5651, 0.1861, 0.6963],\n",
              "        [0.5483, 0.6567, 0.0601, 0.7948, 0.7239],\n",
              "        [0.4406, 0.1099, 0.5892, 0.4038, 0.6269]])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's create a tensor\n",
        "a = torch.rand(size=[3, 5])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "b7478088",
      "metadata": {
        "id": "b7478088",
        "outputId": "4d619952-6dc3-4bff-b379-f6b1f2a6ef5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "07d8480d",
      "metadata": {
        "id": "07d8480d",
        "outputId": "fef9f166-e49f-4649-b5e9-28d75a9364dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.4868, 0.6040, 0.5651, 0.1861, 0.6963, 0.5483, 0.6567, 0.0601, 0.7948,\n",
              "          0.7239, 0.4406, 0.1099, 0.5892, 0.4038, 0.6269]]),\n",
              " torch.Size([1, 15]))"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add an extra dimension\n",
        "a_reshaped = a.reshape(1, 15)\n",
        "a_reshaped, a_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "4a3e04d5",
      "metadata": {
        "id": "4a3e04d5",
        "outputId": "159a0db6-bbea-4a79-e247-912eee6e678c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.4868, 0.6040, 0.5651],\n",
              "         [0.1861, 0.6963, 0.5483],\n",
              "         [0.6567, 0.0601, 0.7948],\n",
              "         [0.7239, 0.4406, 0.1099],\n",
              "         [0.5892, 0.4038, 0.6269]]),\n",
              " torch.Size([5, 3]))"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_reshaped = a.reshape(5, 3)\n",
        "a_reshaped, a_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "6ec1d9b3",
      "metadata": {
        "id": "6ec1d9b3",
        "outputId": "d8a08d7e-522b-4944-e4c3-7f15e82a92bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.4868],\n",
              "         [0.6040],\n",
              "         [0.5651],\n",
              "         [0.1861],\n",
              "         [0.6963],\n",
              "         [0.5483],\n",
              "         [0.6567],\n",
              "         [0.0601],\n",
              "         [0.7948],\n",
              "         [0.7239],\n",
              "         [0.4406],\n",
              "         [0.1099],\n",
              "         [0.5892],\n",
              "         [0.4038],\n",
              "         [0.6269]]),\n",
              " torch.Size([15, 1]))"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_reshaped = a.reshape(15, 1)\n",
        "a_reshaped, a_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "87b094e6",
      "metadata": {
        "id": "87b094e6",
        "outputId": "d290ce32-3db1-4a4c-8e74-311cc9aa31d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.4868, 0.6040, 0.5651, 0.1861, 0.6963],\n",
              "         [0.5483, 0.6567, 0.0601, 0.7948, 0.7239],\n",
              "         [0.4406, 0.1099, 0.5892, 0.4038, 0.6269]]),\n",
              " torch.Size([3, 5]))"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the view \n",
        "b = a.view(3, 5) # chaning b changes a - a view of a tensor shares the same memory as the original input\n",
        "b, b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "2c3aee9e",
      "metadata": {
        "id": "2c3aee9e",
        "outputId": "25bb1d4d-a894-44ad-f667-8b3186fa339a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[19.0000,  0.6040,  0.5651,  0.1861,  0.6963],\n",
              "         [ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239],\n",
              "         [ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269]]),\n",
              " tensor([[19.0000,  0.6040,  0.5651,  0.1861,  0.6963],\n",
              "         [ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239],\n",
              "         [ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269]]))"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b[0][0] = 19\n",
        "a, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "27e6deb9",
      "metadata": {
        "id": "27e6deb9",
        "outputId": "1ed912fc-dd99-45b9-9856-9c51bf523624"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[19.0000,  0.6040,  0.5651,  0.1861,  0.6963],\n",
              "         [ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239],\n",
              "         [ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269]],\n",
              "\n",
              "        [[19.0000,  0.6040,  0.5651,  0.1861,  0.6963],\n",
              "         [ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239],\n",
              "         [ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269]],\n",
              "\n",
              "        [[19.0000,  0.6040,  0.5651,  0.1861,  0.6963],\n",
              "         [ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239],\n",
              "         [ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269]],\n",
              "\n",
              "        [[19.0000,  0.6040,  0.5651,  0.1861,  0.6963],\n",
              "         [ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239],\n",
              "         [ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269]]])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_stacked = torch.stack([a, a, a, a], dim=0)\n",
        "a_stacked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "b8d37bc5",
      "metadata": {
        "id": "b8d37bc5",
        "outputId": "76f7569a-ea1c-4891-ca0f-e9044047e122"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[19.0000,  0.6040,  0.5651,  0.1861,  0.6963],\n",
              "         [19.0000,  0.6040,  0.5651,  0.1861,  0.6963],\n",
              "         [19.0000,  0.6040,  0.5651,  0.1861,  0.6963],\n",
              "         [19.0000,  0.6040,  0.5651,  0.1861,  0.6963]],\n",
              "\n",
              "        [[ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239],\n",
              "         [ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239],\n",
              "         [ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239],\n",
              "         [ 0.5483,  0.6567,  0.0601,  0.7948,  0.7239]],\n",
              "\n",
              "        [[ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269],\n",
              "         [ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269],\n",
              "         [ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269],\n",
              "         [ 0.4406,  0.1099,  0.5892,  0.4038,  0.6269]]])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_stacked = torch.stack([a, a, a, a], dim=1)\n",
        "a_stacked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "029a8e66",
      "metadata": {
        "id": "029a8e66",
        "outputId": "76a39f65-3ea4-4fcb-ec94-53f2584d1da7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.5826, 0.5229, 0.3885]]]), torch.Size([1, 1, 3]))"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = torch.rand(size=[1, 1, 3])\n",
        "b, b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "d75d4128",
      "metadata": {
        "id": "d75d4128",
        "outputId": "4f6b1efa-50ec-4cf9-8075-dcdf49a393e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0.5826, 0.5229, 0.3885]), torch.Size([3]))"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.squeeze() - removes all single dimensions from a target tensor\n",
        "c = b.squeeze()\n",
        "c, c.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "7a6afd42",
      "metadata": {
        "id": "7a6afd42",
        "outputId": "e789eb8e-d82c-4504-f74c-67cea8905259"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.5826, 0.5229, 0.3885]]]), torch.Size([1, 1, 3]))"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove extra dimensions from x_reshaped\n",
        "d = c.unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "d, d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "4414660b",
      "metadata": {
        "id": "4414660b",
        "outputId": "7daf257d-08d2-44db-dab6-cbfeec88007c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.5826, 0.5229, 0.3885]]), torch.Size([1, 3]))"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "e = c.unsqueeze(dim=-2)\n",
        "e, e.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "ab49bc86",
      "metadata": {
        "id": "ab49bc86",
        "outputId": "ba77439e-cac0-4384-f8cd-80c553f97df0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.5826],\n",
              "         [0.5229],\n",
              "         [0.3885]]),\n",
              " torch.Size([3, 1]))"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f = c.unsqueeze(dim=1)\n",
        "f, f.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "1fd29151",
      "metadata": {
        "id": "1fd29151",
        "outputId": "e7af36dd-8570-4c17-e6af-9d8ee1766a60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.9390, 0.9157, 0.4817],\n",
              "          [0.0299, 0.6037, 0.6709],\n",
              "          [0.2481, 0.1196, 0.3228],\n",
              "          ...,\n",
              "          [0.6905, 0.8884, 0.6654],\n",
              "          [0.9930, 0.5028, 0.2070],\n",
              "          [0.9925, 0.0194, 0.9053]],\n",
              " \n",
              "         [[0.7268, 0.9876, 0.5597],\n",
              "          [0.9536, 0.7782, 0.6395],\n",
              "          [0.8140, 0.0580, 0.2135],\n",
              "          ...,\n",
              "          [0.0202, 0.8696, 0.0900],\n",
              "          [0.7159, 0.7364, 0.9489],\n",
              "          [0.4390, 0.9876, 0.7486]],\n",
              " \n",
              "         [[0.0804, 0.0737, 0.9941],\n",
              "          [0.4258, 0.7591, 0.5282],\n",
              "          [0.3839, 0.2166, 0.3339],\n",
              "          ...,\n",
              "          [0.0849, 0.2557, 0.9505],\n",
              "          [0.6723, 0.8729, 0.7789],\n",
              "          [0.4705, 0.1215, 0.3287]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.2349, 0.3573, 0.1680],\n",
              "          [0.4723, 0.6784, 0.5339],\n",
              "          [0.7690, 0.6808, 0.9523],\n",
              "          ...,\n",
              "          [0.3788, 0.0847, 0.3696],\n",
              "          [0.8557, 0.9763, 0.2997],\n",
              "          [0.0902, 0.2867, 0.7327]],\n",
              " \n",
              "         [[0.9249, 0.9200, 0.9047],\n",
              "          [0.0632, 0.1346, 0.7324],\n",
              "          [0.3376, 0.8031, 0.7725],\n",
              "          ...,\n",
              "          [0.5258, 0.9006, 0.5196],\n",
              "          [0.5352, 0.4155, 0.7259],\n",
              "          [0.4444, 0.4532, 0.0524]],\n",
              " \n",
              "         [[0.7653, 0.2055, 0.1060],\n",
              "          [0.6369, 0.8274, 0.3188],\n",
              "          [0.8002, 0.9880, 0.1108],\n",
              "          ...,\n",
              "          [0.3127, 0.1695, 0.3901],\n",
              "          [0.8467, 0.8548, 0.9299],\n",
              "          [0.7182, 0.6445, 0.8941]]]),\n",
              " torch.Size([224, 224, 3]))"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = torch.rand(size=(224, 224, 3))\n",
        "y, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "ea01d0bf",
      "metadata": {
        "id": "ea01d0bf",
        "outputId": "fedbb100-4217-48c4-c4df-1e6c7d676eac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.9390, 0.0299, 0.2481,  ..., 0.6905, 0.9930, 0.9925],\n",
              "          [0.7268, 0.9536, 0.8140,  ..., 0.0202, 0.7159, 0.4390],\n",
              "          [0.0804, 0.4258, 0.3839,  ..., 0.0849, 0.6723, 0.4705],\n",
              "          ...,\n",
              "          [0.2349, 0.4723, 0.7690,  ..., 0.3788, 0.8557, 0.0902],\n",
              "          [0.9249, 0.0632, 0.3376,  ..., 0.5258, 0.5352, 0.4444],\n",
              "          [0.7653, 0.6369, 0.8002,  ..., 0.3127, 0.8467, 0.7182]],\n",
              " \n",
              "         [[0.9157, 0.6037, 0.1196,  ..., 0.8884, 0.5028, 0.0194],\n",
              "          [0.9876, 0.7782, 0.0580,  ..., 0.8696, 0.7364, 0.9876],\n",
              "          [0.0737, 0.7591, 0.2166,  ..., 0.2557, 0.8729, 0.1215],\n",
              "          ...,\n",
              "          [0.3573, 0.6784, 0.6808,  ..., 0.0847, 0.9763, 0.2867],\n",
              "          [0.9200, 0.1346, 0.8031,  ..., 0.9006, 0.4155, 0.4532],\n",
              "          [0.2055, 0.8274, 0.9880,  ..., 0.1695, 0.8548, 0.6445]],\n",
              " \n",
              "         [[0.4817, 0.6709, 0.3228,  ..., 0.6654, 0.2070, 0.9053],\n",
              "          [0.5597, 0.6395, 0.2135,  ..., 0.0900, 0.9489, 0.7486],\n",
              "          [0.9941, 0.5282, 0.3339,  ..., 0.9505, 0.7789, 0.3287],\n",
              "          ...,\n",
              "          [0.1680, 0.5339, 0.9523,  ..., 0.3696, 0.2997, 0.7327],\n",
              "          [0.9047, 0.7324, 0.7725,  ..., 0.5196, 0.7259, 0.0524],\n",
              "          [0.1060, 0.3188, 0.1108,  ..., 0.3901, 0.9299, 0.8941]]]),\n",
              " torch.Size([3, 224, 224]))"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
        "# Permute the original tensor to rearrange the axis (or dim) order\n",
        "z = y.permute((2, 0, 1)) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "z, z.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f30ed1de",
      "metadata": {
        "id": "f30ed1de"
      },
      "source": [
        "### Indexing (selecting data from tensors)\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "f3e39aec",
      "metadata": {
        "id": "f3e39aec",
        "outputId": "69ba7d4a-18bd-4ec6-a030-70ab5e23b6cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 10, 1)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "8ba37a80",
      "metadata": {
        "id": "8ba37a80",
        "outputId": "ea3e44b6-d7ae-49e1-af66-a0a7f5661619"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = x.reshape(1, 3, 3)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "d7ecefea",
      "metadata": {
        "id": "d7ecefea",
        "outputId": "c34dbe67-f606-4b74-f9df-dbfed5d18076"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1), tensor(2), tensor(3))"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's index on our new tensor\n",
        "y[0, 0, 0], y[0, 0, 1], y[0, 0, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "c9483292",
      "metadata": {
        "id": "c9483292",
        "outputId": "c6f432ba-d55a-4e39-99ef-217f8ba37d18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's index on the middle bracket (dim=1)\n",
        "y[0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "7210f6bd",
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index 1 is out of bounds for dimension 0 with size 0",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Let's index on the most inner bracket (last dimension)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m1\u001b[39m]\n",
            "\u001b[31mIndexError\u001b[39m: index 1 is out of bounds for dimension 0 with size 0"
          ]
        }
      ],
      "source": [
        "# Let's index on the most inner bracket (last dimension)\n",
        "x[0][1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "6302208a",
      "metadata": {
        "id": "6302208a",
        "outputId": "43fcc035-c693-45dc-ef7d-8e84d9933b02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "64712d93",
      "metadata": {
        "id": "64712d93",
        "outputId": "9150be11-2890-4809-f393-226b910a3403"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([4, 5])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can also use \":\" to select \"all\" of a target dimension\n",
        "y[0, 1, :2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "40c02f3f",
      "metadata": {
        "id": "40c02f3f",
        "outputId": "5bb6ec1e-d938-47c0-8c42-eeb6da14e4f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5, 6])"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0, 1, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "2f014771",
      "metadata": {
        "id": "2f014771",
        "outputId": "d28e65e5-89f8-422d-e882-7f77e3f29901"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "111e8b35",
      "metadata": {
        "id": "111e8b35",
        "outputId": "e1d5da2d-1d11-4054-eea2-5f3234fef40f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5, 6])"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0][1][1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "75287bc7",
      "metadata": {
        "id": "75287bc7"
      },
      "outputs": [],
      "source": [
        "y[0][0][0] = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "dd4d2c5b",
      "metadata": {
        "id": "dd4d2c5b",
        "outputId": "2cdb2569-cfb0-4696-fd04-e80bae228097"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[10,  2,  3],\n",
              "          [ 4,  5,  6],\n",
              "          [ 7,  8,  9]]]),\n",
              " tensor([10,  2,  3,  4,  5,  6,  7,  8,  9]))"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "c322c8e9",
      "metadata": {
        "id": "c322c8e9",
        "outputId": "39edf86b-7cc7-46f8-e0e2-771122b589c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of 0th and 1st dimensions but only index 1 of 2nd dimension\n",
        "y[:, :, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "1cdd61de",
      "metadata": {
        "id": "1cdd61de",
        "outputId": "137a34cd-5bf7-470f-dec6-bf687b409d6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[10,  4,  7]])"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[:, :, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "d252fe37",
      "metadata": {
        "id": "d252fe37",
        "outputId": "c5984964-6ad9-4e80-8265-1f9f39d78e04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([10,  2,  3]), tensor([10,  2,  3]))"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0][0], y[0, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "398379fa",
      "metadata": {
        "id": "398379fa",
        "outputId": "b43fc7fa-5c91-48b9-afba-7d8b27357618"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Index on x to return 9\n",
        "y[0][2][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "95006b5d",
      "metadata": {
        "id": "95006b5d",
        "outputId": "a6cf2b63-bd86-40d0-abdd-013276dbaa55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[3, 6, 9]])"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Index on x to return 3, 6, 9\n",
        "y[:, :, 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71764285",
      "metadata": {
        "id": "71764285"
      },
      "source": [
        "## PyTorch tensors & NumPy\n",
        "NumPy is a popular scientific Python numerical computing library.\n",
        "\n",
        "And because of this, PyTorch has functionality to interact with it.\n",
        "\n",
        "- Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
        "- PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "c0fd2e62",
      "metadata": {
        "id": "c0fd2e62",
        "outputId": "7ee9579c-41d7-47a1-d0af-0b3dbe5e9c1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = np.arange(1, 10)\n",
        "array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "3109d7a7",
      "metadata": {
        "id": "3109d7a7",
        "outputId": "f35d9c50-37e0-42ea-809d-6a6092be4315"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NumPy array to tensor\n",
        "tensor = torch.from_numpy(array)\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "1ca8d723",
      "metadata": {
        "id": "1ca8d723",
        "outputId": "1ac59069-1d8f-45d6-e411-7c61f9e51f55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
              " tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]))"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the value of array, what will this do to `tensor`?\n",
        "array = array + 1\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "ea3203d6",
      "metadata": {
        "id": "ea3203d6",
        "outputId": "4ab35626-fb8f-415d-a2c5-ee706d1e540f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "d56d135a",
      "metadata": {
        "id": "d56d135a",
        "outputId": "193e528d-32b1-4ee7-82b4-980ffd15ae40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the tesnor, what happens to `numpy_tensor`?\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb42831f",
      "metadata": {
        "id": "eb42831f"
      },
      "source": [
        "## Reproducbility (trying to take random out of random)\n",
        "\n",
        "In short how a neural network learns:\n",
        "\n",
        "start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...\n",
        "\n",
        "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**.\n",
        "\n",
        "Essentially what the random seed does is \"flavour\" the randomness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "25c94fac",
      "metadata": {
        "id": "25c94fac"
      },
      "outputs": [],
      "source": [
        "# Create two random tensors\n",
        "random_a = torch.rand(3, 3)\n",
        "random_b = torch.rand(3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "55c31780",
      "metadata": {
        "id": "55c31780",
        "outputId": "9c7ffb7d-b5eb-4ce6-aaff-cdee3530ea74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.0921, 0.6660, 0.4362],\n",
              "         [0.1558, 0.1642, 0.0852],\n",
              "         [0.8322, 0.1101, 0.2027]]),\n",
              " tensor([[0.3418, 0.1094, 0.4366],\n",
              "         [0.8908, 0.2524, 0.7794],\n",
              "         [0.5150, 0.6854, 0.5510]]))"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_a, random_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "70205561",
      "metadata": {
        "id": "70205561",
        "outputId": "4ec24690-a642-4e8b-a3d4-cc7a5a668ff7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[False, False, False],\n",
              "        [False, False, False],\n",
              "        [False, False, False]])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_a == random_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "8d68d548",
      "metadata": {
        "id": "8d68d548",
        "outputId": "64a26987-6ce3-438a-bb44-94909f4b31bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
              "         [0.3904, 0.6009, 0.2566, 0.7936],\n",
              "         [0.9408, 0.1332, 0.9346, 0.5936]]),\n",
              " tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
              "         [0.3904, 0.6009, 0.2566, 0.7936],\n",
              "         [0.9408, 0.1332, 0.9346, 0.5936]]))"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's make some random but reproducible tensors\n",
        "# Set the random seed\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_c = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_d = torch.rand(3, 4)\n",
        "\n",
        "random_c, random_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "2be40a23",
      "metadata": {
        "id": "2be40a23",
        "outputId": "5fea6879-e8b0-4930-f30c-49523501318a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_c == random_d"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5faa57fb",
      "metadata": {},
      "source": [
        "Extra resources for reproducibility:\n",
        "\n",
        "- https://pytorch.org/docs/stable/notes/randomness.html\n",
        "- https://en.wikipedia.org/wiki/Random_seed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e61e1c90",
      "metadata": {
        "id": "e61e1c90"
      },
      "source": [
        "## Running tensors and PyTorch objects on the GPUs (and making faster computations)\n",
        "\n",
        "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky dory (good)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791475e5",
      "metadata": {},
      "source": [
        "### 1. Getting a GPU\n",
        "\n",
        "1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
        "2. Use your own GPU - takes a little bit of setup and requires the investment of purchasing a GPU, there's lots of options..., see this post for what option to get: https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/\n",
        "3. Use cloud computing - GCP, AWS, Azure, these services allow you to rent computers on the cloud and access them\n",
        "\n",
        "For 2, 3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer to PyTorch setup documentation: https://pytorch.org/get-started/locally/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "5610ae53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5610ae53",
        "outputId": "3806b80a-4b51-47d7-8efb-50aa477bd35b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: nvidia-smi\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I3fsfIiQx1X9",
      "metadata": {
        "id": "I3fsfIiQx1X9"
      },
      "source": [
        "### 2. Check for GPU access with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "12ETds7Mxt-I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12ETds7Mxt-I",
        "outputId": "5be4dd60-7cca-4d19-a536-d987872c8a24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for GPU access with PyTorch\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce700703",
      "metadata": {},
      "source": [
        "For PyTorch since it's capable of running compute on the GPU or CPU, it's best practice to setup device agnostic code: https://pytorch.org/docs/stable/notes/cuda.html#best-practices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "2DhiLEitx6zp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2DhiLEitx6zp",
        "outputId": "4c41f926-495c-4238-f7d7-a2d0463ad2d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code \n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "i2Dmm-uyyAbz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Dmm-uyyAbz",
        "outputId": "874159a6-d8d6-4289-bd83-9acc8a0529b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x70ZS6TzysLD",
      "metadata": {
        "id": "x70ZS6TzysLD"
      },
      "source": [
        "### 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "5UQLL-mgyMro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UQLL-mgyMro",
        "outputId": "cc445108-e6da-4661-c3cd-4547edbfae72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), device(type='cpu'))"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor (default on the CPU)\n",
        "tensor = torch.tensor([1, 2, 3], device=\"cpu\")\n",
        "\n",
        "# Tensor not on GPU\n",
        "tensor, tensor.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "72ojpn64y6Mq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ojpn64y6Mq",
        "outputId": "64e031ba-20c4-48c4-c7a4-27b19a97d041"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), device(type='cpu'))"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu, tensor_on_gpu.device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TEyE7EA-zNr0",
      "metadata": {
        "id": "TEyE7EA-zNr0"
      },
      "source": [
        "### 4. Moving tensors back to the CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "a92809d6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy\n",
        "tensor_on_gpu.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "8af23537",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "4RtC_Pexyy9y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RtC_Pexyy9y",
        "outputId": "bc6fc2e7-5fca-4ada-8ac9-3bf3fd7408fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), device(type='cpu'))"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor = torch.tensor([1, 2, 3], device=device)\n",
        "tensor, tensor.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "5y3Eaj0yy0io",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y3Eaj0yy0io",
        "outputId": "2a6e0af9-b5c9-41fe-afef-ee5fc2ce5148"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), device(type='cpu'))"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_on_cpu = tensor.to(\"cpu\")\n",
        "tensor_on_cpu, tensor_on_cpu.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "icjl40VczGAb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icjl40VczGAb",
        "outputId": "e2aa9f77-6f01-48f8-da84-ae880f1e20c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = tensor.cpu().numpy()\n",
        "array"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Bm7hW7cjztG-",
      "metadata": {
        "id": "Bm7hW7cjztG-"
      },
      "source": [
        "## Exercises and extra-curriculum"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CdQ4g7HEzeog",
      "metadata": {
        "id": "CdQ4g7HEzeog"
      },
      "source": [
        "See exercises for this notebook here: https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises See the template exercises notebook for this module here: https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "14ec2e70",
        "71764285",
        "eb42831f"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
