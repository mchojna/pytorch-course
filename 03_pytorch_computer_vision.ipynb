{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe626b79",
   "metadata": {},
   "source": [
    "## 03. PyTorch Computer Vision\n",
    "\n",
    "Resource coursebook: https://www.learnpytorch.io/03_pytorch_computer_vision/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c54733f",
   "metadata": {},
   "source": [
    "## 0. Computer vision libraries in PyTorch\n",
    "\n",
    "* `torchvision` - base domain library for PyTorch computer vision\n",
    "* `torchvision.datasets` - get datasets and data loading function for computer vision here\n",
    "* `torchvision.models` - get pretrained computer vision models that you can levarage for your own problems\n",
    "* `torchvision.transforms` - function for manipulating your vision data (images) to be suitable for use with ML model\n",
    "* `torch.utils.data.Dataset` - base dataset class for PyTorch\n",
    "* `torch.utils.data.DataLoader` - create a Python iterable over a datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da0743ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1\n",
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a976c7",
   "metadata": {},
   "source": [
    "## 1. Getting a dataset\n",
    "\n",
    "The dataset we'll be using is FashionMNIST from `torchvision.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d9be2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "from torchvision import datasets\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # where to download data to\n",
    "    train=True, # do we want the training dataset\n",
    "    download=True, # do we want to download it\n",
    "    transform=ToTensor(), # how do we want to transform teh data\n",
    "    target_transform=None, # how do we want to transform the labels\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6c440ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b553daca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first training example\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f685103f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57617eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_dix = train_data.class_to_idx\n",
    "class_to_dix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fee04716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90d54a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
      "Image label: 9\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of our image\n",
    "print(f\"Image shape: {image.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4b712",
   "metadata": {},
   "source": [
    "## 1.2 Visualizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eafe0040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "plt.title(label)\n",
    "plt.imshow(image.squeeze())\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "928f6c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFLpJREFUeJzt3WmMnWX5wOHnTKczXaaU0sWhUlu0ra2KlgCyFqTaKiJiEEv8YEQgLglRjMYvfiBGowIuRMGAS4wRE7ewiLKIS1woplSDJaZEyqZQ7EZbS6ezv/+8J+ktBaTzPH/mtcB1JSPt6bnnnJ7OnN+8Z7ltVVVVJQBIKXX8r68AAAcPUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUeAF5/zzz089PT0HPN+b3vSm9sfzpf5cr3vd6563zwcHI1GgEd/4xjdSq9VKxx9//P/6qrwgff7zn0833njj//pq8BIgCjTiBz/4QVqwYEFau3Zt2rhx4//66rzgiAJNEQXG3UMPPZTWrFmTvvKVr6TZs2e3AwEcnESBcVdHYMaMGenMM89M55577rNG4eGHH24/vPSlL30pffOb30yvetWrUnd3dzruuOPS3XfffcDLuOeee9rBqR/3f/LJJ//r+QYGBtKll16aFi5c2P788+bNS5/61Kfap4/Vn//853TSSSelyZMnpyOPPDJdc801zzjPli1b0oUXXphe9rKXpUmTJqU3vOEN6Xvf+94zzrdnz570iU98on096uvz6le/un0bPHV5cX271Oer5+tf1x/18yowLurV2TCelixZUl144YXtX//+97+v7+2qtWvX7neehx56qH360UcfXS1cuLC67LLLqssvv7yaNWtWdcQRR1SDg4Nx3ve///3V1KlT4/f155oxY0a1cuXKqq+vL04/7bTT2h/7jIyMVKtWraqmTJlSXXLJJdW1115bXXzxxVVnZ2d19tlnH/DvUX+uuXPnVnPmzGnPfe1rX6tOOeWU9vX+zne+E+err8PSpUuriRMnVh//+Mfb51u+fHn7fFdeeWWcb3R0tFqxYkXVarWqiy66qLrqqquqs846q32++vrt8/3vf7/q7u5uf4761/XHmjVrMv8VYGxEgXG1bt269p3cHXfcEXeE9Z38xz72sWeNwsyZM6snnngiTr/pppvap998883PGoU//vGP1SGHHFKdeeaZVX9//36f8+lRqO9MOzo6qj/84Q/7ne+aa65pX8add975nH+X+nPV5/vyl78cpw0MDFTLli1rh2JfuOo7/vp81113XZyv/rMTTzyx6unpqf7973+3T7vxxhvb5/vc5z633+Wce+657VBs3LgxTqv/vvXfG8abh48YV/VDRfVDKKeffnr79/VDH+edd1764Q9/mEZGRp5x/vrP6oea9lm+fHn7vw8++OAzzvvb3/42vfWtb01vfvOb0/XXX99++OW5/OQnP0lLly5NS5YsSdu2bYuPFStWxOc7kM7OzvShD30oft/V1dX+ff1wUf2wUu2WW25Jvb296b3vfW+cb+LEiemjH/1o+6Gt3/3ud3G+CRMmtE9/qvrhpPoHtltvvfWA1weeb6LAuKnv9Os7/zoI9ZPN9auO6o/6ZambN29Ov/71r58x84pXvGK/3+8LxI4dO/Y7vb+/v/0cxdFHH51+/OMft++cD+T+++9Pf/vb39rPPTz1Y/Hixe0/r+/YD2Tu3Llp6tSp+522b75+XqT2yCOPpEWLFqWOjv2/veog7fvzff+tP9+0adOe83zQpM5GL42XlN/85jfp8ccfb4eh/ni2o4hVq1btd1r9k/Ozefr/a2x9VPD2t7893XTTTem2225L73jHOw54fUZHR9NRRx3VfhXUs6mf7IWXOlFg3NR3+nPmzElXX331M/6sfrjnhhtuaL9yp34VT676Yaj685999tnpPe95T/uhlgO9e7l+RdNf//rX9sNN9XyJTZs2tV8J9NSjhb///e/t/9bvw6jNnz8/rV+/vh2hpx4t3HffffHn+/77q1/9Ku3evXu/o4Wnn2/f3xea4OEjxsXevXvbd/z1T/D1y1Cf/nHxxRe37wx/9rOfFV9G/ZBRfRn1y1bPOuus9hvjnsvq1avTY489lr71rW896/Wt7+wPZHh4OF177bXx+8HBwfbv64ehjjnmmPZp9RHMv/71r/SjH/1ov7mvf/3r7fUcp512Wpyvfojtqquu2u8yvvrVr7YjcMYZZ8RpdYR27tx5wOsH/1+OFBgX9Z19faf/zne+81n//IQTTog3stVPLpeqjzJ+/vOft58sru9E6ydx/9t+ove9733t5x8+/OEPt59UPvnkk9t3yvVP5vXpt99+ezr22GOf8/Lq5wAuu+yy9vMH9XMJ9R1//R6J+r0V9ZPJtQ9+8IPtUNTvJaiffK6PIH7605+mO++8M1155ZVxVFCHrH6+5dOf/nT789XvZfjlL3/ZfkjskksuaR/Z7FMHpz6qqB/6qq9D/f4IK0MYF+P++iZekurX20+aNKnas2fPfz3P+eef334t/7Zt2+IlqVdcccUzzleffumll/7X9ynU6s/xmte8purt7a3uv//+Z31J6r6XhtbvgXjta1/bfu1//f6GY445pvrMZz5T7dq16zn/TvXnqufql9nWLy+t/37z589vv7/g6TZv3lx94AMfaL/PoqurqzrqqKOq7373u8843+7du9vvZajf/1DfFosWLWrfBvVLd5/qvvvuq0499dRq8uTJ7dvDy1MZL636f8YnNwC80HhOAYAgCgAEUQAgiAIAQRQACKIAQP6b17zNHuCFbSzvQHCkAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAKHzP7+Eg1Or1cqeqaoqNWHatGnZM6ecckrRZd16663pYL29J0yYkD0zPDycXmxaBbddqfH6GnekAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAYCEeB72OjvyfXUZGRrJnFi5cmD1z0UUXZc/s3bs3ldizZ0/2TH9/f/bM2rVrD+rldiVL50q+hloFl9Pk7VCyhHAsHCkAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACBYiMdBr2TxV8lCvBUrVmTPvOUtb8meefTRR1OJ7u7u7JkpU6Zkz6xcuTJ75tvf/nb2zObNm1OJqqoa+Xoo0dPTUzQ3OjqaPdPX15fGgyMFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEC/E46A0ODjZyOccdd1z2zIIFCxpZ8Ffr6Mj/Ge7222/Pnjn66KOzZy6//PLsmXXr1qUS9957b/bMhg0bsmfe+MY3NvI1VFuzZk32zF133ZXGgyMFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEC/FoTKvVKpqrqip7ZuXKldkzxx57bPbM7t27s2emTp2aSixevLiRmbvvvjt7ZuPGjdkzPT09qcSJJ56YPXPOOedkzwwNDTVy29Uuuuii7JmBgYE0HhwpABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAoVWNcQVl6YZLDn4H+79tyZbUP/3pT9kzCxYsSAfz7T08PJw9Mzg4mJrQ39+fPTM6Olp0WX/5y18a2eI6XHB7v+1tb0slXvnKV2bPvPzlLx+X7yVHCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACJ3/+SUvVSUL5w52O3bsyJ45/PDDs2f27t2bPdPd3Z1KdHbmf7v29PQ0stxu8uTJjS3EW758efbMSSedlD3T0ZH/M/OcOXNSidtuuy0dLBwpABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgWIjHi9KUKVMaWYBWMtPX15dK7Nq1K3tm+/bt2TMLFixoZKliq9VKJUpu85Kvh5GRkcaW/M2bNy8dLBwpABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgWIhH0WKykqVkJQvGaj09Pdkzc+fOzZ4ZGBhoZKa7uzuVGBwcbGT53qGHHtrI4r2SJXW1rq6u7Jndu3dnz0yfPj17Zv369ampr/Fjjz02jQdHCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQLAllVRVVfbMhAkTGtuSet5552XP9Pb2Zs9s3bo1e2by5MnZM6Ojo6nE1KlTs2fmzZvXyDbWks2vQ0NDqURnZ2cj/04zZ87Mnrn66qtTiWXLljVyO4yFIwUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAIRWNcZtaK1Wayxn4wWoZLHW8PBwasrxxx+fPfOLX/wie2bv3r0H9WLAadOmZc/09/dnz2zfvj17ZuLEiY3MlC4G3LFjR2pCf8HtXbviiiuyZ6677rrsmbHc3TtSACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAyN+ENs5KF++VLCbr6Oho5PoNDQ1lz4yOjqamNLncrsQtt9ySPbNnz55GFuJ1dXVlz4xxB+UzbN26tZHvi0mTJjXyNV6qqe+nCQW33etf//pUYteuXelg4UgBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgDNLMQrWSg1MjLyolzqdjA79dRTs2fe/e53Z8+cfPLJqURfX1/2zPbt2xtZbtfZ2dnY13jJ7VDyPdjd3d3IEr3SxYAlt0OJroKvhyeffLLoss4555zsmZtvvjmNB0cKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIrWqMW6larVZ6sTnssMOyZ+bOnZs9s2jRokYup3Sx1uLFi7NnBgYGsmc6Osp+BhkaGsqemTx5cvbMpk2bsmcmTpzYyKK12syZM7NnBgcHs2emTJmSPbNmzZrsmZ6entTUAsfR0dHsmV27djXy9VDbvHlz9szSpUuzZ8Zyd+9IAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQAaGZL6gknnJA989nPfjaVmD17dvbMoYcemj0zMjKSPTNhwoTsmZ07d6YSw8PDjWzFLNm+Wbppd+/evdkzGzZsyJ5ZvXp19sy6deuyZ6ZNm5ZKzJgxI3tmwYIFqQkPPvhgY7fD7t27s2f6+voa2bTbU7j59ZBDDmnk+9aWVACyiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQP5CvM7OzpTrrrvuyp45/PDDU4mSRXUlMyWLtUqULNErXR7XlOnTpxfNzZo1K3vm/PPPz55ZtWpV9sxHPvKR7JlNmzalEv39/dkzDz30UCPL7RYtWpQ9M3PmzFSiZBnjxIkTG1nYN7Hgcmqjo6PZM/Pnz8+esRAPgCyiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKACQvxDvggsuSLm++MUvZs888MADqURPT08jM93d3akJpYu1SpbO/fOf/2xkqdvs2bNTiY6O/J9dent7s2fe9a53Zc9MmjQpe2bBggWpRMnX6zHHHNPITMm/Ucliu9LL6urqSk1otVqNfb+fcMIJ2TP/+Mc/DngeRwoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAidaYy2bNmSmli0Nm3atFRiYGCgketXspSsZBnXIYcckko88cQT2TOPPPJII7fD3r17U4n+/v7smeHh4eyZG264IXvm3nvvbWwh3mGHHdbI0rmdO3dmzwwNDTXyb1QbHR1tZOHcaMHllC7EK7mPWLx4cRoPjhQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoAJC/EO+xxx5Luaqqyp559NFHU4mpU6dmz8yaNauRZWHbtm3Lntm6dWsq0dk55n/S0N3d3ciCsUmTJqUSJUsSOzo6Gvl3Wrp0afbMnj17UomSBY47duxo5Ouh5LYrWaJXukiv5LImT56cPdPb25tK7Nq1K3tm2bJlaTw4UgAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAMKYV2rec889Kdf111+fPXPBBRekEps2bcqeefDBB7Nn+vv7s2d6enoa2UJautmxq6sre2bChAnZMwMDA6nEyMhIIxt6+/r6smcef/zxRq5b6e1QsjW3qa/xwcHBVKJkU3HJzFDBZtWSDa61I488Mntm8+bNaTw4UgAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQGhVY9zO1Wq1UhPOOOOMorlPfvKT2TNz5szJntm2bVsjy7hKlp+VLqorWYhXsmit5LqVfu2VLJ0rWUJYMlNye5deVlPftyWXM14L3Z6v23x0dDR7pre3N5VYv3599szq1avH5fvCkQIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAPIX4pUsMytZKNWk008/PXvmC1/4QiOL96ZPn55KdHTkd77k37ZkIV7pkr8SW7ZsaWSJ3mOPPdbY98WTTz7Z2BLCJm67oaGhosvq6+tr5PvijjvuyJ7ZsGFDKrFmzZrUBAvxAMgiCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIA+QvxWq3WWM7G82TJkiVFc7Nmzcqe2blzZ/bMEUcckT3z8MMPpxIli9MeeOCBosuCFzML8QDIIgoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAi2pAK8RFS2pAKQQxQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAoTONUVVVYz0rAC9QjhQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQASPv8HyyBi/s4/76wAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(class_names[label])\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0a4b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    \n",
    "    img, label = train_data[random_idx]\n",
    "    \n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd77d7",
   "metadata": {},
   "source": [
    "Do you think these items of clothing (images) could be modelled with pure linear lines? Or you think we'll need non-linearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0217dbe",
   "metadata": {},
   "source": [
    "## 2. Prepare dataloader\n",
    "\n",
    "Right now, our data is in the form of PyTorch Datasets\n",
    "\n",
    "DataLoader turns our dataset into a Python iterable\n",
    "\n",
    "More specifically, we want to turn our data into batches (or mini-batches)\n",
    "\n",
    "Why would we do this?\n",
    "\n",
    "1. It is more computationally efficient, as in your computer hardware may not be able to look (store in memory) at 60000 images in one hit. So we break it down to 32 images at a time (batch size of 32)\n",
    "2. It gives our neural network more chances to update its gradients per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e850738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_data_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d5bab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders: (<torch.utils.data.dataloader.DataLoader object at 0x1389ef890>, <torch.utils.data.dataloader.DataLoader object at 0x150165810>)\n",
      "Length of train_data_loader: 1875 batches of 32...\n",
      "Length of test_data_loader: 313 batches of 32...\n"
     ]
    }
   ],
   "source": [
    "# Let's check out what we've created\n",
    "print(f\"DataLoaders: {train_data_loader, test_data_loader}\")\n",
    "print(f\"Length of train_data_loader: {len(train_data_loader)} batches of {BATCH_SIZE}...\")\n",
    "print(f\"Length of test_data_loader: {len(test_data_loader)} batches of {BATCH_SIZE}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a28966d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_data_loader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb132193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Label: 6, label size: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Show a sample\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3373042",
   "metadata": {},
   "source": [
    "## 3. Create a baseline model\n",
    "\n",
    "When starting to build a series of machine learning experiments, it's best practice to start with a baseline model\n",
    "\n",
    "A baselin model is a simple model you will try and improve upon with subsequent  models/experiments\n",
    "\n",
    "In other words: start simply and add complexity when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e9d94c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before flattening: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
      "shape after flattening: torch.Size([1, 784]) -> [color_channels, height * width]\n"
     ]
    }
   ],
   "source": [
    "# Create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# Get a single sample\n",
    "x = train_features_batch[0]\n",
    "print(f\"shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "\n",
    "# Flatten the sample\n",
    "output = flatten_model(x) # perform forward pass\n",
    "\n",
    "# Print out what happend\n",
    "print(f\"shape after flattening: {output.shape} -> [color_channels, height * width]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54ffbdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0039, 0.0039, 0.0000, 0.0000, 0.0078, 0.0078,\n",
       "        0.0000, 0.0000, 0.0039, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.2863, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.3725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.3373, 0.3569, 0.2039, 0.4980, 0.4196, 0.4706, 0.3608, 0.3961, 0.4706,\n",
       "        0.4471, 1.0000, 0.4314, 0.3451, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0706, 0.0824, 0.0706, 0.4588, 0.4118, 0.4980, 0.2588, 0.2235,\n",
       "        0.2588, 0.0824, 0.0510, 0.1922, 0.5137, 0.5765, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.1333, 0.8000, 0.5608, 0.5255, 0.2431, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0039, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0078, 0.0000, 0.0000, 0.0000, 0.9137, 0.9686, 0.5137, 0.4353, 0.6471,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.3843, 0.6980, 0.0588, 0.2824,\n",
       "        0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.1333, 0.2078, 0.2157, 0.6745, 0.2941,\n",
       "        0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0039, 0.0000, 0.0078, 0.3333, 0.2980, 0.2941, 0.2039,\n",
       "        0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0039, 0.0039, 0.0000, 0.2196, 0.5020, 0.0157, 0.0706,\n",
       "        0.3451, 0.3216, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.4863, 0.3843, 0.1804,\n",
       "        0.6235, 0.7882, 0.6000, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.4431, 0.4196,\n",
       "        0.5882, 0.5020, 0.1020, 0.2235, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.4078, 0.4314,\n",
       "        0.7137, 0.1843, 0.2196, 0.4118, 0.3216, 0.0196, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2549, 0.5647,\n",
       "        0.6275, 0.0824, 0.0000, 0.0000, 0.5098, 0.3333, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0039, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.5647,\n",
       "        0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.6510, 0.3059, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.7216,\n",
       "        0.4510, 0.0000, 0.0000, 0.0157, 0.0000, 0.0000, 0.6275, 0.2667, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0784, 0.0784,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6392,\n",
       "        0.3804, 0.0000, 0.0000, 0.0000, 0.0314, 0.0000, 0.0000, 0.6667, 0.1529,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0314, 0.2471, 0.2980,\n",
       "        0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5255,\n",
       "        0.5333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.6784,\n",
       "        0.0706, 0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.0000, 0.0706, 0.0941,\n",
       "        0.0000, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3451,\n",
       "        0.7137, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.6588, 0.0039, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078,\n",
       "        0.1922, 0.1059, 0.1216, 0.2196, 0.0667, 0.0000, 0.0000, 0.0000, 0.3451,\n",
       "        0.6000, 0.1922, 0.0000, 0.0196, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.6471, 0.0000, 0.0000, 0.0039, 0.0510, 0.0275, 0.0000, 0.0000,\n",
       "        0.0000, 0.3294, 0.3804, 0.4000, 0.4941, 0.3882, 0.0000, 0.0196, 0.5020,\n",
       "        0.6000, 0.2863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0039, 0.5451, 0.0000, 0.0000, 0.0000, 0.3176, 0.5961, 0.5725,\n",
       "        0.5490, 0.4863, 0.4824, 0.5098, 0.4941, 0.4431, 0.4431, 0.4471, 0.7216,\n",
       "        0.6235, 0.1647, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.7294, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "        0.0000, 0.0941, 0.1647, 0.1804, 0.2235, 0.2549, 0.2706, 0.2549, 0.2471,\n",
       "        0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.7137, 0.0157, 0.0000, 0.0039, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31e81dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf\n",
    "from pandas import infer_freq\n",
    "from torch import nn\n",
    "\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38b26080",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Setup model with input parameters\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=784, # this is 28 * 28\n",
    "    hidden_units=32,\n",
    "    output_shape=len(class_names) # one for every class\n",
    ").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89cf18f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e8393a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0461, -0.1040,  0.2095,  0.0458, -0.0841, -0.3552,  0.0832, -0.1319,\n",
       "          0.1477,  0.0418]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x = torch.rand([1, 1, 28, 28])\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "50115e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer_stack.1.weight',\n",
       "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "                      ...,\n",
       "                      [-0.0023,  0.0071,  0.0330,  ...,  0.0164, -0.0095, -0.0053],\n",
       "                      [ 0.0167, -0.0324,  0.0086,  ..., -0.0090,  0.0203, -0.0100],\n",
       "                      [-0.0118,  0.0119, -0.0080,  ..., -0.0193,  0.0170,  0.0246]])),\n",
       "             ('layer_stack.1.bias',\n",
       "              tensor([ 0.0161, -0.0159,  0.0234,  0.0084, -0.0339, -0.0047, -0.0323, -0.0125,\n",
       "                       0.0065, -0.0339, -0.0036,  0.0208,  0.0018,  0.0308, -0.0056, -0.0006,\n",
       "                      -0.0294, -0.0100,  0.0059,  0.0271,  0.0328, -0.0049,  0.0312,  0.0041,\n",
       "                       0.0242,  0.0212, -0.0234,  0.0345,  0.0085, -0.0198, -0.0343,  0.0012])),\n",
       "             ('layer_stack.2.weight',\n",
       "              tensor([[-0.0630,  0.1486,  0.0598, -0.0858,  0.0406, -0.1010,  0.1632,  0.0980,\n",
       "                        0.0875,  0.0770, -0.0174, -0.0463,  0.0163, -0.1765, -0.0924,  0.0205,\n",
       "                        0.1294,  0.0004, -0.0606,  0.1201,  0.0473, -0.1084,  0.0779,  0.0448,\n",
       "                       -0.1452,  0.0331, -0.1172,  0.1611, -0.1113, -0.0304, -0.0737,  0.0163],\n",
       "                      [ 0.1541, -0.0840,  0.0566, -0.0379, -0.0748,  0.0059,  0.1328, -0.1597,\n",
       "                       -0.0737,  0.1342, -0.0850,  0.0408,  0.0665,  0.0146,  0.0142, -0.1183,\n",
       "                       -0.0277, -0.0340, -0.0090, -0.0195, -0.0413, -0.1051,  0.1259,  0.0513,\n",
       "                        0.0590,  0.0877,  0.0037,  0.1148,  0.0550, -0.0534,  0.0025, -0.1541],\n",
       "                      [-0.0916,  0.1645,  0.1750, -0.1264, -0.0770,  0.0973, -0.1580, -0.0196,\n",
       "                       -0.1620, -0.0836, -0.0927, -0.0084, -0.0470, -0.0974,  0.0924, -0.0782,\n",
       "                       -0.1739,  0.0861,  0.1161, -0.0382,  0.0052,  0.0226, -0.0221, -0.0359,\n",
       "                       -0.1439,  0.0774, -0.0007,  0.0938,  0.0117, -0.0702, -0.0873,  0.0230],\n",
       "                      [ 0.0904,  0.1758,  0.1584,  0.1450, -0.1339,  0.0320,  0.1610,  0.0801,\n",
       "                        0.1178,  0.1678, -0.0534,  0.0945,  0.1047,  0.0031, -0.1039,  0.0488,\n",
       "                        0.1472,  0.0220,  0.0555,  0.0243,  0.1248,  0.0941, -0.0396,  0.0288,\n",
       "                       -0.0827,  0.0277, -0.1524,  0.0606,  0.1071, -0.1483,  0.0482, -0.0243],\n",
       "                      [-0.0701,  0.0791,  0.0080, -0.0932,  0.1213,  0.0460, -0.1222, -0.0288,\n",
       "                       -0.0959, -0.1112,  0.1687, -0.0186, -0.0104, -0.0211, -0.0397, -0.1500,\n",
       "                       -0.0233, -0.0737,  0.0736, -0.0049, -0.1732, -0.1049, -0.1327,  0.0108,\n",
       "                        0.1092,  0.0813,  0.0108,  0.1011, -0.0192,  0.1630, -0.1473, -0.0471],\n",
       "                      [-0.0242, -0.1337,  0.0558,  0.1211,  0.0294,  0.0154,  0.1532, -0.0630,\n",
       "                       -0.0277,  0.0656, -0.0967, -0.1336, -0.0358,  0.1153, -0.0910,  0.0508,\n",
       "                        0.0032,  0.1623,  0.0932, -0.0934, -0.1701,  0.1052, -0.1626, -0.1036,\n",
       "                        0.1716,  0.0521, -0.0024, -0.1343, -0.0331,  0.0237,  0.1047, -0.0691],\n",
       "                      [-0.0311,  0.0352, -0.1738, -0.0547, -0.1616, -0.0636, -0.1045,  0.0867,\n",
       "                       -0.1222, -0.1665, -0.0203, -0.0833, -0.0925, -0.0413,  0.0659, -0.1564,\n",
       "                       -0.1282,  0.0129,  0.0792,  0.0069,  0.1756,  0.0879, -0.1194,  0.1000,\n",
       "                       -0.0915,  0.1303, -0.0449,  0.1472, -0.0415, -0.0514, -0.1292,  0.1749],\n",
       "                      [-0.1009, -0.0771, -0.0970, -0.1748, -0.0872,  0.1457,  0.1128,  0.0454,\n",
       "                       -0.0519,  0.0244, -0.0329, -0.1448,  0.1201,  0.0927,  0.1526, -0.1651,\n",
       "                        0.0277,  0.0997, -0.0245,  0.0820,  0.0878, -0.0871,  0.1300,  0.0447,\n",
       "                       -0.0193,  0.0639,  0.1336,  0.0329,  0.0855, -0.1200, -0.0820, -0.0305],\n",
       "                      [ 0.1010,  0.1004, -0.0481, -0.0278, -0.0243, -0.0819,  0.1486,  0.0892,\n",
       "                        0.1154, -0.0598, -0.0425, -0.1472,  0.1315, -0.0669, -0.0146, -0.1174,\n",
       "                        0.0364,  0.0967, -0.1757,  0.1357,  0.0325,  0.0844, -0.1545,  0.0453,\n",
       "                        0.1731,  0.1165, -0.0794,  0.0096, -0.1209,  0.0709,  0.0839,  0.0766],\n",
       "                      [-0.1532,  0.0859,  0.0067, -0.1235, -0.0604,  0.1554, -0.1420,  0.1045,\n",
       "                        0.1722, -0.1298, -0.1634, -0.1339,  0.0033, -0.1657,  0.1447,  0.1574,\n",
       "                       -0.0198,  0.0966,  0.1450,  0.0565, -0.0870, -0.0059,  0.1240, -0.0727,\n",
       "                        0.0041, -0.0238, -0.0338, -0.0296, -0.0913, -0.0549,  0.1620, -0.0544]])),\n",
       "             ('layer_stack.2.bias',\n",
       "              tensor([-0.0251,  0.1526,  0.0626, -0.1248, -0.0499, -0.0673, -0.0983, -0.1468,\n",
       "                       0.0876,  0.1363]))])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb43758",
   "metadata": {},
   "source": [
    "### 3.1 Setup loss, optimizer and evaluation metrics\n",
    "\n",
    "* Loss function - since we're working with multi-class data, our loss functionwill be `nn.CrossEntropyLoss()`\n",
    "* Optimizer - our optimizer `torch.optim.SGD()` (stochastic gradient descent)\n",
    "* Evaluation metric - since we're working on a classification problem let's use accuracy as our evaluation problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a29d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates when two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2945bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=model_0.parameters(),\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33715cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CrossEntropyLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db9d26",
   "metadata": {},
   "source": [
    "### 3.2 Creating a function to time our experiments\n",
    "\n",
    "Machine learning is very experimental\n",
    "\n",
    "Two of the main things you'll often want to track are:\n",
    "\n",
    "1. Model's performance (loss and accuracy values etc.)\n",
    "2. How fast it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f955946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time\"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3ce8e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cpu: 0.000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.27909988805186e-05"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timer()\n",
    "# some code...\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time, end=end_time, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16d6b46",
   "metadata": {},
   "source": [
    "### 3.3 Creating a trainig loop and training a model on batches of data\n",
    "\n",
    "1. Loop through epochs\n",
    "2. Loop through training batches, perform training steps, calculate train loss *per batch*\n",
    "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*\n",
    "4. Print out what's happeninig\n",
    "5. Time it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74026390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320af1959f1047a48aa2cbe042537afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\n",
      "Looked at 0/60000 sampels.\n",
      "Looked at 12800/60000 sampels.\n",
      "Looked at 25600/60000 sampels.\n",
      "Looked at 38400/60000 sampels.\n",
      "Looked at 51200/60000 sampels.\n",
      "\n",
      "Train loss: 0.5851 | Test loss: 0.5026 | Test acc: 82.4181\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Looked at 0/60000 sampels.\n",
      "Looked at 12800/60000 sampels.\n",
      "Looked at 25600/60000 sampels.\n",
      "Looked at 38400/60000 sampels.\n",
      "Looked at 51200/60000 sampels.\n",
      "\n",
      "Train loss: 0.4756 | Test loss: 0.4851 | Test acc: 82.8275\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Looked at 0/60000 sampels.\n",
      "Looked at 12800/60000 sampels.\n",
      "Looked at 25600/60000 sampels.\n",
      "Looked at 38400/60000 sampels.\n",
      "Looked at 51200/60000 sampels.\n",
      "\n",
      "Train loss: 0.4544 | Test loss: 0.4782 | Test acc: 83.4864\n",
      "\n",
      "Train time on cpu: 7.398 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training time)\n",
    "epochs = 3\n",
    "\n",
    "# Creat training and testing loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n\")\n",
    "    \n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Add a loop to loop through the training batches\n",
    "    for batch, (X_train, y_train) in enumerate(train_data_loader):\n",
    "        model_0.train()\n",
    "                \n",
    "        # 1. Forward pass\n",
    "        y_pred = model_0(X_train)\n",
    "        \n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        train_loss += loss # accumulate train loss\n",
    "        \n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Optimizer step\n",
    "        optimizer.step() # updates one per batch rather than once per epoch\n",
    "\n",
    "        # Print out what's happening\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X_train)}/{len(train_data_loader.dataset)} sampels.\")\n",
    "    \n",
    "    # Divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_data_loader)\n",
    "    \n",
    "    ### Testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    model_0.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_data_loader:\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model_0(X_test)\n",
    "            \n",
    "            # 2. Calculate loss (accumulatively)\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "                        \n",
    "            # 3. Calculate accuracy\n",
    "            test_acc += accuracy_fn(\n",
    "                y_true=y_test, \n",
    "                y_pred=test_pred.argmax(dim=1)\n",
    "            )\n",
    "            \n",
    "        # Calculate the test loss average per batch\n",
    "        test_loss /= len(test_data_loader)\n",
    "        \n",
    "        # Calculate the test accuracy average per batch\n",
    "        test_acc /= len(test_data_loader)\n",
    "\n",
    "    # Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\\n\")\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_ecp = timer()\n",
    "\n",
    "total_train_time_model_0 = print_train_time(\n",
    "    start=train_time_start_on_cpu,\n",
    "    end=train_time_end_on_ecp,\n",
    "    device=str(next(model_0.parameters()).device)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dadf2e3",
   "metadata": {},
   "source": [
    "## 4. Make predictions and get `model_0` results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "32ff3f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48406a01c884f43a742f30a303f7d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode name: FashionMNISTModelV0 | Test loss: 0.47821298241615295 | Test acc: 83.48642172523962\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def eval_model(\n",
    "    model: torch.nn.Module, \n",
    "    data_loader: torch.utils.data.DataLoader, \n",
    "    loss_fn: torch.nn.Module, \n",
    "    accuracy_fn,\n",
    "    device: torch.device = \"cpu\",\n",
    "):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader\"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # Scale loss and acc to find the average loss / acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\n",
    "        \"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "        \"model_loss\": loss,\n",
    "        \"model_acc\": acc\n",
    "    }\n",
    "\n",
    "# Calculate model_0 results on test dataset\n",
    "model_0_results = eval_model(model_0, test_data_loader, loss_fn, accuracy_fn)\n",
    "\n",
    "print(f\"Mode name: {model_0_results['model_name']} | Test loss: {model_0_results['model_loss']} | Test acc: {model_0_results['model_acc']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756aa6be",
   "metadata": {},
   "source": [
    "## 5. Setup device agnostic-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b6969a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device agnostic code\n",
    "# device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2097f8c5",
   "metadata": {},
   "source": [
    "Sometimes, depending on your data / hardware you might find that your model trains faster on CPU than GPU\n",
    "\n",
    "Why is this?\n",
    "\n",
    "1. It could be that the overhead for copying data/model to and from the GPU outweights the cmoputer benefits offered by the GPU\n",
    "2. The hardware you're using has a better CPU in terms computer capability than the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faecb33",
   "metadata": {},
   "source": [
    "## 6. Building a better model with non-linearity\n",
    "\n",
    "We learned about the power of non-linearity with notebook 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5cb73d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV1(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (layer_1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (layer_2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (layer_3): Linear(in_features=32, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model with linear and non-linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, in_shape: int, out_shape: int, hidden_units: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten() # flatten inputs into a single vector\n",
    "        \n",
    "        self.layer_1 = nn.Linear(\n",
    "            in_features=in_shape,\n",
    "            out_features=hidden_units\n",
    "        )\n",
    "        self.layer_2 = nn.Linear(\n",
    "            in_features=hidden_units,\n",
    "            out_features=hidden_units\n",
    "        )\n",
    "        self.layer_3 = nn.Linear(\n",
    "            in_features=hidden_units,\n",
    "            out_features=out_shape\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU() # add non-linearity\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.relu(self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(self.flatten(x)))))))\n",
    "\n",
    "model_1 = FashionMNISTModelV1(\n",
    "    in_shape=784, # output of the flatten layer\n",
    "    out_shape=len(class_names), \n",
    "    hidden_units=32\n",
    ").to(device) # send to device if available\n",
    "\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ca1646a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f8d2d",
   "metadata": {},
   "source": [
    "### 6.1 Setup loss, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c29ddf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates when two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27b12218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CrossEntropyLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() # measure how wrong our model is\n",
    "optimizer = torch.optim.SGD( # tries to update our model's parameters to reduce loss\n",
    "    params=model_1.parameters(), \n",
    "    lr=0.1\n",
    ")\n",
    "\n",
    "loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7853c7",
   "metadata": {},
   "source": [
    "### 6.2 Functioning training and evaluation/testing loops\n",
    "\n",
    "Let's create a function for:\n",
    "\n",
    "* training loop - `train_step()`\n",
    "* testing loop - `test_step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3902915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    accuracy_fn,\n",
    "    device: torch.device=device,\n",
    ") -> None:\n",
    "    \"\"\"Performs a training with model trying to learn data_loader\"\"\"\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Put model into training mode\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Add a loop to loop through training data\n",
    "    for batch, (X_train, y_train) in enumerate(data_loader):\n",
    "        # Put data on target device\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X_train)\n",
    "        \n",
    "        # 2. Calculate loss and acc (per batch)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        train_loss += loss # accumulate train loss\n",
    "        \n",
    "        acc = accuracy_fn(\n",
    "            y_true=y_train, \n",
    "            y_pred=y_pred.argmax(dim=1) # logits -> prediction probabilites\n",
    "        )\n",
    "        train_acc += acc # accumulate train acc\n",
    "        \n",
    "        # 3. Optomizer zero grade\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Loss backawrd\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Optimizer step (update the model's parameters once per batch)\n",
    "        optimizer.step() \n",
    "    \n",
    "    # Divide total train loss and acc by length of train dataloader\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    \n",
    "    # Print out what's happening\n",
    "    print(f\"Train loss: {train_loss:.4} | Train acc: {train_acc:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c93922c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "    model: torch.nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    accuracy_fn,\n",
    "    device: torch.device=device,\n",
    ") -> None:\n",
    "    \"\"\"Performs a testing with model trying to learn data_loader\"\"\"\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in data_loader:\n",
    "            # Put data on target device\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            y_pred = model(X_test)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy (accumlatively)\n",
    "            test_loss += loss_fn(y_pred, y_test)\n",
    "            test_acc += accuracy_fn(\n",
    "                y_true=y_test,\n",
    "                y_pred=y_pred.argmax(dim=1) # go from logits -> prediction labels\n",
    "            )\n",
    "            \n",
    "        # Calculate the loss average per batch\n",
    "        test_loss /= len(data_loader)\n",
    "        \n",
    "        # Calculate the loss average per batch\n",
    "        test_acc /= len(data_loader)\n",
    "        \n",
    "        # Print out what's happening\n",
    "        print(f\"Test loss: {test_loss:.4} | Test acc: {test_acc:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fc1885fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb743a568f645c6aa43ee1cdb6be617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\n",
      "Train loss: 1.202 | Train acc: 63.3767%\n",
      "Test loss: 1.022 | Test acc: 70.8667%\n",
      "Epoch: 1\n",
      "\n",
      "Train loss: 0.7484 | Train acc: 78.6317%\n",
      "Test loss: 0.6051 | Test acc: 81.6317%\n",
      "Epoch: 2\n",
      "\n",
      "Train loss: 0.6053 | Train acc: 81.1950%\n",
      "Test loss: 0.6172 | Test acc: 80.8433%\n",
      "Train time on cpu: 10.911 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time \n",
    "train_timer_start_on_gpu = timer()\n",
    "\n",
    "# Set epochs\n",
    "epochs = 3\n",
    "\n",
    "# Create an optimiziation and evaluation loop using train_step() and test_step()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n\")\n",
    "    \n",
    "    train_step(\n",
    "        model=model_1,\n",
    "        data_loader=train_data_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    test_step(\n",
    "        model=model_1,\n",
    "        data_loader=train_data_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "train_timer_end_on_gpu = timer()\n",
    "\n",
    "total_train_time_model_1 = print_train_time(\n",
    "    start=train_timer_start_on_gpu,\n",
    "    end=train_timer_end_on_gpu,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e84b2adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9010e1e7f94f9b91c496e46ad22539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV1',\n",
       " 'model_loss': tensor(0.6557),\n",
       " 'model_acc': 79.85223642172524}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model_1 results dictionary\n",
    "model_1_results = eval_model(\n",
    "    model=model_1,\n",
    "    data_loader=test_data_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn\n",
    ")\n",
    "\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5756057e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': tensor(0.4782),\n",
       " 'model_acc': 83.48642172523962}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69b2b44",
   "metadata": {},
   "source": [
    "## 7. Build a convolutional neural network (CNN) - model 2\n",
    "\n",
    "CNN's are also known ConvNets\n",
    "\n",
    "CNN's are know for their capabilities to find patterns in visual data\n",
    "\n",
    "To find out what's happening inside a CNN, see this website: https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "501f836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture that replicates the TinyVGG model from CNN explainer website\n",
    "    \"\"\"\n",
    "    def __init__(self, in_shape: int, hidden_units: int, out_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            # Create a conv layer\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3), # how big is the square that's going over the image\n",
    "                stride=1,\n",
    "                padding=1, # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(2, 2),\n",
    "                stride=2,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(2, 2),\n",
    "                stride=2,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=hidden_units * 7 * 7, # there is a trick to calculate this...\n",
    "                out_features=out_shape,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = self.conv_block_1(x)\n",
    "        # print(f\"Output shape of conv_block_1: {z.shape}\")\n",
    "        \n",
    "        z = self.conv_block_2(z)\n",
    "        # print(f\"Output shape of conv_block_2: {z.shape}\")\n",
    "        \n",
    "        z = self.classifier(z)\n",
    "        # print(f\"Output shape of classifier: {z.shape}\")\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a254f609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV2(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=3136, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(\n",
    "    in_shape=1,\n",
    "    out_shape=len(class_names),\n",
    "    hidden_units=64,\n",
    ").to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1561f036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAADURJREFUeJzt3LuP1PX+x/HvzN5YmAXklgUlrkaINAYjKl4TjRjtDCbYGkJj739godHaztJaC+Mt9mCUGAMFjeANMNyEDbD3nTnZ4vc6xa84+/nk7Pfs4TwelQWvDJmd4bnfwndnMBgMGgBomqb7n/4LALB+iAIAIQoAhCgAEKIAQIgCACEKAIQoABDDzSp1Op3V/lEA1qHV/L/KnhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBj+53/C+tTpdIo3g8GgacPExETx5vnnn696ra+//rpZr+/30NBQ8WZpaam513Qq3rtaa/UZ96QAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEA7ise51u+W/uywvLxdvHnnkkeLNiRMnijezs7NNjbt37xZv5ubmijc//PDDuj5uV3N0ruYz1Kl4nTbfh5ojhKvhSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgHMRj3as5/FVzEO/ll18u3rzyyivFm4sXLzY1xsbGijcbN24s3hw5cqR488knnxRvrly50tQYDAatfB5q9Hq9ql2/3y/ezMzMNGvBkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAOIjHurewsNDK6zz55JPFm6mpqVYO/K3odst/h/v222+LN48//njx5sMPPyzenD59uqlx9uzZ4s25c+eKN0899VQrn6EVJ0+eLN6cOnWqWQueFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDCQTxa0+l0qnaDwaB4c+TIkeLNoUOHije3b98u3mzatKmpsX///lY2P/74Y/Hml19+Kd70er2mxjPPPFO8OXr0aPFmcXGxlfduxYkTJ4o38/PzzVrwpABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAdAarPEFZe+GS9W+9/2xrrqR+//33xZupqalmPb/fS0tLxZuFhYWmDXNzc8Wbfr9f9Vo//fRTK1dclyre79dee62p8fDDDxdv7r///jX5LnlSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIjhf/4n/6tqDs6tdzdv3ize7N69u3gzOztbvBkbG2tqDA+Xf117vV4rx+3Gx8dbO4j3wgsvFG+effbZ4k23W/47865du5oa33zzTbNeeFIAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACAfxuCdt3LixlQNoNZuZmZmmxvT0dPHmxo0bxZupqalWjip2Op2mRs17XvN5WF5ebu3I3969e5v1wpMCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQDiIR9VhspqjZDUHxlb0er3izZ49e4o38/PzrWzGxsaaGgsLC60c39u6dWsrh/dqjtStGB0dLd7cvn27eLNly5bizZkzZ5q2PuOHDh1q1oInBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDClVSawWBQvBkaGmrtSupbb71VvJmcnCzeXLt2rXgzPj5evOn3+02NTZs2FW/27t3byjXWmsuvi4uLTY3h4eFWfk7bt28v3nz88cdNjYMHD7byPqyGJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA6AxWeQ2t0+ms5o/xX6jmsNbS0lLTlqeffrp48+WXXxZvZmdn1/VhwImJieLN3Nxc8ebGjRvFm5GRkVY2tYcBb9682bRhruL9XvHRRx8Vbz799NPizWr+ufekAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABDll9DWWO3hvZrDZN1ut5W/3+LiYvGm3+83bWnzuF2Nr776qnhz9+7dVg7ijY6OFm9WeYPy/7l27Vor34sNGza08hmv1db3aajivXvssceaGtPT08164UkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAoJ2DeDUHpZaXl+/Jo27r2Ysvvli8efPNN4s3zz33XFNjZmameHPjxo1WjtsNDw+39hmveR9qvoNjY2OtHNGrPQxY8z7UGK34PNy5c6fqtY4ePVq8+eKLL5q14EkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIDqDVV6l6nQ6zb1m27ZtxZs9e/YUb/bt29fK69Qe1tq/f3/xZn5+vnjT7db9DrK4uFi8GR8fL95cvny5eDMyMtLKobUV27dvL94sLCwUbzZu3Fi8OXnyZPGm1+s1bR1w7Pf7xZvp6elWPg8rrly5Urw5cOBA8WY1/9x7UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQCgnSuphw8fLt689957TY2dO3cWb7Zu3Vq8WV5eLt4MDQ0Vb27dutXUWFpaauUqZs31zdpLu7Ozs8Wbc+fOFW+OHTtWvDl9+nTxZmJioqlx3333FW+mpqaaNly4cKG19+H27dvFm5mZmVYu7fYqL79u3ry5le+tK6kAFBEFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAoPwg3vDwcFPq1KlTxZvdu3c3NWoO1dVsag5r1ag5old7PK4tW7Zsqdrt2LGjePP2228Xb1599dXizTvvvFO8uXz5clNjbm6uePPrr7+2ctxu3759xZvt27c3NWqOMY6MjLRysG+k4nVW9Pv94s2DDz5YvHEQD4AiogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCUH8Q7fvx4U+qDDz4o3pw/f76p0ev1WtmMjY01bag9rFVzdO7PP/9s5ajbzp07mxrdbvnvLpOTk8WbN954o3izYcOG4s3U1FRTo+bz+sQTT7SyqfkZ1Ry2q32t0dHRpg2dTqe17/vhw4eLN3/88ce//DOeFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBiuFmlq1evNm0cWpuYmGhqzM/Pt/L3qzlKVnOMa/PmzU2Nv//+u3jz+++/t/I+zM7OFm9WzM3NFW+WlpaKN59//nnx5uzZs60dxNu2bVsrR+du3bpVvFlcXGzlZ7Si3++3cnCuX/E6tQfxav6N2L9/f7MWPCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAlB/Eu3TpUlNqMBgUby5evNjU2LRpU/Fmx44drRwLu379evHm2rVrTY3h4VX/SGNsbKyVA2MbNmxoatQcSex2u638nA4cOFC8uXv3blOj5oDjzZs3W/k81Lx3NUf0ag/p1bzW+Ph48WZycrKpMT09Xbw5ePBgsxY8KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQqz6p+fPPPzelPvvss+LN8ePHmxqXL18u3ly4cKF4Mzc3V7zp9XqtXCGtvew4OjpavBkaGirezM/PNzWWl5dbudA7MzNTvPnrr79a+bvVvg81V3Pb+owvLCw0NWouFddsFisuq9ZccF3x0EMPFW+uXLnSrAVPCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDRGazyOlen02na8Prrr1ft3n333eLNrl27ijfXr19v5RhXzfGz2kN1NQfxag6t1fzdaj97NUfnao4Q1mxq3u/a12rre1vzOmt10O3f9Z73+/3izeTkZFPjzJkzxZtjx46tyffCkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBA+UG8mmNmNQel2vTSSy8Vb95///1WDu9t2bKlqdHtlne+5mdbcxCv9shfjatXr7ZyRO/SpUutfS/u3LnT2hHCNt67xcXFqteamZlp5Xvx3XffFW/OnTvX1Dh58mTTBgfxACgiCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAED5QbxOp7OaP8a/yaOPPlq127FjR/Hm1q1bxZsHHnigePPbb781NWoOp50/f77qteBe5iAeAEVEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBcSQX4HzFwJRWAEqIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEMPNKg0Gg9X+UQD+S3lSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAoPk//wDGSdril0zApQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "04ac212b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0039,  0.0135,  0.0136,  0.0265,  0.0249,  0.0150, -0.0071,  0.0043,\n",
       "         -0.0383,  0.0096]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass image through model\n",
    "model_2(image.unsqueeze(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4dd05aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_image_tensor = torch.randn(size=(1, 1, 28, 28)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f8a02a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0098, -0.0218,  0.0137,  0.0146,  0.0285,  0.0176, -0.0169, -0.0015,\n",
       "         -0.0949,  0.0560]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass random tensor through model\n",
    "model_2(rand_image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646355a9",
   "metadata": {},
   "source": [
    "### 7.1 Stepping through `nn.Conv2d()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2b553f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([1, 28, 28])\n",
      "Test image shape: torch.Size([3, 64, 64])\n",
      "Test image: tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
      "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
      "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
      "         ...,\n",
      "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
      "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
      "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
      "\n",
      "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
      "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
      "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
      "         ...,\n",
      "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
      "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
      "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
      "\n",
      "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
      "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
      "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
      "         ...,\n",
      "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
      "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
      "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a batch of images\n",
    "images = torch.randn(size=(32, 3, 64, 64))\n",
    "test_image = images[0]\n",
    "\n",
    "print(f\"Image batch shape: {image.shape}\")\n",
    "print(f\"Test image shape: {test_image.shape}\")\n",
    "print(f\"Test image: {test_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "379b0d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3047,  1.4238,  0.9435,  ...,  0.3078,  0.4244, -0.3909],\n",
       "         [ 0.6132,  1.5396,  0.0516,  ...,  0.8711,  0.4256, -0.3416],\n",
       "         [ 1.0524,  0.3662,  1.0114,  ...,  0.2809, -0.2741,  0.3787],\n",
       "         ...,\n",
       "         [ 0.0377,  0.2981, -0.2432,  ..., -0.7283, -0.5767, -0.0783],\n",
       "         [-0.2693, -0.0386, -0.0781,  ...,  0.4228, -0.1802, -0.5140],\n",
       "         [ 0.5006, -0.5684,  0.1166,  ...,  0.5425, -0.3335,  0.7756]],\n",
       "\n",
       "        [[-0.1153,  0.5129, -0.7227,  ..., -0.6758,  0.4840, -0.8125],\n",
       "         [ 0.2266, -0.2840, -0.0319,  ...,  1.5599, -1.2449, -0.4410],\n",
       "         [-0.6666,  0.2753, -0.1262,  ...,  0.1999, -0.8856, -0.4292],\n",
       "         ...,\n",
       "         [-0.0647, -0.1984, -0.6386,  ..., -0.0585, -0.7833, -0.0764],\n",
       "         [ 0.2940, -0.6306, -0.2052,  ...,  0.2456, -0.7134,  0.7373],\n",
       "         [-0.1683, -0.8397,  0.2643,  ...,  0.2593, -0.5630,  0.1587]],\n",
       "\n",
       "        [[ 0.4864, -0.7476, -0.6414,  ...,  0.5477, -1.2156,  0.2989],\n",
       "         [-0.5791,  0.4414,  0.5100,  ...,  0.2638,  1.1258, -0.0662],\n",
       "         [ 0.6065,  0.8117,  0.3191,  ...,  0.2319,  0.5003,  0.0034],\n",
       "         ...,\n",
       "         [-0.7888,  0.2941,  0.4417,  ...,  0.4814, -0.4799,  0.6813],\n",
       "         [-0.2186,  0.6059, -0.0415,  ...,  0.2521, -0.4372, -0.9096],\n",
       "         [ 0.4489, -0.2549, -0.3202,  ..., -0.7820, -0.5369,  0.2537]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.5501,  0.9690,  1.2804,  ...,  0.2162,  0.6271,  0.3134],\n",
       "         [ 0.7574, -0.2560, -0.0477,  ...,  0.7553, -0.7055, -0.0276],\n",
       "         [-0.1636,  1.5595, -0.2209,  ...,  0.7754,  0.0750,  0.0063],\n",
       "         ...,\n",
       "         [-0.1605, -0.3486, -0.7173,  ...,  0.7219,  0.1513, -0.7218],\n",
       "         [ 0.5251,  0.0119,  0.1017,  ..., -0.8127, -0.1257,  0.4847],\n",
       "         [-0.6399,  0.1466, -0.2109,  ...,  0.7455, -0.6983,  0.1332]],\n",
       "\n",
       "        [[ 0.1910, -1.2740, -2.1166,  ..., -0.8778, -0.0292, -0.3584],\n",
       "         [-0.1359,  0.3841,  1.1322,  ...,  0.0109,  0.6058, -0.0432],\n",
       "         [ 0.7342,  0.1664,  0.1873,  ...,  0.9096, -0.5399, -0.2297],\n",
       "         ...,\n",
       "         [-0.0607,  0.0535,  0.4411,  ..., -1.0056,  0.3759,  0.2856],\n",
       "         [ 0.1089,  0.3031, -0.1590,  ..., -0.4271, -0.4876, -0.2490],\n",
       "         [ 0.4154,  0.0436,  0.3085,  ..., -0.1570, -0.7712, -0.3026]],\n",
       "\n",
       "        [[-0.1319, -0.2679, -0.4623,  ...,  0.4089, -0.7995,  0.0225],\n",
       "         [-1.2177, -1.1865, -0.7280,  ..., -0.0542, -1.5949,  0.3016],\n",
       "         [-0.5843, -0.6345, -0.5920,  ..., -0.7963, -0.0647,  0.1041],\n",
       "         ...,\n",
       "         [ 0.3001, -0.2609, -0.2328,  ..., -0.8436, -0.7524,  0.2401],\n",
       "         [-0.2574, -1.1399, -0.1751,  ...,  0.3377,  0.3493,  1.2920],\n",
       "         [-0.6151,  0.4477,  0.0631,  ..., -0.5504,  0.0327, -0.3162]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Create a single conv2d layer\n",
    "conv_layer = nn.Conv2d(\n",
    "    in_channels=3,\n",
    "    out_channels=10, \n",
    "    kernel_size=(3, 3),\n",
    "    stride=1,\n",
    "    padding=1,\n",
    ")\n",
    "\n",
    "# Pass the data through the convolutional layer\n",
    "conv_output = conv_layer(test_image)\n",
    "conv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91639700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 64, 64]), torch.Size([10, 64, 64]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape, conv_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05de532",
   "metadata": {},
   "source": [
    "### 7.2 Stepping through `nn.MaxPool2d()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65bc4d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
       "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
       "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
       "         ...,\n",
       "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
       "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
       "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
       "\n",
       "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
       "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
       "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
       "         ...,\n",
       "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
       "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
       "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
       "\n",
       "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
       "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
       "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
       "         ...,\n",
       "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
       "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
       "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f5c2e39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image original shape: torch.Size([3, 64, 64])\n",
      "Test image with unsqueezed dimenstion: torch.Size([1, 3, 64, 64])\n",
      "Shape after going through conv_layer(): torch.Size([1, 10, 64, 64])\n",
      "Shape after going thorugh conv_layer() and max_pool_layer(): torch.Size([1, 10, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Print out original image shape without unsqueezed dimension\n",
    "print(f\"Test image original shape: {test_image.shape}\")\n",
    "print(f\"Test image with unsqueezed dimenstion: {test_image.unsqueeze(0).shape}\")\n",
    "\n",
    "# Create a sample nn.MaxPool2d layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# Pass data through just the conv_layer\n",
    "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
    "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
    "\n",
    "# Pass data through max pool layer\n",
    "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
    "print(f\"Shape after going thorugh conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ff060525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor: tensor([[[[0.3367, 0.1288],\n",
      "          [0.2345, 0.2303]]]])\n",
      "Random tensor shape: torch.Size([1, 1, 2, 2])\n",
      "Max pool tensor: tensor([[[[0.3367]]]])\n",
      "Max pool tensor shape: torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Create a random tensor with a smiliar number of dimensions to our image\n",
    "random_tensor = torch.randn(size=(1, 1, 2, 2))\n",
    "print(f\"Random tensor: {random_tensor}\")\n",
    "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
    "\n",
    "# Create a max pool layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# Pass the random tensor thorugh the max pool layer\n",
    "max_pool_tensor = max_pool_layer(random_tensor)\n",
    "print(f\"Max pool tensor: {max_pool_tensor}\")\n",
    "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d5ef8",
   "metadata": {},
   "source": [
    "### 7.3 Setup a loss function, optimizer and evaluation metrics for `model_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f9086b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=model_2.parameters(),\n",
    "    lr=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "93d57db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CrossEntropyLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "18e5f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates when two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4b1253e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
       "                        [ 0.3062, -0.0730,  0.0673],\n",
       "                        [-0.1623,  0.1958,  0.2938]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2445,  0.2897,  0.0624],\n",
       "                        [ 0.2463,  0.0451,  0.1607],\n",
       "                        [-0.0471,  0.2570,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1556,  0.0850, -0.1536],\n",
       "                        [-0.0391, -0.1354,  0.2211],\n",
       "                        [-0.2631, -0.1537, -0.0941]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2004,  0.0315, -0.3292],\n",
       "                        [ 0.3010, -0.2832,  0.2573],\n",
       "                        [ 0.0555, -0.1082,  0.2060]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0520,  0.2693,  0.0364],\n",
       "                        [-0.1051,  0.0896, -0.0904],\n",
       "                        [ 0.1403,  0.2976,  0.1927]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1457,  0.1924,  0.0596],\n",
       "                        [ 0.1693, -0.2032, -0.3300],\n",
       "                        [-0.1288, -0.2557,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0960,  0.1381,  0.1054],\n",
       "                        [-0.0058,  0.2609, -0.2368],\n",
       "                        [ 0.0210, -0.2275,  0.1028]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1148,  0.1021, -0.0694],\n",
       "                        [ 0.2765, -0.1976, -0.1988],\n",
       "                        [-0.1988,  0.2998,  0.1111]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3208, -0.2751, -0.3306],\n",
       "                        [-0.2608, -0.2242,  0.1350],\n",
       "                        [ 0.1194,  0.2770, -0.1721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2272,  0.1769, -0.1347],\n",
       "                        [ 0.2023, -0.0791,  0.1907],\n",
       "                        [-0.2590, -0.1682,  0.1016]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0705, -0.0850,  0.1987],\n",
       "                        [ 0.2266, -0.2417, -0.1780],\n",
       "                        [ 0.3052, -0.1125, -0.1182]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3225, -0.1909,  0.0833],\n",
       "                        [-0.0440, -0.2420,  0.0078],\n",
       "                        [-0.2277, -0.2828, -0.1836]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2917, -0.2122,  0.3332],\n",
       "                        [ 0.0630,  0.1027, -0.3109],\n",
       "                        [-0.2189, -0.1110,  0.0521]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2933, -0.1436, -0.1996],\n",
       "                        [ 0.0009, -0.1240, -0.0231],\n",
       "                        [-0.2259, -0.2288, -0.1945]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1141, -0.2631,  0.2795],\n",
       "                        [-0.0662,  0.2868,  0.1039],\n",
       "                        [-0.2823,  0.2307, -0.0917]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1278, -0.2767, -0.3314],\n",
       "                        [ 0.0954, -0.0728,  0.1298],\n",
       "                        [-0.2736,  0.2475, -0.2447]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0576,  0.0696,  0.1721],\n",
       "                        [ 0.2691,  0.3037, -0.2643],\n",
       "                        [ 0.0839, -0.1434, -0.0365]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2495,  0.3036, -0.2447],\n",
       "                        [ 0.1782,  0.1171,  0.1083],\n",
       "                        [-0.1802,  0.3030,  0.0733]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0429, -0.2938,  0.1399],\n",
       "                        [-0.0500, -0.1527,  0.2863],\n",
       "                        [ 0.0743, -0.1844, -0.1687]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0159,  0.1861, -0.0852],\n",
       "                        [-0.1902, -0.1141, -0.2490],\n",
       "                        [ 0.1189,  0.2580, -0.3138]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0774,  0.1722,  0.0604],\n",
       "                        [-0.1187,  0.1740,  0.1752],\n",
       "                        [ 0.1246, -0.0586, -0.0883]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0357, -0.0589, -0.0993],\n",
       "                        [ 0.2131,  0.2865, -0.0330],\n",
       "                        [-0.0746,  0.0049, -0.0199]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0801,  0.0934, -0.3028],\n",
       "                        [-0.1230,  0.2807,  0.1299],\n",
       "                        [-0.0166, -0.2010, -0.2039]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2986, -0.1087,  0.1126],\n",
       "                        [ 0.2125,  0.1539, -0.2946],\n",
       "                        [-0.2005, -0.0526,  0.3224]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0482, -0.0863,  0.1379],\n",
       "                        [-0.1270, -0.2158,  0.2433],\n",
       "                        [-0.1516, -0.0668, -0.3316]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2231,  0.2525,  0.1215],\n",
       "                        [-0.2324, -0.3290, -0.2707],\n",
       "                        [ 0.2486,  0.1600,  0.2805]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1746,  0.0844, -0.0033],\n",
       "                        [-0.2535, -0.2856, -0.3118],\n",
       "                        [ 0.1365, -0.1637, -0.0671]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1918, -0.0607, -0.2346],\n",
       "                        [-0.2178,  0.1106, -0.0991],\n",
       "                        [ 0.2058, -0.1069, -0.2445]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0588, -0.1616, -0.1020],\n",
       "                        [-0.3173,  0.1865, -0.2321],\n",
       "                        [ 0.1675,  0.1513,  0.2381]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2557,  0.2397, -0.1576],\n",
       "                        [ 0.1237,  0.3130, -0.0470],\n",
       "                        [-0.0026, -0.0767, -0.2783]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1600, -0.3309,  0.2069],\n",
       "                        [ 0.2494,  0.3152, -0.0786],\n",
       "                        [-0.2739,  0.0749,  0.1841]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3318, -0.0757, -0.1998],\n",
       "                        [-0.0292, -0.1641, -0.1363],\n",
       "                        [-0.1058, -0.3168,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2794, -0.0523, -0.0380],\n",
       "                        [-0.1360, -0.3010, -0.3244],\n",
       "                        [ 0.1239, -0.1830, -0.2143]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0260, -0.1110, -0.1078],\n",
       "                        [ 0.0107, -0.0707, -0.1148],\n",
       "                        [-0.1596, -0.2713,  0.2795]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1334,  0.0883, -0.1157],\n",
       "                        [ 0.0271,  0.3108,  0.1536],\n",
       "                        [-0.2889,  0.1323,  0.3164]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0877,  0.2235,  0.3286],\n",
       "                        [-0.0511,  0.0692, -0.2317],\n",
       "                        [-0.0687,  0.2469,  0.1709]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2109, -0.2673, -0.2278],\n",
       "                        [-0.3290, -0.2572, -0.0824],\n",
       "                        [ 0.2250,  0.0558, -0.2535]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2674,  0.1658, -0.2479],\n",
       "                        [-0.0410,  0.1599, -0.1543],\n",
       "                        [-0.0363, -0.0290, -0.0789]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1690, -0.2971, -0.2695],\n",
       "                        [-0.1785,  0.3219, -0.1610],\n",
       "                        [-0.2238,  0.0808,  0.0919]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1826,  0.2534,  0.1856],\n",
       "                        [-0.3305,  0.0296,  0.2019],\n",
       "                        [-0.0308, -0.1964,  0.3178]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1247, -0.1898, -0.3005],\n",
       "                        [ 0.0149,  0.1477,  0.0738],\n",
       "                        [ 0.0659, -0.2528, -0.3113]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0059,  0.3039,  0.1923],\n",
       "                        [-0.1941, -0.0433, -0.2457],\n",
       "                        [-0.1608,  0.0604,  0.1815]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2761, -0.3060,  0.2229],\n",
       "                        [-0.2351,  0.1248,  0.2821],\n",
       "                        [ 0.0047,  0.3033, -0.2840]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1273,  0.1944, -0.0726],\n",
       "                        [-0.0682, -0.1389,  0.2298],\n",
       "                        [ 0.1635,  0.1068, -0.1873]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2706,  0.0361,  0.0988],\n",
       "                        [-0.1539, -0.0933,  0.2251],\n",
       "                        [ 0.0266,  0.0150, -0.0820]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3019, -0.3134, -0.1593],\n",
       "                        [-0.1694,  0.1039, -0.0970],\n",
       "                        [-0.1304,  0.3178,  0.1161]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2376, -0.1614, -0.1362],\n",
       "                        [ 0.1225, -0.2221, -0.2179],\n",
       "                        [-0.0161, -0.1219, -0.2499]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1977,  0.2681,  0.0541],\n",
       "                        [-0.0580, -0.3088, -0.1214],\n",
       "                        [ 0.0849,  0.1572, -0.0421]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1318,  0.1857, -0.2655],\n",
       "                        [ 0.2107, -0.1293,  0.0051],\n",
       "                        [-0.0659,  0.0404, -0.1007]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2424, -0.0087,  0.2602],\n",
       "                        [ 0.3205, -0.1624, -0.2432],\n",
       "                        [ 0.2674,  0.2612, -0.2545]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0258, -0.3287, -0.2729],\n",
       "                        [ 0.0644,  0.0887,  0.0707],\n",
       "                        [-0.0907,  0.3075,  0.0477]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1967, -0.0189,  0.0800],\n",
       "                        [ 0.1167, -0.2357,  0.1249],\n",
       "                        [-0.1703, -0.2770, -0.1821]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3215,  0.2850,  0.2985],\n",
       "                        [ 0.1957,  0.2518, -0.0446],\n",
       "                        [-0.1834,  0.1666, -0.1727]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2250, -0.1064,  0.0700],\n",
       "                        [ 0.1716, -0.1295, -0.1962],\n",
       "                        [ 0.0450, -0.1965, -0.2170]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1738, -0.0560,  0.3046],\n",
       "                        [ 0.3243,  0.0997,  0.1147],\n",
       "                        [ 0.0768,  0.0052, -0.0242]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0046,  0.1245,  0.3099],\n",
       "                        [-0.0864, -0.1409, -0.0807],\n",
       "                        [-0.1610,  0.0567,  0.2488]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2607,  0.1530, -0.2453],\n",
       "                        [-0.1789, -0.0732, -0.0614],\n",
       "                        [ 0.0274, -0.3060,  0.1037]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2543, -0.2109, -0.2771],\n",
       "                        [ 0.2904, -0.3156,  0.2515],\n",
       "                        [-0.0112, -0.0388,  0.2085]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0308,  0.2091,  0.2410],\n",
       "                        [-0.2894,  0.1283,  0.0629],\n",
       "                        [ 0.0717,  0.0487,  0.0912]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1604, -0.0426,  0.3167],\n",
       "                        [ 0.2239, -0.0125, -0.3135],\n",
       "                        [ 0.0146, -0.2270,  0.2711]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2024, -0.0241, -0.0740],\n",
       "                        [ 0.0593,  0.3137,  0.0317],\n",
       "                        [ 0.1931,  0.2587,  0.2691]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1151, -0.0746,  0.1606],\n",
       "                        [-0.0910,  0.1561, -0.0728],\n",
       "                        [-0.2261,  0.1357,  0.0511]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1486,  0.3312,  0.2276],\n",
       "                        [ 0.3160,  0.0178, -0.2867],\n",
       "                        [-0.2338, -0.2071, -0.2937]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1671, -0.3069, -0.3075],\n",
       "                        [-0.1992, -0.3286, -0.2046],\n",
       "                        [ 0.1271,  0.2780, -0.0992]]]])),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([-0.0970,  0.1780, -0.1645, -0.1576,  0.2054, -0.2904,  0.0408,  0.2945,\n",
       "                       0.0572,  0.0906, -0.1941, -0.0046,  0.0183,  0.0818,  0.1295,  0.2896,\n",
       "                      -0.2544,  0.0100, -0.1665, -0.2637, -0.0267, -0.2934,  0.2326,  0.0386,\n",
       "                      -0.1797,  0.1742, -0.3155, -0.1289, -0.0649, -0.2833, -0.2120, -0.0544,\n",
       "                       0.2529,  0.3219,  0.2121, -0.1990, -0.2181,  0.2909,  0.1179,  0.0089,\n",
       "                       0.0451, -0.2679, -0.1113,  0.3209, -0.0822, -0.0167, -0.2768, -0.1865,\n",
       "                      -0.0068, -0.2071, -0.0413,  0.1357, -0.3261,  0.0990, -0.2204, -0.1627,\n",
       "                       0.1280,  0.2650, -0.0911, -0.1369, -0.3014, -0.1719, -0.2919, -0.0763])),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[ 8.5023e-03, -3.9036e-02,  3.6380e-02],\n",
       "                        [ 2.6141e-02, -4.0789e-02, -1.9901e-02],\n",
       "                        [ 1.3590e-02, -8.5608e-03, -4.5407e-03]],\n",
       "              \n",
       "                       [[-1.8813e-02,  3.3467e-02, -2.3292e-02],\n",
       "                        [ 3.4553e-02,  2.6884e-03,  8.3759e-03],\n",
       "                        [ 3.2505e-02, -6.8652e-03, -2.3723e-02]],\n",
       "              \n",
       "                       [[-6.7389e-03,  3.3794e-02, -3.0916e-02],\n",
       "                        [ 9.4575e-03, -4.0950e-02,  2.1846e-02],\n",
       "                        [ 1.5394e-02,  1.7663e-03,  1.7883e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.7109e-02, -1.3818e-02,  3.3369e-02],\n",
       "                        [ 3.2898e-02, -3.1979e-02, -3.2176e-02],\n",
       "                        [-3.3711e-02, -2.2834e-02, -1.6220e-02]],\n",
       "              \n",
       "                       [[-3.1362e-03, -1.0133e-02, -2.1052e-02],\n",
       "                        [-1.3237e-02, -1.5073e-02,  4.0877e-02],\n",
       "                        [-1.5443e-02, -2.9833e-02,  1.7321e-02]],\n",
       "              \n",
       "                       [[-2.4067e-03,  3.1898e-02,  2.6035e-02],\n",
       "                        [ 3.8280e-02, -3.0515e-02,  2.6786e-02],\n",
       "                        [ 3.4968e-02, -2.0576e-02,  3.8299e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1235e-02,  4.5630e-04,  2.0090e-02],\n",
       "                        [-1.4568e-02, -3.6341e-02,  1.0533e-02],\n",
       "                        [ 1.2422e-02, -2.7232e-02,  2.0208e-02]],\n",
       "              \n",
       "                       [[-3.5593e-02,  3.5859e-02,  4.0350e-02],\n",
       "                        [ 1.1344e-02, -2.6143e-02,  2.0278e-02],\n",
       "                        [ 7.1007e-03,  1.1330e-02,  1.3694e-02]],\n",
       "              \n",
       "                       [[ 3.1723e-02, -1.7910e-02, -9.3727e-03],\n",
       "                        [ 1.1363e-02,  4.5400e-03,  3.3599e-02],\n",
       "                        [-2.1885e-02, -1.5174e-03,  7.7855e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3955e-02,  1.2650e-02,  2.9453e-02],\n",
       "                        [ 2.3210e-02,  2.3128e-02,  1.7286e-02],\n",
       "                        [-2.5843e-02, -3.3083e-02,  1.7272e-03]],\n",
       "              \n",
       "                       [[ 3.9566e-02,  2.3461e-03, -3.5837e-03],\n",
       "                        [-2.8281e-02, -2.0660e-02, -3.2119e-02],\n",
       "                        [ 3.3361e-02, -6.7887e-03, -3.6809e-02]],\n",
       "              \n",
       "                       [[ 4.4698e-03,  3.0237e-03, -5.1479e-03],\n",
       "                        [ 1.4915e-02,  2.2407e-02, -3.9184e-02],\n",
       "                        [-3.1920e-02, -2.0017e-03, -3.8631e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7848e-02,  3.6788e-02, -3.1691e-03],\n",
       "                        [-2.0600e-02, -1.4292e-02, -3.2530e-02],\n",
       "                        [ 3.2515e-02, -9.0350e-03, -2.3427e-02]],\n",
       "              \n",
       "                       [[-3.1601e-02,  2.4354e-02, -5.7596e-03],\n",
       "                        [-4.3774e-03, -1.0860e-02, -2.0113e-02],\n",
       "                        [ 7.4121e-03,  3.2057e-02, -2.4149e-02]],\n",
       "              \n",
       "                       [[ 1.9964e-03, -3.1688e-02, -1.9537e-02],\n",
       "                        [ 3.6574e-02,  4.3688e-04,  4.0138e-02],\n",
       "                        [-7.3002e-03, -2.2710e-02, -2.4895e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.5829e-03, -2.6362e-02, -1.4988e-02],\n",
       "                        [ 2.0355e-02,  1.3002e-02,  8.0982e-04],\n",
       "                        [-5.4990e-03, -1.6212e-02, -1.4789e-02]],\n",
       "              \n",
       "                       [[-2.1979e-02,  6.8276e-03,  1.1702e-02],\n",
       "                        [ 3.1906e-02, -9.4131e-03,  2.9829e-03],\n",
       "                        [ 2.6929e-02,  1.8125e-02,  5.3537e-03]],\n",
       "              \n",
       "                       [[ 1.2803e-02,  2.1628e-03, -3.5741e-02],\n",
       "                        [ 1.6063e-03, -9.1075e-03,  3.7600e-02],\n",
       "                        [ 3.7609e-02,  8.2663e-03,  3.7242e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2618e-02,  3.9587e-02,  2.8482e-02],\n",
       "                        [-5.4359e-03,  1.5041e-02,  2.4441e-02],\n",
       "                        [ 1.9579e-02,  2.0476e-02,  3.9186e-02]],\n",
       "              \n",
       "                       [[ 3.9588e-02, -2.7388e-02, -3.3195e-02],\n",
       "                        [ 4.1083e-02,  7.5012e-03, -4.1216e-02],\n",
       "                        [ 1.3478e-04,  2.9627e-02,  9.8274e-03]],\n",
       "              \n",
       "                       [[-1.9978e-02, -3.0172e-02, -1.9576e-02],\n",
       "                        [ 2.7986e-02,  8.0023e-03,  2.0627e-03],\n",
       "                        [ 7.8074e-03, -7.1615e-03, -1.6136e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0375e-02,  6.9525e-04, -3.1735e-02],\n",
       "                        [ 1.1574e-02, -3.6389e-02,  4.4459e-03],\n",
       "                        [ 1.8955e-02,  2.5098e-02, -3.7177e-03]],\n",
       "              \n",
       "                       [[ 1.5228e-02,  1.8052e-02,  3.4076e-02],\n",
       "                        [ 4.1627e-02,  3.8341e-02, -2.6043e-02],\n",
       "                        [ 4.3324e-03, -4.0594e-02,  1.9444e-02]],\n",
       "              \n",
       "                       [[ 2.4304e-02,  2.1029e-02,  9.1496e-03],\n",
       "                        [-3.4941e-02, -1.2763e-02,  1.4329e-02],\n",
       "                        [ 4.1014e-02, -1.5737e-02, -5.2657e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1093e-02, -1.0547e-02,  7.0954e-03],\n",
       "                        [-1.0236e-02, -4.0989e-02,  1.8355e-02],\n",
       "                        [-3.1597e-03,  3.3019e-02,  4.3857e-03]],\n",
       "              \n",
       "                       [[-1.0679e-02,  3.3458e-03, -2.3569e-02],\n",
       "                        [ 1.8621e-02,  2.7323e-02, -1.0628e-02],\n",
       "                        [-4.0083e-02, -2.1794e-02, -7.9042e-03]],\n",
       "              \n",
       "                       [[ 3.4101e-02, -2.0153e-03,  2.6396e-02],\n",
       "                        [-6.1488e-03, -5.3689e-03,  2.2041e-02],\n",
       "                        [-3.7100e-02, -8.7438e-03,  3.8674e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7265e-02, -3.2861e-02,  4.6981e-03],\n",
       "                        [ 3.4216e-02,  3.9015e-02,  4.0265e-02],\n",
       "                        [-8.6789e-03, -4.0848e-02, -1.2984e-02]],\n",
       "              \n",
       "                       [[-8.6611e-03, -1.9641e-02,  1.6065e-02],\n",
       "                        [ 4.0355e-02, -1.6203e-02,  3.9391e-02],\n",
       "                        [-4.1644e-02, -2.0914e-02,  2.8773e-02]],\n",
       "              \n",
       "                       [[ 1.2368e-02,  2.5640e-02, -2.9640e-02],\n",
       "                        [-1.9302e-02, -8.4299e-03,  3.8824e-02],\n",
       "                        [-4.1322e-02,  1.3150e-02,  2.8180e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0320e-02,  2.4757e-02, -2.9215e-03],\n",
       "                        [ 8.6763e-03, -9.2422e-05, -2.2259e-02],\n",
       "                        [ 2.6174e-02, -4.0824e-02, -5.7563e-03]],\n",
       "              \n",
       "                       [[ 3.4654e-02, -3.0853e-02, -1.5151e-02],\n",
       "                        [-2.4016e-03,  4.1192e-02,  3.3371e-02],\n",
       "                        [ 2.3558e-02,  1.5365e-02, -5.2623e-03]],\n",
       "              \n",
       "                       [[ 3.6297e-02, -1.5542e-02,  2.2486e-02],\n",
       "                        [-2.5857e-02,  2.8871e-04, -2.4330e-02],\n",
       "                        [ 3.7076e-02, -1.9306e-02, -3.7589e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.0509e-02, -1.5718e-02, -3.3647e-02],\n",
       "                        [ 3.0954e-02, -1.9008e-02, -2.5973e-02],\n",
       "                        [-1.7578e-02,  1.5535e-02, -3.1302e-03]],\n",
       "              \n",
       "                       [[ 1.9000e-02, -2.5173e-02,  2.6224e-03],\n",
       "                        [ 2.7723e-02, -1.1576e-02, -1.0791e-02],\n",
       "                        [-4.1244e-02,  3.9085e-02, -2.1472e-02]],\n",
       "              \n",
       "                       [[ 1.2346e-03, -2.8055e-02, -2.7353e-02],\n",
       "                        [ 3.1625e-02, -3.6325e-02,  3.8031e-02],\n",
       "                        [-4.1584e-02,  1.6012e-02,  2.3511e-02]]]])),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([ 9.0847e-05,  2.5891e-02, -2.3368e-02,  6.3847e-03,  7.1218e-03,\n",
       "                       3.5592e-04,  1.3226e-02,  2.5787e-02, -1.9929e-02,  9.5518e-03,\n",
       "                      -6.6952e-03, -4.2011e-03, -2.3976e-02, -2.7578e-02,  3.1207e-02,\n",
       "                      -2.6910e-02,  5.2050e-04,  4.1228e-02,  3.4886e-02, -3.8900e-02,\n",
       "                      -1.4289e-02,  1.8171e-02,  4.0508e-02, -2.8313e-03, -1.2693e-02,\n",
       "                      -3.3640e-02,  1.2786e-02, -4.4438e-03, -2.2675e-02, -4.1230e-02,\n",
       "                       3.2383e-03,  3.7075e-02, -1.0657e-02,  8.9271e-03,  3.9278e-02,\n",
       "                       1.5077e-02, -1.8619e-02, -8.8753e-03,  2.6845e-02, -2.2166e-02,\n",
       "                       2.2572e-02,  3.0506e-02, -1.1271e-02,  1.6040e-02,  3.4909e-02,\n",
       "                       3.0645e-02,  3.5019e-02, -4.4885e-03,  3.6656e-02,  3.6369e-05,\n",
       "                       4.0846e-03,  1.3903e-02,  3.8663e-02,  2.9773e-02, -2.5760e-03,\n",
       "                       1.0741e-02, -3.6126e-02,  3.0707e-02, -1.8744e-02, -3.0451e-03,\n",
       "                       2.4368e-03, -9.5675e-03, -1.6627e-02,  1.4533e-02])),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[ 3.1910e-02, -3.2848e-02,  9.5516e-03],\n",
       "                        [-4.4873e-04,  3.3748e-02, -3.6712e-02],\n",
       "                        [-1.3876e-02, -2.1981e-02, -2.4157e-02]],\n",
       "              \n",
       "                       [[ 2.7730e-02,  3.7077e-02,  1.2620e-02],\n",
       "                        [-1.8727e-02, -3.1942e-02,  3.9209e-02],\n",
       "                        [-7.9318e-03,  1.3155e-03,  4.0499e-02]],\n",
       "              \n",
       "                       [[ 2.1127e-02,  1.9560e-02, -7.4941e-03],\n",
       "                        [-1.0475e-02,  1.3797e-02, -3.4478e-03],\n",
       "                        [-3.0463e-02,  5.5212e-03,  3.0433e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0935e-02,  2.0315e-03, -4.2959e-03],\n",
       "                        [-1.7220e-02, -3.8043e-02,  2.9584e-02],\n",
       "                        [-3.1002e-02,  3.8086e-02, -1.3840e-02]],\n",
       "              \n",
       "                       [[ 1.4430e-02,  1.6541e-02, -6.4465e-03],\n",
       "                        [-2.2216e-02, -2.5019e-02,  3.7312e-02],\n",
       "                        [-3.8132e-02,  3.8330e-02, -1.5217e-02]],\n",
       "              \n",
       "                       [[ 2.6450e-02, -3.3631e-02, -2.2238e-03],\n",
       "                        [-2.0135e-02, -2.2752e-02,  1.5309e-02],\n",
       "                        [ 2.8209e-02, -3.0802e-02,  1.9868e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4686e-02,  2.0201e-02,  1.8373e-02],\n",
       "                        [ 2.2562e-02,  3.0670e-02,  1.3784e-02],\n",
       "                        [ 4.0531e-02,  7.8252e-03,  3.5044e-02]],\n",
       "              \n",
       "                       [[ 8.1924e-03,  9.4392e-03, -2.6535e-02],\n",
       "                        [-7.4502e-03,  1.1046e-02, -1.5136e-02],\n",
       "                        [ 1.7911e-02,  1.1463e-02, -1.8678e-02]],\n",
       "              \n",
       "                       [[-2.5026e-02,  1.9379e-02, -2.9333e-02],\n",
       "                        [ 1.5225e-02, -2.5932e-02, -3.6305e-02],\n",
       "                        [ 3.9463e-04, -6.5788e-03,  1.5304e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.1674e-02, -1.4163e-02, -2.8950e-02],\n",
       "                        [-6.3934e-03,  4.0294e-02, -1.7318e-02],\n",
       "                        [-2.9730e-02,  2.6562e-02, -2.8178e-03]],\n",
       "              \n",
       "                       [[-1.1829e-02,  2.6450e-02,  1.8236e-02],\n",
       "                        [ 1.3908e-02,  4.0041e-02, -3.6238e-02],\n",
       "                        [-1.4448e-02,  2.8864e-02, -3.5131e-02]],\n",
       "              \n",
       "                       [[-6.7065e-03,  1.3898e-02,  2.7654e-03],\n",
       "                        [ 8.4024e-03, -2.2597e-02,  1.2679e-02],\n",
       "                        [-2.7544e-02,  5.6325e-03, -5.5737e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2265e-02, -3.8480e-02, -2.9502e-02],\n",
       "                        [ 3.6201e-02,  4.0974e-02, -1.3109e-03],\n",
       "                        [ 2.8793e-02, -6.4691e-03,  3.8095e-02]],\n",
       "              \n",
       "                       [[-2.2552e-02, -2.0356e-02,  5.6621e-03],\n",
       "                        [-1.8578e-02,  2.6818e-02, -1.3832e-02],\n",
       "                        [ 2.8520e-02, -3.5390e-02, -2.4937e-02]],\n",
       "              \n",
       "                       [[-1.9489e-02,  1.1220e-02,  4.1499e-02],\n",
       "                        [ 1.8125e-02, -3.3504e-02, -4.1035e-02],\n",
       "                        [ 1.7787e-02,  2.2540e-02,  3.0814e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5349e-02,  1.9931e-02,  6.4072e-03],\n",
       "                        [-1.2137e-02,  8.0979e-03,  3.6041e-02],\n",
       "                        [-3.8224e-02,  2.6205e-02,  3.5017e-02]],\n",
       "              \n",
       "                       [[-2.7625e-02, -3.5976e-02,  3.1929e-03],\n",
       "                        [-3.0114e-02, -1.4216e-03,  3.9176e-04],\n",
       "                        [ 3.1196e-02,  1.6583e-03,  2.2340e-02]],\n",
       "              \n",
       "                       [[-2.7324e-02,  5.6466e-04,  7.4617e-03],\n",
       "                        [ 8.0264e-03, -2.7509e-04,  1.8569e-02],\n",
       "                        [-2.1862e-03, -9.5959e-03,  4.8516e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.6428e-02,  7.7831e-03, -7.9487e-03],\n",
       "                        [-2.9455e-02, -1.2260e-02,  1.4773e-02],\n",
       "                        [-3.8072e-03,  6.1168e-03, -1.6666e-02]],\n",
       "              \n",
       "                       [[ 1.4565e-02,  1.1431e-02, -4.1570e-02],\n",
       "                        [-6.9259e-03,  2.5407e-02,  3.8652e-02],\n",
       "                        [-3.7741e-02, -2.8172e-02, -1.8796e-02]],\n",
       "              \n",
       "                       [[ 2.7815e-02, -2.8695e-04,  2.1634e-02],\n",
       "                        [ 3.1182e-02,  1.5805e-02, -1.1073e-02],\n",
       "                        [-2.7733e-02,  6.1772e-03,  4.1231e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.5843e-02, -2.0484e-02,  3.8513e-02],\n",
       "                        [-2.9233e-02,  3.3069e-02, -1.4078e-02],\n",
       "                        [-1.9605e-02,  1.1142e-02,  8.6142e-03]],\n",
       "              \n",
       "                       [[-3.5445e-02, -2.8879e-02,  2.3224e-02],\n",
       "                        [ 1.6839e-03,  2.1050e-03, -3.1040e-02],\n",
       "                        [ 2.8721e-02,  3.4392e-02,  2.8083e-02]],\n",
       "              \n",
       "                       [[-3.4567e-02, -3.3603e-02,  3.1216e-02],\n",
       "                        [-2.1829e-02, -3.5123e-02,  4.0063e-02],\n",
       "                        [-2.6286e-05, -4.3368e-03, -1.1368e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7842e-02,  3.8080e-02, -9.3195e-03],\n",
       "                        [-3.7552e-02,  1.5182e-02, -2.4414e-02],\n",
       "                        [ 1.7873e-02, -3.3778e-02,  7.5908e-03]],\n",
       "              \n",
       "                       [[ 2.8927e-02, -4.0837e-02,  4.1257e-02],\n",
       "                        [ 9.8228e-03,  1.9113e-02,  1.9043e-02],\n",
       "                        [ 1.1066e-02, -7.1698e-03, -3.4172e-02]],\n",
       "              \n",
       "                       [[-2.3268e-02,  8.7166e-03,  4.0021e-02],\n",
       "                        [ 3.8777e-02, -3.3061e-02, -3.3383e-02],\n",
       "                        [ 1.1288e-02,  1.0928e-02,  1.2726e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4935e-02, -3.9596e-02, -1.6346e-02],\n",
       "                        [ 1.9340e-02, -3.0740e-02, -1.7099e-02],\n",
       "                        [-5.1803e-03, -3.5737e-02,  3.1534e-02]],\n",
       "              \n",
       "                       [[-3.3333e-02,  3.6033e-02, -1.8603e-02],\n",
       "                        [-5.7044e-03, -4.0464e-02,  1.8373e-02],\n",
       "                        [-4.0819e-02,  9.3790e-04, -3.0480e-02]],\n",
       "              \n",
       "                       [[ 1.9697e-02, -2.5363e-02, -1.4677e-02],\n",
       "                        [ 6.7424e-03, -1.0397e-02, -7.2310e-04],\n",
       "                        [ 3.9954e-02, -6.3340e-03,  2.0991e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5884e-02,  2.1334e-03,  3.5633e-02],\n",
       "                        [ 7.0019e-03, -2.7289e-02,  3.8748e-02],\n",
       "                        [ 4.2007e-04, -3.2663e-02, -1.7207e-02]],\n",
       "              \n",
       "                       [[ 3.9111e-02, -7.5806e-03,  3.8611e-02],\n",
       "                        [-4.9263e-03,  2.7333e-02, -2.2957e-03],\n",
       "                        [ 3.8859e-02, -3.9516e-02, -3.2021e-02]],\n",
       "              \n",
       "                       [[ 2.7594e-02, -1.7171e-02,  1.9187e-02],\n",
       "                        [-1.3822e-03,  1.3699e-02, -5.6093e-03],\n",
       "                        [ 1.5500e-02, -1.9500e-02, -1.0040e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2561e-02,  2.7615e-02,  3.3339e-02],\n",
       "                        [ 1.5528e-02,  2.4173e-02,  1.5674e-02],\n",
       "                        [ 3.0512e-02, -2.5878e-02,  3.0907e-02]],\n",
       "              \n",
       "                       [[ 8.6045e-03, -4.0935e-02,  7.7411e-03],\n",
       "                        [-3.6223e-02, -3.4765e-02, -8.2832e-03],\n",
       "                        [-2.1089e-02, -3.0889e-02,  1.9907e-02]],\n",
       "              \n",
       "                       [[ 5.8768e-03, -2.3039e-03, -2.6287e-02],\n",
       "                        [ 2.6876e-02, -3.3819e-02,  2.5457e-02],\n",
       "                        [-3.8271e-02, -3.7971e-02,  3.5857e-04]]]])),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([-0.0088,  0.0032,  0.0308,  0.0024, -0.0072, -0.0414, -0.0201, -0.0236,\n",
       "                      -0.0117, -0.0290,  0.0276,  0.0228, -0.0417,  0.0377,  0.0026, -0.0348,\n",
       "                      -0.0155, -0.0319,  0.0147,  0.0389,  0.0291, -0.0040, -0.0407, -0.0321,\n",
       "                      -0.0240,  0.0331,  0.0188, -0.0065,  0.0152, -0.0410, -0.0224, -0.0274,\n",
       "                      -0.0408,  0.0236, -0.0383,  0.0379, -0.0392,  0.0385,  0.0070,  0.0211,\n",
       "                       0.0151, -0.0182,  0.0051, -0.0038, -0.0062, -0.0351, -0.0069,  0.0029,\n",
       "                      -0.0033, -0.0131, -0.0338, -0.0406,  0.0221, -0.0028,  0.0256, -0.0389,\n",
       "                       0.0191,  0.0280,  0.0405,  0.0138,  0.0183, -0.0352,  0.0365,  0.0274])),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[-2.1017e-02, -3.5335e-02, -2.8480e-02],\n",
       "                        [ 1.7076e-02, -1.3883e-02,  3.3149e-02],\n",
       "                        [-3.5954e-03,  1.7017e-02,  1.9920e-02]],\n",
       "              \n",
       "                       [[-1.5928e-02,  1.6098e-03,  4.8292e-03],\n",
       "                        [-1.8223e-02,  6.1994e-03, -1.5510e-02],\n",
       "                        [ 1.8061e-02, -1.6157e-02,  3.2949e-02]],\n",
       "              \n",
       "                       [[-3.5137e-03,  2.0327e-02,  3.4042e-02],\n",
       "                        [-2.9430e-02,  6.5710e-03, -1.9893e-02],\n",
       "                        [ 1.9760e-02, -3.6740e-02, -9.0440e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.8103e-02, -2.5094e-02,  3.0498e-02],\n",
       "                        [ 2.7903e-02,  4.7300e-04,  2.2405e-02],\n",
       "                        [-2.6271e-02, -2.9426e-02, -1.1048e-02]],\n",
       "              \n",
       "                       [[ 1.4922e-02,  4.0363e-02, -1.1502e-02],\n",
       "                        [ 3.6142e-02, -3.9633e-02,  2.5873e-03],\n",
       "                        [ 3.6207e-02,  2.0476e-03,  2.1808e-02]],\n",
       "              \n",
       "                       [[ 4.0563e-02,  4.1270e-02, -1.6726e-02],\n",
       "                        [ 5.2780e-03, -3.3864e-02,  2.2999e-02],\n",
       "                        [-1.0359e-02, -3.2083e-02,  2.6485e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1822e-05, -1.0279e-02,  4.0615e-02],\n",
       "                        [-2.8767e-02, -2.0963e-03, -2.4596e-02],\n",
       "                        [-1.4965e-02,  1.7836e-02,  1.4207e-02]],\n",
       "              \n",
       "                       [[-1.9758e-03,  3.9463e-02,  1.5389e-02],\n",
       "                        [-7.8478e-04,  1.8823e-02,  3.1764e-03],\n",
       "                        [-6.3115e-03, -3.7202e-02, -4.0705e-02]],\n",
       "              \n",
       "                       [[-2.2483e-02, -2.2157e-02,  1.9258e-02],\n",
       "                        [-2.1018e-02, -8.4229e-03, -3.3295e-02],\n",
       "                        [-2.9104e-02,  2.1384e-02, -6.0182e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.0224e-02,  3.2869e-02,  2.5692e-02],\n",
       "                        [-2.3724e-02, -3.2912e-02, -1.5425e-02],\n",
       "                        [-2.6718e-02,  3.7049e-02, -3.4890e-02]],\n",
       "              \n",
       "                       [[ 2.4102e-02,  6.6242e-03, -3.0949e-03],\n",
       "                        [-7.3521e-03,  8.6873e-03, -3.9584e-02],\n",
       "                        [-1.3819e-02, -7.4826e-03,  3.0524e-02]],\n",
       "              \n",
       "                       [[ 2.9374e-02, -3.3689e-02,  1.6543e-02],\n",
       "                        [-1.9728e-02, -2.2857e-02,  2.7891e-02],\n",
       "                        [ 2.6887e-02, -3.0726e-02,  3.4567e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6582e-02, -3.0535e-02, -1.3413e-02],\n",
       "                        [ 3.5135e-03, -4.1621e-02, -1.7668e-02],\n",
       "                        [-3.2877e-04, -2.0942e-02,  1.0872e-02]],\n",
       "              \n",
       "                       [[ 3.9716e-02, -1.3830e-02,  3.1586e-02],\n",
       "                        [ 3.7944e-02, -3.0051e-02,  1.5819e-02],\n",
       "                        [ 1.7107e-02,  2.2688e-02,  1.0612e-02]],\n",
       "              \n",
       "                       [[ 7.2405e-03,  1.4096e-03,  3.3200e-02],\n",
       "                        [ 3.5867e-02,  5.4511e-03,  1.8506e-02],\n",
       "                        [ 2.2153e-05, -1.0606e-02, -4.1512e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5429e-02, -1.1699e-02,  8.7095e-03],\n",
       "                        [ 1.5588e-02,  1.0116e-02, -3.6282e-02],\n",
       "                        [ 3.9972e-02, -6.5425e-03,  1.2105e-03]],\n",
       "              \n",
       "                       [[-1.2325e-03,  4.8485e-03,  9.8713e-03],\n",
       "                        [ 1.0377e-02, -7.4177e-03, -3.8501e-02],\n",
       "                        [ 2.8388e-02,  2.9139e-02,  2.8442e-02]],\n",
       "              \n",
       "                       [[-1.2442e-02,  1.1418e-03,  2.2785e-02],\n",
       "                        [ 3.7177e-02, -6.9256e-03,  2.2093e-02],\n",
       "                        [ 2.6676e-02, -6.3043e-03,  1.1570e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8812e-02,  4.0114e-02,  1.5814e-02],\n",
       "                        [-3.0045e-02, -3.8309e-02,  1.7351e-03],\n",
       "                        [-3.8679e-02, -2.1344e-02, -4.0922e-02]],\n",
       "              \n",
       "                       [[ 2.6271e-02,  3.8746e-02,  3.9324e-02],\n",
       "                        [-3.4399e-02, -2.8773e-02, -3.6070e-02],\n",
       "                        [ 2.1578e-02, -3.6404e-02,  2.7079e-02]],\n",
       "              \n",
       "                       [[-3.0730e-02,  1.5001e-02, -2.6270e-02],\n",
       "                        [-2.1184e-02,  7.5104e-03,  2.9882e-03],\n",
       "                        [ 3.8464e-02, -4.3308e-03, -4.4553e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0412e-02,  3.2506e-04, -3.5784e-04],\n",
       "                        [ 3.8607e-02, -9.5099e-05, -3.6400e-02],\n",
       "                        [ 8.7995e-03, -3.8761e-02, -2.6274e-02]],\n",
       "              \n",
       "                       [[-2.3797e-04,  1.0472e-02,  2.2547e-02],\n",
       "                        [ 3.0464e-02, -2.8205e-02, -3.1154e-02],\n",
       "                        [-2.8705e-02, -3.5155e-02, -2.0799e-02]],\n",
       "              \n",
       "                       [[ 2.0347e-02,  8.3963e-03, -9.1840e-03],\n",
       "                        [-3.0716e-02,  3.4869e-02,  2.0462e-02],\n",
       "                        [-2.9291e-02, -3.8725e-02,  3.6097e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2176e-02,  6.9862e-04,  3.1173e-02],\n",
       "                        [-1.6254e-02,  9.9380e-03,  3.1266e-02],\n",
       "                        [ 1.8702e-02, -4.3708e-03,  2.4939e-02]],\n",
       "              \n",
       "                       [[ 1.2939e-02, -3.2330e-02,  7.6407e-03],\n",
       "                        [ 2.1844e-02, -4.5565e-03,  1.3290e-03],\n",
       "                        [-3.3729e-02, -2.7077e-03,  1.3173e-02]],\n",
       "              \n",
       "                       [[-1.7363e-02,  7.5263e-03, -3.9267e-02],\n",
       "                        [-2.4051e-02,  1.1300e-03,  1.4903e-02],\n",
       "                        [ 1.1658e-02, -2.8341e-02, -1.6960e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.3755e-02,  1.5810e-02,  2.0095e-02],\n",
       "                        [ 1.5301e-02,  2.5452e-02,  1.5152e-02],\n",
       "                        [-2.1844e-02, -1.0241e-02, -2.4060e-02]],\n",
       "              \n",
       "                       [[ 1.0219e-03,  1.4436e-02, -3.4319e-02],\n",
       "                        [ 3.7161e-02,  1.3391e-02, -3.3624e-02],\n",
       "                        [-1.7592e-02,  1.1442e-02, -1.7463e-02]],\n",
       "              \n",
       "                       [[-2.5999e-03,  1.8629e-02, -2.8454e-02],\n",
       "                        [ 3.7902e-03,  3.9019e-02,  1.7860e-02],\n",
       "                        [-1.2809e-02,  3.1236e-02, -1.5560e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6021e-02, -3.9979e-02, -2.1011e-02],\n",
       "                        [ 3.6725e-02, -1.7328e-02, -4.0903e-02],\n",
       "                        [-9.8103e-03,  3.7195e-02,  4.7391e-03]],\n",
       "              \n",
       "                       [[-9.8618e-03,  2.7650e-02, -2.3053e-02],\n",
       "                        [-2.7706e-02,  3.7233e-02,  2.6299e-02],\n",
       "                        [ 3.7443e-02, -5.0265e-03, -6.4160e-03]],\n",
       "              \n",
       "                       [[ 2.7300e-03, -3.0900e-02,  3.6899e-02],\n",
       "                        [ 1.3088e-02,  4.0681e-02,  4.0560e-02],\n",
       "                        [ 3.8683e-02,  1.4937e-02, -3.0374e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0578e-02, -1.5477e-02, -1.8110e-02],\n",
       "                        [ 2.2629e-02, -1.7647e-02, -3.6245e-02],\n",
       "                        [ 2.6330e-02, -2.1013e-02, -2.4607e-02]],\n",
       "              \n",
       "                       [[ 6.3182e-03, -7.7657e-03, -2.2914e-02],\n",
       "                        [-2.2714e-02, -1.6982e-02, -1.6545e-02],\n",
       "                        [ 1.4326e-02, -3.4815e-02, -3.0689e-02]],\n",
       "              \n",
       "                       [[-3.0622e-03,  5.1370e-03, -2.8103e-02],\n",
       "                        [ 3.5835e-02,  3.8342e-02,  2.0835e-02],\n",
       "                        [ 2.2112e-03, -9.6501e-03,  8.7862e-03]]]])),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([ 0.0322, -0.0182, -0.0228, -0.0033, -0.0227, -0.0266, -0.0181, -0.0150,\n",
       "                      -0.0401, -0.0015, -0.0128, -0.0283, -0.0290, -0.0265,  0.0084,  0.0017,\n",
       "                      -0.0066, -0.0231,  0.0082, -0.0346,  0.0396,  0.0183,  0.0097, -0.0211,\n",
       "                      -0.0223,  0.0157,  0.0032, -0.0169, -0.0395,  0.0201, -0.0139,  0.0247,\n",
       "                      -0.0380, -0.0004,  0.0040, -0.0295, -0.0089,  0.0015, -0.0314, -0.0075,\n",
       "                      -0.0394,  0.0107, -0.0216, -0.0059, -0.0263, -0.0145, -0.0103, -0.0033,\n",
       "                      -0.0280, -0.0364,  0.0078,  0.0077, -0.0397,  0.0149,  0.0011,  0.0265,\n",
       "                       0.0372,  0.0009,  0.0210,  0.0098,  0.0245, -0.0200,  0.0027, -0.0354])),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[ 5.7847e-03,  9.9525e-03,  1.6296e-02,  ..., -1.2392e-02,\n",
       "                       -1.2653e-02,  6.5333e-03],\n",
       "                      [ 7.0026e-03, -6.4349e-03, -7.9245e-03,  ..., -1.1731e-02,\n",
       "                       -5.0630e-03, -6.3898e-03],\n",
       "                      [-1.2785e-02, -1.5970e-02, -3.5421e-03,  ..., -4.6852e-03,\n",
       "                        1.3445e-02, -1.3492e-03],\n",
       "                      ...,\n",
       "                      [-3.4761e-03,  8.4854e-04,  1.6511e-03,  ..., -2.3702e-03,\n",
       "                        2.5682e-03,  7.9956e-03],\n",
       "                      [-4.8109e-03, -2.4473e-03,  3.4554e-03,  ...,  3.0139e-05,\n",
       "                       -3.1828e-03, -1.0805e-02],\n",
       "                      [-8.3341e-03,  4.6190e-03,  4.4081e-03,  ..., -1.7294e-02,\n",
       "                       -1.1829e-02, -4.7307e-03]])),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([ 0.0081,  0.0077,  0.0033,  0.0090, -0.0053,  0.0073, -0.0082,  0.0176,\n",
       "                      -0.0111, -0.0106]))])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6400cb",
   "metadata": {},
   "source": [
    "### 7.4 Training and testing `model_2` using our training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4637143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f778a23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c3827af77e4bdab88c67d69fc55e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "\n",
      "Train loss: 0.2248 | Train acc: 91.9583%\n",
      "Test loss: 0.2415 | Test acc: 91.3538%\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Train loss: 0.2034 | Train acc: 92.7350%\n",
      "Test loss: 0.2415 | Test acc: 91.2440%\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Train loss: 0.1887 | Train acc: 93.1583%\n",
      "Test loss: 0.2474 | Test acc: 91.4736%\n",
      "Train time on mps: 76.306 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "start_time = timer()\n",
    "\n",
    "# Train and test model\n",
    "epoch = 3\n",
    "\n",
    "for epoch in tqdm(range(epoch)):\n",
    "    print(f\"\\nEpoch: {epoch}\\n\")\n",
    "    \n",
    "    train_step(\n",
    "        model=model_2,\n",
    "        data_loader=train_data_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    test_step(\n",
    "        model=model_2,\n",
    "        data_loader=test_data_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "# Measure time\n",
    "end_time = timer()\n",
    "\n",
    "total_train_time_model_2 = print_train_time(\n",
    "    start=start_time,\n",
    "    end=end_time,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a76756e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8b194d52ac40ad9d69e4f8357fb116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV2',\n",
       " 'model_loss': tensor(0.1653, device='mps:0'),\n",
       " 'model_acc': 94.015}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model_2 results\n",
    "model_2_results = eval_model(\n",
    "    model=model_2,\n",
    "    data_loader=train_data_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn,\n",
    "    device=device,\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e95e6",
   "metadata": {},
   "source": [
    "## 8. Compare model results and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f9eb657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModelV0</td>\n",
       "      <td>tensor(0.4782)</td>\n",
       "      <td>83.486422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>tensor(0.6557)</td>\n",
       "      <td>79.852236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>tensor(0.1653, device='mps:0')</td>\n",
       "      <td>94.015000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name                      model_loss  model_acc\n",
       "0  FashionMNISTModelV0                  tensor(0.4782)  83.486422\n",
       "1  FashionMNISTModelV1                  tensor(0.6557)  79.852236\n",
       "2  FashionMNISTModelV2  tensor(0.1653, device='mps:0')  94.015000"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "compare_results = pd.DataFrame(\n",
    "    [model_0_results, model_1_results, model_2_results]\n",
    ")\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f7d71089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModelV0</td>\n",
       "      <td>tensor(0.4782)</td>\n",
       "      <td>83.486422</td>\n",
       "      <td>7.397986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>tensor(0.6557)</td>\n",
       "      <td>79.852236</td>\n",
       "      <td>10.910964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>tensor(0.1653, device='mps:0')</td>\n",
       "      <td>94.015000</td>\n",
       "      <td>76.306189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name                      model_loss  model_acc  \\\n",
       "0  FashionMNISTModelV0                  tensor(0.4782)  83.486422   \n",
       "1  FashionMNISTModelV1                  tensor(0.6557)  79.852236   \n",
       "2  FashionMNISTModelV2  tensor(0.1653, device='mps:0')  94.015000   \n",
       "\n",
       "   training_time  \n",
       "0       7.397986  \n",
       "1      10.910964  \n",
       "2      76.306189  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add training time to results comparison\n",
    "compare_results[\"training_time\"] = [\n",
    "    total_train_time_model_0, total_train_time_model_1, total_train_time_model_2\n",
    "]\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "02b7e931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'model')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize our model results\n",
    "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
    "plt.xlabel(\"accuracy (%)\")\n",
    "plt.ylabel(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f02d90",
   "metadata": {},
   "source": [
    "## 9. Make and evaluate random predictions with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ce700ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(\n",
    "    model: torch.nn.Module,\n",
    "    data: list,\n",
    "    device: torch.device = \"cpu\"\n",
    "):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # Prepare the sample (add a batch dimension and pass to target device)\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device)\n",
    "            \n",
    "            # Forward pass (model outputs raw logits)\n",
    "            pred_logit = model(sample)\n",
    "            \n",
    "            # Get prediction probability (logit -> pred probabilities)\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
    "            \n",
    "            # Get pred_prob off the GPU for futher calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "        \n",
    "    # Stack the preb_probs to trun list into a tensor\n",
    "    return torch.stack(pred_probs)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "796c869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# View the first sample shape\n",
    "test_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "57b65939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_samples[0].squeeze(), cmap=\"grey\")\n",
    "plt.title(class_names[test_labels[0]])\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c0171482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.7249e-10, 4.0685e-12, 2.2187e-10, 1.2076e-13, 2.1919e-12, 1.0000e+00,\n",
       "         4.3108e-09, 1.6728e-09, 1.7653e-07, 6.6327e-07],\n",
       "        [6.7714e-03, 9.6826e-01, 8.4716e-04, 1.7651e-02, 4.3070e-03, 4.9743e-05,\n",
       "         1.9183e-03, 2.8834e-05, 4.9077e-05, 1.1592e-04],\n",
       "        [1.6841e-06, 1.0527e-09, 1.5725e-07, 2.2680e-07, 5.2217e-08, 3.2959e-06,\n",
       "         3.9476e-07, 9.9279e-01, 4.3897e-05, 7.1576e-03],\n",
       "        [6.3292e-05, 1.1739e-05, 9.2459e-03, 1.6125e-06, 9.9055e-01, 6.9702e-08,\n",
       "         1.2270e-04, 5.9019e-08, 1.5785e-06, 3.9474e-06],\n",
       "        [5.0484e-02, 4.3407e-06, 5.3791e-05, 9.2507e-01, 2.0969e-02, 2.5694e-05,\n",
       "         2.9751e-03, 4.0738e-05, 5.4731e-05, 3.2269e-04]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "pred_probs = make_predictions(\n",
    "    model=model_2,\n",
    "    data=test_samples\n",
    ")\n",
    "\n",
    "# View first two prediction probabilites\n",
    "pred_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3d8c1ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 1, 7, 4, 3, 0, 4, 7, 1])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conver prediction probabilites to labels\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f752296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
