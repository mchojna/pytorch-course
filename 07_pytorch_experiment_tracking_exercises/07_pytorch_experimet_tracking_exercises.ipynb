{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77de26a6",
   "metadata": {},
   "source": [
    "# 07. PyTorch Experiment Tracking Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d453d3f",
   "metadata": {},
   "source": [
    "Resource: https://www.learnpytorch.io/07_pytorch_experiment_tracking/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9f89d",
   "metadata": {},
   "source": [
    "## 0. Get imports and helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ad1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f812147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eabac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import get_data, setup_data, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c011baaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\n",
    "    \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f67363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b63f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer(\n",
    "    experiment_name: str,\n",
    "    model_name: str,\n",
    "    extra: str=None,\n",
    "):\n",
    "    \"\"\"Creates a torch.utils.tensorboard.SummaryWriter() instance saving to a specific log_dir\"\"\"\n",
    "\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    \n",
    "    timestampe = datetime.now().strftime(\"%y-%m-%d\")\n",
    "    \n",
    "    if extra:\n",
    "        log_dir = os.path.join(\"runs\", timestampe, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestampe, experiment_name, model_name)\n",
    "    \n",
    "    print(f\"[INFO] Created SummaryWriter, saving to {log_dir}...\")\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a070c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import torch.utils.tensorboard\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    writer: torch.utils.tensorboard.writer.SummaryWriter\n",
    ") -> Dict[str, List]:\n",
    "    \"\"\"Trains and test PyTorch model\"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = engine.train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        test_loss, test_acc = engine.test_step(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "        ### New: Use the writer parameter to track experiments ###\n",
    "        # See if there's a writer, if so, log to it\n",
    "        if writer:\n",
    "            # Add results to SummaryWriter\n",
    "            writer.add_scalars(\n",
    "                main_tag=\"Loss\", \n",
    "                tag_scalar_dict={\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"test_loss\": test_loss\n",
    "                },\n",
    "                global_step=epoch\n",
    "            )\n",
    "            \n",
    "            writer.add_scalars(\n",
    "                main_tag=\"Accuracy\", \n",
    "                tag_scalar_dict={\n",
    "                    \"train_acc\": train_acc,\n",
    "                    \"test_acc\": test_acc\n",
    "                }, \n",
    "                global_step=epoch\n",
    "            )\n",
    "\n",
    "            # Close the writer\n",
    "            writer.close()\n",
    "        else:\n",
    "            pass\n",
    "    ### End new ###\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf13d5",
   "metadata": {},
   "source": [
    "## 1. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510dc650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pizza_steak_sushi_10_percent exists...\n",
      "Data in data/pizza_steak_sushi_10_percent already exits, skipping downloading and unzipping...\n",
      "Finished getting data...\n",
      "data/pizza_steak_sushi_20_percent exists...\n",
      "Data in data/pizza_steak_sushi_20_percent already exits, skipping downloading and unzipping...\n",
      "Finished getting data...\n"
     ]
    }
   ],
   "source": [
    "get_data.get_data(\n",
    "    data_dir_str=\"data/\",\n",
    "    image_path_str=\"pizza_steak_sushi_10_percent\",\n",
    "    data_url_str=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "    file_name_str=\"pizza_steak_sushi.zip\"\n",
    ")\n",
    "\n",
    "get_data.get_data(\n",
    "    data_dir_str=\"data/\",\n",
    "    image_path_str=\"pizza_steak_sushi_20_percent\",\n",
    "    data_url_str=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
    "    file_name_str=\"pizza_steak_sushi_20_percent.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25adb41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training directory 10%: data/pizza_steak_sushi_10_percent/train\n",
      "Training directory 20%: data/pizza_steak_sushi_20_percent/train\n",
      "Testing directory: data/pizza_steak_sushi_10_percent/test\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_10_percent_path = Path(\"data/pizza_steak_sushi_10_percent\")\n",
    "data_20_percent_path = Path(\"data/pizza_steak_sushi_20_percent\")\n",
    "\n",
    "# Setup training directory paths\n",
    "train_dir_10_percent = data_10_percent_path / \"train\"\n",
    "train_dir_20_percent = data_20_percent_path / \"train\"\n",
    "\n",
    "# Setup testing directory paths (note: use the same test dataset for both to compare the results)\n",
    "test_dir = data_10_percent_path / \"test\"\n",
    "\n",
    "# Check the directories\n",
    "print(f\"Training directory 10%: {train_dir_10_percent}\")\n",
    "print(f\"Training directory 20%: {train_dir_20_percent}\")\n",
    "print(f\"Testing directory: {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da935b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a transform to normalize data distribution to be inline with ImageNet\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], # values per colour channel [red, green, blue]\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# Create a transform pipeline\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), # get image values between 0 & 1\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaaec90",
   "metadata": {},
   "source": [
    "## 2. Turn data into DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd5c85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches of size 32 in 10 percent training data: 8\n",
      "Number of batches of size 32 in 20 percent training data: 15\n",
      "Number of batches of size 32 in testing data: 8 (all experiments will use the same test set)\n",
      "Number of classes: 3, class names: ['pizza', 'steak', 'sushi']\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create 10% training and test DataLoaders\n",
    "train_dataloader_10_percent, test_dataloader, class_names = setup_data.create_dataloaders(\n",
    "    train_dir=train_dir_10_percent,\n",
    "    test_dir=test_dir,\n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create 20% training and test DataLoaders\n",
    "train_dataloader_20_percent, test_dataloader, class_names = setup_data.create_dataloaders(\n",
    "    train_dir=train_dir_20_percent,\n",
    "    test_dir=test_dir,\n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Find the number of samples/batches per dataloader (using the same test_dataloader for both experiments)\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 10 percent training data: {len(train_dataloader_10_percent)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training data: {len(train_dataloader_20_percent)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in testing data: {len(train_dataloader_10_percent)} (all experiments will use the same test set)\")\n",
    "print(f\"Number of classes: {len(class_names)}, class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045253b",
   "metadata": {},
   "source": [
    "## 3. Exercise 1: Pick a larger model from torchvision.models to add to the list of experiments (for example, EffNetB3 or higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01dcdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_effnetb0() -> nn.Module:\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad=False\n",
    "    \n",
    "    set_seeds()\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"[INFO] Created EfficientNetB0...\")\n",
    "    return model\n",
    "    \n",
    "def create_effnetb1() -> nn.Module:\n",
    "    weights = torchvision.models.EfficientNet_B1_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b1(weights=weights).to(device)\n",
    "\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad=False\n",
    "    \n",
    "    set_seeds()\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"[INFO] Created EfficientNetB1...\")\n",
    "    return model\n",
    "\n",
    "def create_effnetb2() -> nn.Module:\n",
    "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
    "\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad=False\n",
    "    \n",
    "    set_seeds()\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3, inplace=True),\n",
    "        nn.Linear(in_features=1408, out_features=len(class_names), bias=True)\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"[INFO] Created EfficientNetB2...\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d41bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "import gc\n",
    "\n",
    "def run_experiment(experiments: Dict):\n",
    "\n",
    "    for model_name, model_ in experiments[\"models\"].items():\n",
    "        \n",
    "        for epochs_num, epochs in experiments[\"epochs\"].items():\n",
    "            \n",
    "            for data_name, data in experiments[\"data\"].items():\n",
    "                \n",
    "                model = model_()\n",
    "                        \n",
    "                optimizer = torch.optim.Adam(\n",
    "                    params=model.parameters(),\n",
    "                    lr=0.001\n",
    "                )\n",
    "                loss_fn = torch.nn.CrossEntropyLoss()\n",
    "                \n",
    "                train(\n",
    "                    model=model,\n",
    "                    train_dataloader=data,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_fn=loss_fn,\n",
    "                    epochs=epochs,\n",
    "                    device=device,\n",
    "                    writer=create_writer(\n",
    "                        experiment_name=data_name,\n",
    "                        model_name=model_name,\n",
    "                        extra=f\"{epochs}_epochs\"\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # Save model to file so we can import it later if need be\n",
    "                save_filepath = f\"07_{model_name}_{data_name}_{epochs}_epochs.pth\"\n",
    "                utils.save_model(\n",
    "                    model=model,\n",
    "                    target_dir=\"models\",\n",
    "                    model_name=save_filepath\n",
    "                )\n",
    "\n",
    "                if device == \"cuda\":\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                del model, optimizer, loss_fn, data\n",
    "                gc.collect()\n",
    "\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ddb36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"models\": {\n",
    "        \"effnetb0\": create_effnetb0,\n",
    "        \"effnetb1\": create_effnetb1,\n",
    "    },\n",
    "    \"epochs\": {\n",
    "        \"5\": 5,\n",
    "        \"10\": 10\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"10_percent\": train_dataloader_10_percent,\n",
    "        \"20_percent\": train_dataloader_20_percent\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7793572d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created EfficientNetB0...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/10_percent/effnetb0/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e3d82de303428590cba9e2273973f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0434 | train_acc: 0.4844 | test_loss: 0.9274 | test_acc: 0.4782\n",
      "Epoch: 2 | train_loss: 0.8841 | train_acc: 0.6602 | test_loss: 0.8153 | test_acc: 0.6108\n",
      "Epoch: 3 | train_loss: 0.7880 | train_acc: 0.6719 | test_loss: 0.7110 | test_acc: 0.8352\n",
      "Epoch: 4 | train_loss: 0.7326 | train_acc: 0.7461 | test_loss: 0.5842 | test_acc: 0.8864\n",
      "Epoch: 5 | train_loss: 0.6158 | train_acc: 0.9102 | test_loss: 0.5591 | test_acc: 0.8968\n",
      "[INFO] Saving model to: models/07_effnetb0_10_percent_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB0...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/20_percent/effnetb0/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43c5abfcb2446a0a04543e1bd254049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.9632 | train_acc: 0.6062 | test_loss: 0.6667 | test_acc: 0.8864\n",
      "Epoch: 2 | train_loss: 0.7031 | train_acc: 0.8063 | test_loss: 0.5944 | test_acc: 0.8665\n",
      "Epoch: 3 | train_loss: 0.5831 | train_acc: 0.8438 | test_loss: 0.4716 | test_acc: 0.9072\n",
      "Epoch: 4 | train_loss: 0.5008 | train_acc: 0.8438 | test_loss: 0.4583 | test_acc: 0.8968\n",
      "Epoch: 5 | train_loss: 0.5042 | train_acc: 0.8479 | test_loss: 0.4054 | test_acc: 0.9176\n",
      "[INFO] Saving model to: models/07_effnetb0_20_percent_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB0...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/10_percent/effnetb0/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd77b5effd9744fe898800db4d3d082c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0434 | train_acc: 0.4844 | test_loss: 0.9274 | test_acc: 0.4782\n",
      "Epoch: 2 | train_loss: 0.8841 | train_acc: 0.6602 | test_loss: 0.8153 | test_acc: 0.6108\n",
      "Epoch: 3 | train_loss: 0.7880 | train_acc: 0.6719 | test_loss: 0.7110 | test_acc: 0.8352\n",
      "Epoch: 4 | train_loss: 0.7326 | train_acc: 0.7461 | test_loss: 0.5842 | test_acc: 0.8864\n",
      "Epoch: 5 | train_loss: 0.6158 | train_acc: 0.9102 | test_loss: 0.5591 | test_acc: 0.8968\n",
      "Epoch: 6 | train_loss: 0.5523 | train_acc: 0.8945 | test_loss: 0.5858 | test_acc: 0.8968\n",
      "Epoch: 7 | train_loss: 0.5588 | train_acc: 0.8008 | test_loss: 0.5410 | test_acc: 0.8968\n",
      "Epoch: 8 | train_loss: 0.4760 | train_acc: 0.9336 | test_loss: 0.5043 | test_acc: 0.8864\n",
      "Epoch: 9 | train_loss: 0.6039 | train_acc: 0.7656 | test_loss: 0.5024 | test_acc: 0.8873\n",
      "Epoch: 10 | train_loss: 0.4965 | train_acc: 0.8047 | test_loss: 0.4587 | test_acc: 0.9176\n",
      "[INFO] Saving model to: models/07_effnetb0_10_percent_10_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB0...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/20_percent/effnetb0/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dda19b72454ea7a5bdaa862ba5e537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.9632 | train_acc: 0.6062 | test_loss: 0.6667 | test_acc: 0.8864\n",
      "Epoch: 2 | train_loss: 0.7031 | train_acc: 0.8063 | test_loss: 0.5944 | test_acc: 0.8665\n",
      "Epoch: 3 | train_loss: 0.5831 | train_acc: 0.8438 | test_loss: 0.4716 | test_acc: 0.9072\n",
      "Epoch: 4 | train_loss: 0.5008 | train_acc: 0.8438 | test_loss: 0.4583 | test_acc: 0.8968\n",
      "Epoch: 5 | train_loss: 0.5042 | train_acc: 0.8479 | test_loss: 0.4054 | test_acc: 0.9176\n",
      "Epoch: 6 | train_loss: 0.3748 | train_acc: 0.9021 | test_loss: 0.3729 | test_acc: 0.8968\n",
      "Epoch: 7 | train_loss: 0.3685 | train_acc: 0.9167 | test_loss: 0.3322 | test_acc: 0.9072\n",
      "Epoch: 8 | train_loss: 0.3660 | train_acc: 0.8958 | test_loss: 0.3458 | test_acc: 0.9072\n",
      "Epoch: 9 | train_loss: 0.3014 | train_acc: 0.9313 | test_loss: 0.3143 | test_acc: 0.9072\n",
      "Epoch: 10 | train_loss: 0.3551 | train_acc: 0.8854 | test_loss: 0.2844 | test_acc: 0.9072\n",
      "[INFO] Saving model to: models/07_effnetb0_20_percent_10_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB1...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/10_percent/effnetb1/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5a154bd12d4dbaa8b3ee0722e4d3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0542 | train_acc: 0.5625 | test_loss: 0.9792 | test_acc: 0.6932\n",
      "Epoch: 2 | train_loss: 0.9665 | train_acc: 0.7031 | test_loss: 0.9296 | test_acc: 0.6629\n",
      "Epoch: 3 | train_loss: 0.9260 | train_acc: 0.5312 | test_loss: 0.8595 | test_acc: 0.7652\n",
      "Epoch: 4 | train_loss: 0.8831 | train_acc: 0.7773 | test_loss: 0.7717 | test_acc: 0.9489\n",
      "Epoch: 5 | train_loss: 0.7697 | train_acc: 0.8945 | test_loss: 0.7457 | test_acc: 0.9176\n",
      "[INFO] Saving model to: models/07_effnetb1_10_percent_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB1...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/20_percent/effnetb1/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0aa91e748ef4004af93913038b6426e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0039 | train_acc: 0.6042 | test_loss: 0.8834 | test_acc: 0.8873\n",
      "Epoch: 2 | train_loss: 0.8129 | train_acc: 0.8458 | test_loss: 0.7443 | test_acc: 0.8570\n",
      "Epoch: 3 | train_loss: 0.6999 | train_acc: 0.8396 | test_loss: 0.6074 | test_acc: 0.9489\n",
      "Epoch: 4 | train_loss: 0.6056 | train_acc: 0.8667 | test_loss: 0.5538 | test_acc: 0.9280\n",
      "Epoch: 5 | train_loss: 0.5495 | train_acc: 0.8771 | test_loss: 0.4986 | test_acc: 0.9280\n",
      "[INFO] Saving model to: models/07_effnetb1_20_percent_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB1...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/10_percent/effnetb1/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc95992236a44d93ba40c3371548f9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0542 | train_acc: 0.5625 | test_loss: 0.9792 | test_acc: 0.6932\n",
      "Epoch: 2 | train_loss: 0.9665 | train_acc: 0.7031 | test_loss: 0.9296 | test_acc: 0.6629\n",
      "Epoch: 3 | train_loss: 0.9260 | train_acc: 0.5312 | test_loss: 0.8595 | test_acc: 0.7652\n",
      "Epoch: 4 | train_loss: 0.8831 | train_acc: 0.7773 | test_loss: 0.7717 | test_acc: 0.9489\n",
      "Epoch: 5 | train_loss: 0.7697 | train_acc: 0.8945 | test_loss: 0.7457 | test_acc: 0.9176\n",
      "Epoch: 6 | train_loss: 0.7382 | train_acc: 0.8867 | test_loss: 0.7189 | test_acc: 0.9072\n",
      "Epoch: 7 | train_loss: 0.7297 | train_acc: 0.7578 | test_loss: 0.6579 | test_acc: 0.9280\n",
      "Epoch: 8 | train_loss: 0.6705 | train_acc: 0.9414 | test_loss: 0.6407 | test_acc: 0.9186\n",
      "Epoch: 9 | train_loss: 0.6554 | train_acc: 0.7734 | test_loss: 0.6249 | test_acc: 0.8570\n",
      "Epoch: 10 | train_loss: 0.5845 | train_acc: 0.9180 | test_loss: 0.5879 | test_acc: 0.9280\n",
      "[INFO] Saving model to: models/07_effnetb1_10_percent_10_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB1...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/20_percent/effnetb1/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3dc34ca04f4559af5450333caca7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0039 | train_acc: 0.6042 | test_loss: 0.8834 | test_acc: 0.8873\n",
      "Epoch: 2 | train_loss: 0.8129 | train_acc: 0.8458 | test_loss: 0.7443 | test_acc: 0.8570\n",
      "Epoch: 3 | train_loss: 0.6999 | train_acc: 0.8396 | test_loss: 0.6074 | test_acc: 0.9489\n",
      "Epoch: 4 | train_loss: 0.6056 | train_acc: 0.8667 | test_loss: 0.5538 | test_acc: 0.9280\n",
      "Epoch: 5 | train_loss: 0.5495 | train_acc: 0.8771 | test_loss: 0.4986 | test_acc: 0.9280\n",
      "Epoch: 6 | train_loss: 0.4680 | train_acc: 0.9292 | test_loss: 0.4342 | test_acc: 0.9384\n",
      "Epoch: 7 | train_loss: 0.4479 | train_acc: 0.9167 | test_loss: 0.4046 | test_acc: 0.9280\n",
      "Epoch: 8 | train_loss: 0.4591 | train_acc: 0.8875 | test_loss: 0.4458 | test_acc: 0.9072\n",
      "Epoch: 9 | train_loss: 0.3866 | train_acc: 0.9187 | test_loss: 0.4164 | test_acc: 0.8977\n",
      "Epoch: 10 | train_loss: 0.4144 | train_acc: 0.8896 | test_loss: 0.3480 | test_acc: 0.9384\n",
      "[INFO] Saving model to: models/07_effnetb1_20_percent_10_epochs.pth\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment(experiments=experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56d9ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"models\": {\n",
    "        \"effnetb2\": create_effnetb2,\n",
    "    },\n",
    "    \"epochs\": {\n",
    "        \"5\": 5,\n",
    "        \"10\": 10\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"10_percent\": train_dataloader_10_percent,\n",
    "        \"20_percent\": train_dataloader_20_percent\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6637204e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created EfficientNetB2...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/10_percent/effnetb2/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e1b04d0caf43c5b9f2fdc2cbb17c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0869 | train_acc: 0.3984 | test_loss: 0.9611 | test_acc: 0.6903\n",
      "Epoch: 2 | train_loss: 0.9222 | train_acc: 0.6445 | test_loss: 0.8637 | test_acc: 0.8144\n",
      "Epoch: 3 | train_loss: 0.8365 | train_acc: 0.7227 | test_loss: 0.7447 | test_acc: 0.9688\n",
      "Epoch: 4 | train_loss: 0.7069 | train_acc: 0.8906 | test_loss: 0.7121 | test_acc: 0.9081\n",
      "Epoch: 5 | train_loss: 0.6768 | train_acc: 0.7812 | test_loss: 0.7047 | test_acc: 0.8873\n",
      "[INFO] Saving model to: models/07_effnetb2_10_percent_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB2...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/20_percent/effnetb2/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f302d195e63481f8344b84a24d8fad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.9894 | train_acc: 0.5292 | test_loss: 0.7819 | test_acc: 0.8049\n",
      "Epoch: 2 | train_loss: 0.7408 | train_acc: 0.7604 | test_loss: 0.6632 | test_acc: 0.8873\n",
      "Epoch: 3 | train_loss: 0.6080 | train_acc: 0.8229 | test_loss: 0.5614 | test_acc: 0.9384\n",
      "Epoch: 4 | train_loss: 0.5478 | train_acc: 0.8458 | test_loss: 0.5675 | test_acc: 0.8674\n",
      "Epoch: 5 | train_loss: 0.4397 | train_acc: 0.8708 | test_loss: 0.4475 | test_acc: 0.9489\n",
      "[INFO] Saving model to: models/07_effnetb2_20_percent_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB2...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/10_percent/effnetb2/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e878567fcff482abe5209db863a72b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0869 | train_acc: 0.3984 | test_loss: 0.9611 | test_acc: 0.6903\n",
      "Epoch: 2 | train_loss: 0.9222 | train_acc: 0.6445 | test_loss: 0.8637 | test_acc: 0.8144\n",
      "Epoch: 3 | train_loss: 0.8365 | train_acc: 0.7227 | test_loss: 0.7447 | test_acc: 0.9688\n",
      "Epoch: 4 | train_loss: 0.7069 | train_acc: 0.8906 | test_loss: 0.7121 | test_acc: 0.9081\n",
      "Epoch: 5 | train_loss: 0.6768 | train_acc: 0.7812 | test_loss: 0.7047 | test_acc: 0.8873\n",
      "Epoch: 6 | train_loss: 0.6048 | train_acc: 0.7773 | test_loss: 0.6300 | test_acc: 0.9280\n",
      "Epoch: 7 | train_loss: 0.5829 | train_acc: 0.8086 | test_loss: 0.6334 | test_acc: 0.8873\n",
      "Epoch: 8 | train_loss: 0.5261 | train_acc: 0.9336 | test_loss: 0.6156 | test_acc: 0.8977\n",
      "Epoch: 9 | train_loss: 0.5385 | train_acc: 0.8125 | test_loss: 0.6248 | test_acc: 0.8466\n",
      "Epoch: 10 | train_loss: 0.4922 | train_acc: 0.9219 | test_loss: 0.5833 | test_acc: 0.9176\n",
      "[INFO] Saving model to: models/07_effnetb2_10_percent_10_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB2...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/20_percent/effnetb2/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27adc4367b234e9d9549cc77b286c25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.9894 | train_acc: 0.5292 | test_loss: 0.7819 | test_acc: 0.8049\n",
      "Epoch: 2 | train_loss: 0.7408 | train_acc: 0.7604 | test_loss: 0.6632 | test_acc: 0.8873\n",
      "Epoch: 3 | train_loss: 0.6080 | train_acc: 0.8229 | test_loss: 0.5614 | test_acc: 0.9384\n",
      "Epoch: 4 | train_loss: 0.5478 | train_acc: 0.8458 | test_loss: 0.5675 | test_acc: 0.8674\n",
      "Epoch: 5 | train_loss: 0.4397 | train_acc: 0.8708 | test_loss: 0.4475 | test_acc: 0.9489\n",
      "Epoch: 6 | train_loss: 0.3890 | train_acc: 0.9104 | test_loss: 0.4610 | test_acc: 0.9280\n",
      "Epoch: 7 | train_loss: 0.3699 | train_acc: 0.9062 | test_loss: 0.4225 | test_acc: 0.9384\n",
      "Epoch: 8 | train_loss: 0.3872 | train_acc: 0.8896 | test_loss: 0.4414 | test_acc: 0.8674\n",
      "Epoch: 9 | train_loss: 0.3256 | train_acc: 0.9250 | test_loss: 0.4315 | test_acc: 0.8977\n",
      "Epoch: 10 | train_loss: 0.3702 | train_acc: 0.9021 | test_loss: 0.3958 | test_acc: 0.9280\n",
      "[INFO] Saving model to: models/07_effnetb2_20_percent_10_epochs.pth\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment(experiments=experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08aaa33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a31bc96ed0794759\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a31bc96ed0794759\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's view oru experiments from within notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b4495",
   "metadata": {},
   "source": [
    "## 4. Exercise 2. Introduce data augmentation to the list of experiments using the 20% pizza, steak, sushi training and test datasets, does this change anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e12c6e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aa74df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_aug_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e0f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_aug_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9392b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches of size 32 in 20 percent training data w/o augmentation: 15\n",
      "Number of batches of size 32 in 20 percent training data with augomentation: 15\n",
      "Number of batches of size 32 in testing data: 8 (all experiments will use the same test set)\n",
      "Number of classes: 3, class names: ['pizza', 'steak', 'sushi']\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create train dataloader *without* data augmentation\n",
    "train_dataloader_non_aug, test_dataloader, class_names = setup_data.create_dataloaders(\n",
    "    train_dir=train_dir_20_percent,\n",
    "    test_dir=test_dir,\n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create train dataloader *with* data augmentation\n",
    "train_dataloader_aug, test_dataloader_aug, class_names = setup_data.create_dataloaders(\n",
    "    train_dir=train_dir_20_percent,\n",
    "    test_dir=test_dir,\n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Find the number of samples/batches per dataloader (using the same test_dataloader for both experiments)\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training data w/o augmentation: {len(train_dataloader_non_aug)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training data with augomentation: {len(train_dataloader_aug)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in testing data: {len(train_dataloader_10_percent)} (all experiments will use the same test set)\")\n",
    "print(f\"Number of classes: {len(class_names)}, class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9cacda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"models\": {\n",
    "        \"effnetb0\": create_effnetb0,\n",
    "        \"effnetb1\": create_effnetb1,\n",
    "    },\n",
    "    \"epochs\": {\n",
    "        \"5\": 5,\n",
    "        \"10\": 10\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"non_aug\": train_dataloader_non_aug,\n",
    "        \"aug\": train_dataloader_aug\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e51b893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created EfficientNetB0...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/non_aug/effnetb0/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b883d19b5864f02a33fbdfe31de0caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.9632 | train_acc: 0.6062 | test_loss: 0.6667 | test_acc: 0.8864\n",
      "Epoch: 2 | train_loss: 0.7031 | train_acc: 0.8063 | test_loss: 0.5944 | test_acc: 0.8665\n",
      "Epoch: 3 | train_loss: 0.5831 | train_acc: 0.8438 | test_loss: 0.4716 | test_acc: 0.9072\n",
      "Epoch: 4 | train_loss: 0.5008 | train_acc: 0.8438 | test_loss: 0.4583 | test_acc: 0.8968\n",
      "Epoch: 5 | train_loss: 0.5042 | train_acc: 0.8479 | test_loss: 0.4054 | test_acc: 0.9176\n",
      "[INFO] Saving model to: models/07_effnetb0_non_aug_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB0...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/aug/effnetb0/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90f34ea7d3e4737bc5d76a6ab997d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.9632 | train_acc: 0.6062 | test_loss: 0.6667 | test_acc: 0.8864\n",
      "Epoch: 2 | train_loss: 0.7031 | train_acc: 0.8063 | test_loss: 0.5944 | test_acc: 0.8665\n",
      "Epoch: 3 | train_loss: 0.5831 | train_acc: 0.8438 | test_loss: 0.4716 | test_acc: 0.9072\n",
      "Epoch: 4 | train_loss: 0.5008 | train_acc: 0.8438 | test_loss: 0.4583 | test_acc: 0.8968\n",
      "Epoch: 5 | train_loss: 0.5042 | train_acc: 0.8479 | test_loss: 0.4054 | test_acc: 0.9176\n",
      "[INFO] Saving model to: models/07_effnetb0_aug_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB0...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/non_aug/effnetb0/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10154580015470ca7c854e3096dc4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.9632 | train_acc: 0.6062 | test_loss: 0.6667 | test_acc: 0.8864\n",
      "Epoch: 2 | train_loss: 0.7031 | train_acc: 0.8063 | test_loss: 0.5944 | test_acc: 0.8665\n",
      "Epoch: 3 | train_loss: 0.5831 | train_acc: 0.8438 | test_loss: 0.4716 | test_acc: 0.9072\n",
      "Epoch: 4 | train_loss: 0.5008 | train_acc: 0.8438 | test_loss: 0.4583 | test_acc: 0.8968\n",
      "Epoch: 5 | train_loss: 0.5042 | train_acc: 0.8479 | test_loss: 0.4054 | test_acc: 0.9176\n",
      "Epoch: 6 | train_loss: 0.3748 | train_acc: 0.9021 | test_loss: 0.3729 | test_acc: 0.8968\n",
      "Epoch: 7 | train_loss: 0.3685 | train_acc: 0.9167 | test_loss: 0.3322 | test_acc: 0.9072\n",
      "Epoch: 8 | train_loss: 0.3660 | train_acc: 0.8958 | test_loss: 0.3458 | test_acc: 0.9072\n",
      "Epoch: 9 | train_loss: 0.3014 | train_acc: 0.9313 | test_loss: 0.3143 | test_acc: 0.9072\n",
      "Epoch: 10 | train_loss: 0.3551 | train_acc: 0.8854 | test_loss: 0.2844 | test_acc: 0.9072\n",
      "[INFO] Saving model to: models/07_effnetb0_non_aug_10_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB0...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/aug/effnetb0/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb564a5f3dc46769f32d63ef479a48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.9632 | train_acc: 0.6062 | test_loss: 0.6667 | test_acc: 0.8864\n",
      "Epoch: 2 | train_loss: 0.7031 | train_acc: 0.8063 | test_loss: 0.5944 | test_acc: 0.8665\n",
      "Epoch: 3 | train_loss: 0.5831 | train_acc: 0.8438 | test_loss: 0.4716 | test_acc: 0.9072\n",
      "Epoch: 4 | train_loss: 0.5008 | train_acc: 0.8438 | test_loss: 0.4583 | test_acc: 0.8968\n",
      "Epoch: 5 | train_loss: 0.5042 | train_acc: 0.8479 | test_loss: 0.4054 | test_acc: 0.9176\n",
      "Epoch: 6 | train_loss: 0.3748 | train_acc: 0.9021 | test_loss: 0.3729 | test_acc: 0.8968\n",
      "Epoch: 7 | train_loss: 0.3685 | train_acc: 0.9167 | test_loss: 0.3322 | test_acc: 0.9072\n",
      "Epoch: 8 | train_loss: 0.3660 | train_acc: 0.8958 | test_loss: 0.3458 | test_acc: 0.9072\n",
      "Epoch: 9 | train_loss: 0.3014 | train_acc: 0.9313 | test_loss: 0.3143 | test_acc: 0.9072\n",
      "Epoch: 10 | train_loss: 0.3551 | train_acc: 0.8854 | test_loss: 0.2844 | test_acc: 0.9072\n",
      "[INFO] Saving model to: models/07_effnetb0_aug_10_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB1...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/non_aug/effnetb1/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cd33d609614f0293bc30dccbeb462c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0039 | train_acc: 0.6042 | test_loss: 0.8834 | test_acc: 0.8873\n",
      "Epoch: 2 | train_loss: 0.8129 | train_acc: 0.8458 | test_loss: 0.7443 | test_acc: 0.8570\n",
      "Epoch: 3 | train_loss: 0.6999 | train_acc: 0.8396 | test_loss: 0.6074 | test_acc: 0.9489\n",
      "Epoch: 4 | train_loss: 0.6056 | train_acc: 0.8667 | test_loss: 0.5538 | test_acc: 0.9280\n",
      "Epoch: 5 | train_loss: 0.5495 | train_acc: 0.8771 | test_loss: 0.4986 | test_acc: 0.9280\n",
      "[INFO] Saving model to: models/07_effnetb1_non_aug_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB1...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/aug/effnetb1/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a5404d0f0b41f59ee1aede23677c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0039 | train_acc: 0.6042 | test_loss: 0.8834 | test_acc: 0.8873\n",
      "Epoch: 2 | train_loss: 0.8129 | train_acc: 0.8458 | test_loss: 0.7443 | test_acc: 0.8570\n",
      "Epoch: 3 | train_loss: 0.6999 | train_acc: 0.8396 | test_loss: 0.6074 | test_acc: 0.9489\n",
      "Epoch: 4 | train_loss: 0.6056 | train_acc: 0.8667 | test_loss: 0.5538 | test_acc: 0.9280\n",
      "Epoch: 5 | train_loss: 0.5495 | train_acc: 0.8771 | test_loss: 0.4986 | test_acc: 0.9280\n",
      "[INFO] Saving model to: models/07_effnetb1_aug_5_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB1...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/non_aug/effnetb1/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ae64b6564a4919b31f24c51f17ef7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0039 | train_acc: 0.6042 | test_loss: 0.8834 | test_acc: 0.8873\n",
      "Epoch: 2 | train_loss: 0.8129 | train_acc: 0.8458 | test_loss: 0.7443 | test_acc: 0.8570\n",
      "Epoch: 3 | train_loss: 0.6999 | train_acc: 0.8396 | test_loss: 0.6074 | test_acc: 0.9489\n",
      "Epoch: 4 | train_loss: 0.6056 | train_acc: 0.8667 | test_loss: 0.5538 | test_acc: 0.9280\n",
      "Epoch: 5 | train_loss: 0.5495 | train_acc: 0.8771 | test_loss: 0.4986 | test_acc: 0.9280\n",
      "Epoch: 6 | train_loss: 0.4680 | train_acc: 0.9292 | test_loss: 0.4342 | test_acc: 0.9384\n",
      "Epoch: 7 | train_loss: 0.4479 | train_acc: 0.9167 | test_loss: 0.4046 | test_acc: 0.9280\n",
      "Epoch: 8 | train_loss: 0.4591 | train_acc: 0.8875 | test_loss: 0.4458 | test_acc: 0.9072\n",
      "Epoch: 9 | train_loss: 0.3866 | train_acc: 0.9187 | test_loss: 0.4164 | test_acc: 0.8977\n",
      "Epoch: 10 | train_loss: 0.4144 | train_acc: 0.8896 | test_loss: 0.3480 | test_acc: 0.9384\n",
      "[INFO] Saving model to: models/07_effnetb1_non_aug_10_epochs.pth\n",
      "\n",
      "\n",
      "[INFO] Created EfficientNetB1...\n",
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/aug/effnetb1/10_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8825d2d128348109b38ca12bc952183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0039 | train_acc: 0.6042 | test_loss: 0.8834 | test_acc: 0.8873\n",
      "Epoch: 2 | train_loss: 0.8129 | train_acc: 0.8458 | test_loss: 0.7443 | test_acc: 0.8570\n",
      "Epoch: 3 | train_loss: 0.6999 | train_acc: 0.8396 | test_loss: 0.6074 | test_acc: 0.9489\n",
      "Epoch: 4 | train_loss: 0.6056 | train_acc: 0.8667 | test_loss: 0.5538 | test_acc: 0.9280\n",
      "Epoch: 5 | train_loss: 0.5495 | train_acc: 0.8771 | test_loss: 0.4986 | test_acc: 0.9280\n",
      "Epoch: 6 | train_loss: 0.4680 | train_acc: 0.9292 | test_loss: 0.4342 | test_acc: 0.9384\n",
      "Epoch: 7 | train_loss: 0.4479 | train_acc: 0.9167 | test_loss: 0.4046 | test_acc: 0.9280\n",
      "Epoch: 8 | train_loss: 0.4591 | train_acc: 0.8875 | test_loss: 0.4458 | test_acc: 0.9072\n",
      "Epoch: 9 | train_loss: 0.3866 | train_acc: 0.9187 | test_loss: 0.4164 | test_acc: 0.8977\n",
      "Epoch: 10 | train_loss: 0.4144 | train_acc: 0.8896 | test_loss: 0.3480 | test_acc: 0.9384\n",
      "[INFO] Saving model to: models/07_effnetb1_aug_10_epochs.pth\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment(experiments=experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b17ba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 60567), started 0:02:11 ago. (Use '!kill 60567' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4f6da23e8dd9db0f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4f6da23e8dd9db0f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's view oru experiments from within notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653cf1b1",
   "metadata": {},
   "source": [
    "## Exercise 3. Scale up the dataset to turn FoodVision Mini into FoodVision Big using the entire Food101 dataset from torchvision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d2fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and transform Food101 data\n",
    "train_data = torchvision.datasets.Food101(\n",
    "    root=\"data\",\n",
    "    # download=True,\n",
    "    split=\"train\",\n",
    "    transform=simple_transform,\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.Food101(\n",
    "    root=\"data\",\n",
    "    # download=True,\n",
    "    split=\"test\",\n",
    "    transform=simple_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0a9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75750, 25250)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sample numbers\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0736783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "train_dataloader_big = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=os.cpu_count(),\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader_big = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=os.cpu_count(),\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bde0adc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader_big), len(test_dataloader_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d6afb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /home/michal-chojna/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82.7M/82.7M [00:08<00:00, 9.95MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "EfficientNet                                            [1, 101]                  --\n",
       "├─Sequential: 1-1                                       [1, 1280, 7, 7]           --\n",
       "│    └─Conv2dNormActivation: 2-1                        [1, 24, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-1                                 [1, 24, 112, 112]         (648)\n",
       "│    │    └─BatchNorm2d: 3-2                            [1, 24, 112, 112]         (48)\n",
       "│    │    └─SiLU: 3-3                                   [1, 24, 112, 112]         --\n",
       "│    └─Sequential: 2-2                                  [1, 24, 112, 112]         --\n",
       "│    │    └─FusedMBConv: 3-4                            [1, 24, 112, 112]         (5,232)\n",
       "│    │    └─FusedMBConv: 3-5                            [1, 24, 112, 112]         (5,232)\n",
       "│    └─Sequential: 2-3                                  [1, 48, 56, 56]           --\n",
       "│    │    └─FusedMBConv: 3-6                            [1, 48, 56, 56]           (25,632)\n",
       "│    │    └─FusedMBConv: 3-7                            [1, 48, 56, 56]           (92,640)\n",
       "│    │    └─FusedMBConv: 3-8                            [1, 48, 56, 56]           (92,640)\n",
       "│    │    └─FusedMBConv: 3-9                            [1, 48, 56, 56]           (92,640)\n",
       "│    └─Sequential: 2-4                                  [1, 64, 28, 28]           --\n",
       "│    │    └─FusedMBConv: 3-10                           [1, 64, 28, 28]           (95,744)\n",
       "│    │    └─FusedMBConv: 3-11                           [1, 64, 28, 28]           (164,480)\n",
       "│    │    └─FusedMBConv: 3-12                           [1, 64, 28, 28]           (164,480)\n",
       "│    │    └─FusedMBConv: 3-13                           [1, 64, 28, 28]           (164,480)\n",
       "│    └─Sequential: 2-5                                  [1, 128, 14, 14]          --\n",
       "│    │    └─MBConv: 3-14                                [1, 128, 14, 14]          (61,200)\n",
       "│    │    └─MBConv: 3-15                                [1, 128, 14, 14]          (171,296)\n",
       "│    │    └─MBConv: 3-16                                [1, 128, 14, 14]          (171,296)\n",
       "│    │    └─MBConv: 3-17                                [1, 128, 14, 14]          (171,296)\n",
       "│    │    └─MBConv: 3-18                                [1, 128, 14, 14]          (171,296)\n",
       "│    │    └─MBConv: 3-19                                [1, 128, 14, 14]          (171,296)\n",
       "│    └─Sequential: 2-6                                  [1, 160, 14, 14]          --\n",
       "│    │    └─MBConv: 3-20                                [1, 160, 14, 14]          (281,440)\n",
       "│    │    └─MBConv: 3-21                                [1, 160, 14, 14]          (397,800)\n",
       "│    │    └─MBConv: 3-22                                [1, 160, 14, 14]          (397,800)\n",
       "│    │    └─MBConv: 3-23                                [1, 160, 14, 14]          (397,800)\n",
       "│    │    └─MBConv: 3-24                                [1, 160, 14, 14]          (397,800)\n",
       "│    │    └─MBConv: 3-25                                [1, 160, 14, 14]          (397,800)\n",
       "│    │    └─MBConv: 3-26                                [1, 160, 14, 14]          (397,800)\n",
       "│    │    └─MBConv: 3-27                                [1, 160, 14, 14]          (397,800)\n",
       "│    │    └─MBConv: 3-28                                [1, 160, 14, 14]          (397,800)\n",
       "│    └─Sequential: 2-7                                  [1, 256, 7, 7]            --\n",
       "│    │    └─MBConv: 3-29                                [1, 256, 7, 7]            (490,152)\n",
       "│    │    └─MBConv: 3-30                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-31                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-32                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-33                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-34                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-35                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-36                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-37                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-38                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-39                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-40                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-41                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-42                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    │    └─MBConv: 3-43                                [1, 256, 7, 7]            (1,005,120)\n",
       "│    └─Conv2dNormActivation: 2-8                        [1, 1280, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-44                                [1, 1280, 7, 7]           (327,680)\n",
       "│    │    └─BatchNorm2d: 3-45                           [1, 1280, 7, 7]           (2,560)\n",
       "│    │    └─SiLU: 3-46                                  [1, 1280, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                                [1, 1280, 1, 1]           --\n",
       "├─Sequential: 1-3                                       [1, 101]                  --\n",
       "│    └─Dropout: 2-9                                     [1, 1280]                 --\n",
       "│    └─Linear: 2-10                                     [1, 101]                  129,381\n",
       "=========================================================================================================\n",
       "Total params: 20,306,869\n",
       "Trainable params: 129,381\n",
       "Non-trainable params: 20,177,488\n",
       "Total mult-adds (Units.GIGABYTES): 2.85\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 194.81\n",
       "Params size (MB): 81.23\n",
       "Estimated Total Size (MB): 276.64\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "effnetv2_s_weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "foodvision_big_model = torchvision.models.efficientnet_v2_s(weights=effnetv2_s_weights).to(device)\n",
    "\n",
    "# Freeze the base layers\n",
    "for param in foodvision_big_model.features.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "# Change the classifier head to suit 101 different classes\n",
    "foodvision_big_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(in_features=1280, out_features=101) # 101 output classes for Food101 \n",
    ").to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(\n",
    "  model=foodvision_big_model,\n",
    "    input_size=(1, 3, 224, 224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004142d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to runs/25-08-19/food101_all_data/foodvision_big/5_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05156169b9474b2a88265515873aaaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foodvision_big_results = train(\n",
    "    model=foodvision_big_model,\n",
    "    train_dataloader=train_dataloader_big,\n",
    "    test_dataloader=test_dataloader_big,\n",
    "    optimizer=torch.optim.Adam(params=foodvision_big_model.parameters(), lr=0.001),\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    epochs=5,\n",
    "    device=device,\n",
    "    writer=create_writer(\n",
    "        experiment_name=\"food101_all_data\",\n",
    "        model_name=\"foodvision_big\",\n",
    "        extra=f\"{5}_epochs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b743c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
