{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0850aa",
   "metadata": {},
   "source": [
    "# 05. PyTorch Going Modular Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b1c680",
   "metadata": {},
   "source": [
    "## 0. Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa9246",
   "metadata": {},
   "source": [
    "These exercises/solutions are based on section 05. PyTorch Going Modular of the Learn PyTorch for Deep Learning course by Zero to Mastery: https://www.learnpytorch.io/05_pytorch_going_modular/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb159e",
   "metadata": {},
   "source": [
    "## 1. Turn the code to get the data into a Python script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35699ae",
   "metadata": {},
   "source": [
    "When you run the script using python `get_data.py` it should check if the data already exists and skip downloading if it does.\n",
    "If the data download is successful, you should be able to access the `pizza_steak_sushi` images from the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aca905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/get_data.py\n",
    "\"\"\"\n",
    "Contains function to download data\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_data(\n",
    "    data_dir_str: str = \"data/\",\n",
    "    image_path_str: str = \"pizza_steak_sushi\",\n",
    "    data_url_str: str = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "    file_name_str: str = \"pizza_steak_sushi.zip\"\n",
    ") -> None:\n",
    "    \"\"\"Downloads data from GitHub.\n",
    "\n",
    "    Args:\n",
    "        data_dir_str (str, optional): Path do data directory.\n",
    "            Defaults to \"../data/\".\n",
    "        image_path_str (str, optional): Name of the folder where data will\n",
    "            be stored. Defaults to \"pizza_steak_sushi\".\n",
    "        data_url_str (_type_, optional): Link to site from where data will\n",
    "            be downloaded. Defaults to \"https://github.com/mrdbourke/ \\\n",
    "            pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\".\n",
    "        file_name_str (str, optional): Name of the downloaded file.\n",
    "            Defaults to \"pizza_steak_sushi.zip\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup path to data folder\n",
    "    data_dir = Path(data_dir_str)\n",
    "    image_path = data_dir / image_path_str\n",
    "    \n",
    "    # Check if data folder exists\n",
    "    if image_path.exists():\n",
    "        print(f\"{image_path} exists...\")\n",
    "    else:\n",
    "        print(f\"{image_path} does not exists, creating...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if data is already downloaded\n",
    "    if len(list(image_path.glob(\"*/*/*\"))) == 0:\n",
    "        \n",
    "        # Download data\n",
    "        with open(data_dir / file_name_str, \"wb\") as f:\n",
    "            print(f\"Downloading {file_name_str}...\")\n",
    "            request = requests.get(data_url_str)\n",
    "            f.write(request.content)\n",
    "        \n",
    "        # Unzip data\n",
    "        with zipfile.ZipFile(data_dir / file_name_str, \"r\") as z:\n",
    "            print(f\"Extracting {file_name_str}...\")\n",
    "            z.extractall(image_path)\n",
    "            \n",
    "        # Remove zip file\n",
    "        print(f\"Deleting {file_name_str}...\")\n",
    "        os.remove(data_dir / file_name_str)\n",
    "    else:\n",
    "        print(f\"Data in {image_path} already exits, skipping downloading and unzipping...\")\n",
    "        \n",
    "    print(\"Finished getting data...\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dfef1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pizza_steak_sushi exists...\n",
      "Data in data/pizza_steak_sushi already exits, skipping downloading and unzipping...\n",
      "Finished getting data...\n"
     ]
    }
   ],
   "source": [
    "# Example running of get_data.py\n",
    "!python src/get_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc73010",
   "metadata": {},
   "source": [
    "## 2. Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852af0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/setup_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/setup_data.py\n",
    "\"\"\"\n",
    "Contains functino to setup datasets and dataloaders\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = 0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    num_workers: int = NUM_WORKERS,\n",
    "):\n",
    "    \"\"\"Creates training and testing DataLoaders.\n",
    "\n",
    "    Args:\n",
    "        train_dir (str): Path to training directory.\n",
    "        test_dir (str): Path to testing directory.\n",
    "        transform (transforms.Compose): torchvision.transforms to perform\n",
    "            on training and testing data. Defaults to BATCH_SIZE.\n",
    "        batch_size (int, optional): Number of samples per batch in\n",
    "            each of the DataLoaders.\n",
    "        num_workers (int, optional): Integer for number of workers\n",
    "            per DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (train_dataloader, test_dataloader, class_names) \n",
    "        where class_names is a list of the target classes.\n",
    "    \"\"\"\n",
    "    # Use ImageFolder to create dataset(s)\n",
    "    train_data = datasets.ImageFolder(\n",
    "        root=train_dir,\n",
    "        transform=transform,\n",
    "        target_transform=None,\n",
    "    )\n",
    "    test_data = datasets.ImageFolder(\n",
    "        root=test_dir,\n",
    "        transform=transform,\n",
    "        target_transform=None,\n",
    "    )\n",
    "    \n",
    "    # Get class names as a list\n",
    "    class_names = train_data.classes\n",
    "    \n",
    "    # Turn train and test Datasets into DataLoaders\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39fc08a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x11836e270>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x11834b250>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "from src import setup_data\n",
    "from pathlib import Path\n",
    "\n",
    "train_dir = Path(\"data\") / \"pizza_steak_sushi\" / \"train\"\n",
    "test_dir = Path(\"data\") / \"pizza_steak_sushi\" / \"test\"\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = setup_data.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=data_transform\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b450fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d59995",
   "metadata": {},
   "source": [
    "## 3. Create a model (TinyVGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ca60ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/model_builder.py\n",
    "\"\"\"\n",
    "Contains model code to instantiate TinyVGG model\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"Creates TinyVGG architecture.\n",
    "\n",
    "        Args:\n",
    "        input_shape: An integer indicating number\n",
    "            of input channels.\n",
    "        hidden_units: An integer indicating number\n",
    "            of hidden units between layers.\n",
    "        output_shape: An integer indicating number\n",
    "            of output units.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=hidden_units*13*13,\n",
    "                out_features=output_shape,\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc71f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2704, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src import model_builder\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\n",
    "    \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Instantiate a mode from the model_builder.py script\n",
    "model = model_builder.TinyVGG(\n",
    "    input_shape=3,\n",
    "    hidden_units=16,\n",
    "    output_shape=len(class_names)\n",
    ").to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9498785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mchojna/Documents/GitHub/pytorch-course/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single image shape: torch.Size([1, 3, 64, 64])\n",
      "\n",
      "Output logits:\n",
      "tensor([[0.0258, 0.0559, 0.0569]], device='mps:0')\n",
      "\n",
      "Output prediction probabilities:\n",
      "tensor([[0.3266, 0.3366, 0.3369]], device='mps:0')\n",
      "\n",
      "Output prediction label:\n",
      "tensor([2], device='mps:0')\n",
      "\n",
      "Actual label:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 1. Get a batch of images and labels from the DataLoader\n",
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model(img_single.to(device))\n",
    "\n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(\n",
    "    f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3184a41",
   "metadata": {},
   "source": [
    "## 4. Turn training and testing functions into scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f61102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/engine.py\n",
    "\"\"\"\n",
    "Contains functions for training and testing model.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "def train_step(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model to be trained.\n",
    "        dataloader (torch.utils.data.DataLoader): A DataLoader instance\n",
    "            for the model to be trained on.\n",
    "        loss_fn (torch.nn.Module): A PyTorch loss function\n",
    "        to minimize.\n",
    "        optimizer (torch.optim.Optimizer): A PyTorch optimizer to\n",
    "            help minimize the loss function.\n",
    "        device (str): A target device to compute \n",
    "            on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: A tuple of training loss and\n",
    "            training accuracy metrics.\n",
    "    \"\"\"\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0., 0.\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for X, y in dataloader:\n",
    "        # Send data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(\n",
    "    model: torch.nn.Module, \n",
    "    dataloader: torch.utils.data.DataLoader, \n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model to be tested.\n",
    "        dataloader (torch.utils.data.DataLoader): A DataLoader instance \n",
    "            for the model to be tested on.\n",
    "        loss_fn (torch.nn.Module): A PyTorch loss function to calculate\n",
    "            loss on the test data.\n",
    "        device (torch.device): A target device to compute on\n",
    "            (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: A tuple of testing loss and\n",
    "            testing accuracy metrics.\n",
    "    \"\"\"\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "\n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for X, y in dataloader:\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module, \n",
    "    train_dataloader: torch.utils.data.DataLoader, \n",
    "    test_dataloader: torch.utils.data.DataLoader, \n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    epochs: int,\n",
    "    device: torch.device\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model to be trained\n",
    "            and tested.\n",
    "        train_dataloader (torch.utils.data.DataLoader): A DataLoader\n",
    "            instance for the model to be trained on.\n",
    "        test_dataloader (torch.utils.data.DataLoader): A DataLoader\n",
    "            instance for the model to be tested on.\n",
    "        optimizer (torch.optim.Optimizer): A PyTorch optimizer to\n",
    "            help minimize the loss function.\n",
    "        loss_fn (torch.nn.Module): A PyTorch loss function to\n",
    "            calculate loss on both datasets.\n",
    "        epochs (int): An integer indicating how many epochs\n",
    "            to train for.\n",
    "        device (torch.device): A target device to compute\n",
    "            on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[float]]: A dictionary of training and\n",
    "        testing loss as well as training and\n",
    "        testing accuracy metrics. Each metric has a value in\n",
    "        a list for each epoch.\n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                            dataloader=train_dataloader,\n",
    "                                            loss_fn=loss_fn,\n",
    "                                            optimizer=optimizer,\n",
    "                                            device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device)\n",
    "        \n",
    "        # Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f614fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9674b2f3f6049839ca2d8ba08d21363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mchojna/Documents/GitHub/pytorch-course/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0991 | train_acc: 0.3633 | test_loss: 1.0967 | test_acc: 0.4422\n",
      "Epoch: 2 | train_loss: 1.0979 | train_acc: 0.3750 | test_loss: 1.0967 | test_acc: 0.4119\n",
      "Epoch: 3 | train_loss: 1.0967 | train_acc: 0.3867 | test_loss: 1.0972 | test_acc: 0.4347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.099069595336914, 1.097921147942543, 1.0966666787862778],\n",
       " 'train_acc': [0.36328125, 0.375, 0.38671875],\n",
       " 'test_loss': [1.096712867418925, 1.0967222452163696, 1.097179651260376],\n",
       " 'test_acc': [0.44223484848484845, 0.4119318181818182, 0.4346590909090909]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src import engine\n",
    "\n",
    "engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=torch.optim.SGD(params=model.parameters(), lr=0.001),\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    epochs=3,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748bd90",
   "metadata": {},
   "source": [
    "## 5. Turn saving functions into scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9688fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils.py\n",
    "\"\"\"\n",
    "File containint utility functions for model training\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def save_model(\n",
    "    model: torch.nn.Module,\n",
    "    target_dir: str,\n",
    "    model_name: str\n",
    "):\n",
    "    \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A target PyTorch model to save.\n",
    "        target_dir (str): A directory for saving the model to.\n",
    "        model_name (str): A filename for the saved model. Should include\n",
    "            either \".pth\" or \".pt\" as the file extension.\n",
    "    \"\"\"\n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "\n",
    "    # Create model save path\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    # Save the model state_dict()\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(),\n",
    "                f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ba86c5",
   "metadata": {},
   "source": [
    "## 6. Train evaluate and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c329456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/train.py\n",
    "\"\"\"\n",
    "Trains a PyTorch image classification model using device-agnostic code \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import setup_data, engine, model_builder, utils\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Setup hyperparamaters\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "HIDDEN_UNITS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Setup directories\n",
    "train_dir = \"data/pizza_steak_sushi/train\"\n",
    "test_dir = \"data/pizza_steak_sushi/test\"\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\n",
    "    \"mps\" if torch.mps.is_available else \"cpu\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create transforms\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize(size=(64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create DataLoaders and get class_names\n",
    "    test_dataloader, train_dataloader, class_names = setup_data.create_dataloaders(\n",
    "        train_dir=train_dir,\n",
    "        test_dir=test_dir,\n",
    "        transform=data_transform,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    model = model_builder.TinyVGG(\n",
    "        input_shape=3,\n",
    "        hidden_units=HIDDEN_UNITS,\n",
    "        output_shape=len(class_names)\n",
    "    ).to(device)\n",
    "\n",
    "    # Setup loss and optimizer\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "    )\n",
    "\n",
    "    # Start timer\n",
    "    start_time = timer()\n",
    "\n",
    "    # Start trainig with help from engine.py\n",
    "    engine.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # End timer\n",
    "    end_time = timer()\n",
    "    print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "    # Save the model to file\n",
    "    utils.save_model(\n",
    "        model=model,\n",
    "        target_dir=\"models\",\n",
    "        model_name=\"05_pytorch_going_modular_script_mode.pth\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bbb3429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]/Users/mchojna/Documents/GitHub/pytorch-course/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch: 1 | train_loss: 1.0927 | train_acc: 0.4216 | test_loss: 1.0968 | test_acc: 0.3625\n",
      "  5%|██▏                                         | 1/20 [00:01<00:34,  1.84s/it]Epoch: 2 | train_loss: 1.0781 | train_acc: 0.4159 | test_loss: 1.1124 | test_acc: 0.3000\n",
      " 10%|████▍                                       | 2/20 [00:02<00:22,  1.27s/it]Epoch: 3 | train_loss: 1.0756 | train_acc: 0.4159 | test_loss: 1.1201 | test_acc: 0.3000\n",
      " 15%|██████▌                                     | 3/20 [00:03<00:18,  1.10s/it]Epoch: 4 | train_loss: 1.0720 | train_acc: 0.4216 | test_loss: 1.1102 | test_acc: 0.3625\n",
      " 20%|████████▊                                   | 4/20 [00:04<00:17,  1.09s/it]Epoch: 5 | train_loss: 1.0775 | train_acc: 0.4045 | test_loss: 1.1096 | test_acc: 0.3625\n",
      " 25%|███████████                                 | 5/20 [00:05<00:17,  1.13s/it]Epoch: 6 | train_loss: 1.0575 | train_acc: 0.4045 | test_loss: 1.0938 | test_acc: 0.3625\n",
      " 30%|█████████████▏                              | 6/20 [00:06<00:14,  1.04s/it]Epoch: 7 | train_loss: 1.0409 | train_acc: 0.4216 | test_loss: 1.1000 | test_acc: 0.2958\n",
      " 35%|███████████████▍                            | 7/20 [00:07<00:12,  1.02it/s]Epoch: 8 | train_loss: 1.0110 | train_acc: 0.4295 | test_loss: 1.0854 | test_acc: 0.3917\n",
      " 40%|█████████████████▌                          | 8/20 [00:08<00:11,  1.06it/s]Epoch: 9 | train_loss: 0.9495 | train_acc: 0.5330 | test_loss: 1.0264 | test_acc: 0.4958\n",
      " 45%|███████████████████▊                        | 9/20 [00:09<00:10,  1.09it/s]Epoch: 10 | train_loss: 0.9297 | train_acc: 0.5909 | test_loss: 1.0373 | test_acc: 0.4750\n",
      " 50%|█████████████████████▌                     | 10/20 [00:10<00:08,  1.12it/s]Epoch: 11 | train_loss: 0.8549 | train_acc: 0.6273 | test_loss: 1.0475 | test_acc: 0.5083\n",
      " 55%|███████████████████████▋                   | 11/20 [00:11<00:07,  1.14it/s]Epoch: 12 | train_loss: 0.8183 | train_acc: 0.6205 | test_loss: 1.0689 | test_acc: 0.4292\n",
      " 60%|█████████████████████████▊                 | 12/20 [00:11<00:06,  1.15it/s]Epoch: 13 | train_loss: 0.8294 | train_acc: 0.6477 | test_loss: 1.1643 | test_acc: 0.4333\n",
      " 65%|███████████████████████████▉               | 13/20 [00:12<00:06,  1.16it/s]Epoch: 14 | train_loss: 0.7672 | train_acc: 0.6898 | test_loss: 1.0268 | test_acc: 0.5083\n",
      " 70%|██████████████████████████████             | 14/20 [00:13<00:05,  1.16it/s]Epoch: 15 | train_loss: 0.7480 | train_acc: 0.6955 | test_loss: 1.0556 | test_acc: 0.5000\n",
      " 75%|████████████████████████████████▎          | 15/20 [00:14<00:04,  1.16it/s]Epoch: 16 | train_loss: 0.6700 | train_acc: 0.6830 | test_loss: 1.0669 | test_acc: 0.5083\n",
      " 80%|██████████████████████████████████▍        | 16/20 [00:15<00:03,  1.17it/s]Epoch: 17 | train_loss: 0.6158 | train_acc: 0.7455 | test_loss: 1.0583 | test_acc: 0.5125\n",
      " 85%|████████████████████████████████████▌      | 17/20 [00:16<00:02,  1.17it/s]Epoch: 18 | train_loss: 0.5895 | train_acc: 0.7773 | test_loss: 1.1511 | test_acc: 0.4958\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [00:16<00:01,  1.18it/s]Epoch: 19 | train_loss: 0.4938 | train_acc: 0.7830 | test_loss: 1.1512 | test_acc: 0.4833\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [00:17<00:00,  1.18it/s]Epoch: 20 | train_loss: 0.4207 | train_acc: 0.8568 | test_loss: 1.3949 | test_acc: 0.4292\n",
      "100%|███████████████████████████████████████████| 20/20 [00:18<00:00,  1.07it/s]\n",
      "[INFO] Total training time: 18.668 seconds\n",
      "[INFO] Saving model to: models/05_pytorch_going_modular_script_mode.pth\n"
     ]
    }
   ],
   "source": [
    "!python src/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65994d2a",
   "metadata": {},
   "source": [
    "## 7. Use `argparse` module to be able to send the `train.py` custom hyperparameter values for training procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6382824",
   "metadata": {},
   "source": [
    "Add an argument flag for using a different:\n",
    "- Training/testing directory\n",
    "- Learning rate\n",
    "- Batch size\n",
    "- Number of epochs to train for\n",
    "- Number of hidden units in the TinyVGG model\n",
    "    - Keep the default values for each of the above arguments as what they already are\n",
    "\n",
    "For example, you should be able to run something similar to the following line to train a TinyVGG model with a learning rate of 0.003 and a batch size of 64 for 20 epochs: `python train.py --learning_rate 0.003 batch_size 64 num_epochs 20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1786a7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/pizza_steak_sushi/test'),\n",
       " PosixPath('data/pizza_steak_sushi/train'))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir, train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51583485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/test_arg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/test_arg.py\n",
    "\"\"\"\n",
    "Trains a PyTorch image classification model using device-agnostic code and custom arguments\n",
    "\"\"\"\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    prog=\"ProgramName\",\n",
    "    description=\"What the program does\",\n",
    "    epilog=\"Text at the bottom of help\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"-r\", \"--train_dir\", default=\"data/pizza_steak_sushi/train\")\n",
    "parser.add_argument(\"-s\", \"--test_dir\", default=\"data/pizza_steak_sushi/test\")\n",
    "parser.add_argument(\"-l\", \"--learning_rate\", default=\"0.001\")\n",
    "parser.add_argument(\"-b\", \"--batch_size\", default=\"32\")\n",
    "parser.add_argument(\"-e\", \"--num_epochs\", default=\"8\")\n",
    "parser.add_argument(\"-u\", \"--hidden_units\", default=\"8\")\n",
    "parser.add_argument(\"-n\", \"--model_name\", default=\"model.pth\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "TRAIN_DIR = args.train_dir\n",
    "TEST_DIR = args.test_dir\n",
    "LEARNING_RATE = float(args.learning_rate)\n",
    "BATCH_SIZE = int(args.batch_size)\n",
    "NUM_EPOCHS = int(args.num_epochs)\n",
    "HIDDEN_UNITS = int(args.hidden_units)\n",
    "MODEL_NAME = args.model_name\n",
    "\n",
    "print(f\"Paths:\\n\\tTrain directory: {TRAIN_DIR}\\n\\tTest directoryt: {TEST_DIR}\\n\\tModel directory: models/{MODEL_NAME}\\n\")\n",
    "print(f\"Hyperparameters:\\n\\tLearning rage: {LEARNING_RATE}\\n\\tBatch size: {BATCH_SIZE}\\n\\tNumber of epochs: {NUM_EPOCHS}\\n\\tHidden units: {HIDDEN_UNITS}\\n\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import setup_data, engine, model_builder, utils\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\n",
    "    \"mps\" if torch.mps.is_available else \"cpu\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create transforms\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize(size=(64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create DataLoaders and get class_names\n",
    "    test_dataloader, train_dataloader, class_names = setup_data.create_dataloaders(\n",
    "        train_dir=TRAIN_DIR,\n",
    "        test_dir=TEST_DIR,\n",
    "        transform=data_transform,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    model = model_builder.TinyVGG(\n",
    "        input_shape=3,\n",
    "        hidden_units=HIDDEN_UNITS,\n",
    "        output_shape=len(class_names)\n",
    "    ).to(device)\n",
    "\n",
    "    # Setup loss and optimizer\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "    )\n",
    "\n",
    "    # Start timer\n",
    "    start_time = timer()\n",
    "\n",
    "    # Start trainig with help from engine.py\n",
    "    engine.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # End timer\n",
    "    end_time = timer()\n",
    "    print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "    # Save the model to file\n",
    "    utils.save_model(\n",
    "        model=model,\n",
    "        target_dir=\"models\",\n",
    "        model_name=MODEL_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6302d20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths:\n",
      "\tTrain directory: data/pizza_steak_sushi/train\n",
      "\tTest directoryt: data/pizza_steak_sushi/test\n",
      "\tModel directory: models/model_2.pth\n",
      "\n",
      "Hyperparameters:\n",
      "\tLearning rage: 0.001\n",
      "\tBatch size: 32\n",
      "\tNumber of epochs: 8\n",
      "\tHidden units: 8\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/Users/mchojna/Documents/GitHub/pytorch-course/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch: 1 | train_loss: 1.0972 | train_acc: 0.3608 | test_loss: 1.1002 | test_acc: 0.2930\n",
      " 12%|█████▋                                       | 1/8 [00:01<00:13,  1.90s/it]Epoch: 2 | train_loss: 1.0892 | train_acc: 0.4527 | test_loss: 1.0818 | test_acc: 0.4023\n",
      " 25%|███████████▎                                 | 2/8 [00:02<00:08,  1.35s/it]Epoch: 3 | train_loss: 1.0871 | train_acc: 0.3826 | test_loss: 1.0817 | test_acc: 0.4023\n",
      " 38%|████████████████▉                            | 3/8 [00:03<00:05,  1.10s/it]Epoch: 4 | train_loss: 1.0704 | train_acc: 0.4025 | test_loss: 1.1404 | test_acc: 0.2812\n",
      " 50%|██████████████████████▌                      | 4/8 [00:04<00:03,  1.02it/s]Epoch: 5 | train_loss: 1.0607 | train_acc: 0.4025 | test_loss: 1.1247 | test_acc: 0.2812\n",
      " 62%|████████████████████████████▏                | 5/8 [00:05<00:02,  1.09it/s]Epoch: 6 | train_loss: 1.0256 | train_acc: 0.4025 | test_loss: 1.1447 | test_acc: 0.2812\n",
      " 75%|█████████████████████████████████▊           | 6/8 [00:06<00:01,  1.11it/s]Epoch: 7 | train_loss: 0.9996 | train_acc: 0.4631 | test_loss: 1.0541 | test_acc: 0.3984\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [00:06<00:00,  1.14it/s]Epoch: 8 | train_loss: 0.9918 | train_acc: 0.4451 | test_loss: 1.0815 | test_acc: 0.2891\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:07<00:00,  1.03it/s]\n",
      "[INFO] Total training time: 7.806 seconds\n",
      "[INFO] Saving model to: models/model_2.pth\n"
     ]
    }
   ],
   "source": [
    "!python src/test_arg.py -n model_2.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee208183",
   "metadata": {},
   "source": [
    "## 8. Create a Python script to predict on a target image given a file path with a saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185bcad7",
   "metadata": {},
   "source": [
    "- For example, you should be able to run the command python `predict.py` `some_image.jpeg` and have a trained PyTorch model predict on the image and return its prediction.\n",
    "- You may also have to write code to load in a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececc6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
