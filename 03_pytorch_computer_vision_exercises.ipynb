{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ac748a",
   "metadata": {},
   "source": [
    "## 03. PyTorch Computer Vision Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393883c",
   "metadata": {},
   "source": [
    "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
    "\n",
    "They're a bunch of fun.\n",
    "\n",
    "You're going to get to write plenty of code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb54913",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "1. These exercises are based on notebook 03 of the Learn PyTorch for Deep Learning course: https://www.learnpytorch.io/03_pytorch_computer_vision/\n",
    "\n",
    "2. See a live walkthrough of the solutions (errors and all) on YouTube: https://youtu.be/_PibmqpEyhA\n",
    "\n",
    "    - **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
    "\n",
    "3. See other solutions on the course GitHub: https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad41bdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1\n"
     ]
    }
   ],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\n",
    "    \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9da156",
   "metadata": {},
   "source": [
    "## 5. Load the torchvision.datasets.MNIST() train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee8ea88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "990243a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c16f6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d589f92",
   "metadata": {},
   "source": [
    "## 6. Visualize at least 5 different samples of the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07412a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(train_data.class_to_idx.keys())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85455bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAACiCAYAAAC6cvAnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIglJREFUeJzt3Ql0FdUZwPGRnaxAgAQie2QRVKBYEBHqhqWACLaKpRUXLG2V2sVSUbtQAUWKpdBjrV3UalupsoktRVpcKBQsVhAqqyVhKVkIkJAQEpbX843n5bz55mbuCwnJS/L/nYNyJ7ORue/OfTPfd+9FoVAo5AAAAACoUKOKfwQAAABA0GkGAAAALOg0AwAAABZ0mgEAAAALOs0AAACABZ1mAAAAwIJOMwAAAGBBpxkAAACwoNMMAAAAWNBpBmpBZmamc9FFFzk/+clPavtUAABAfeg0S8cimj9vv/12bZ8qYsy2bducz3/+806XLl2cFi1aOOnp6c6NN97oLFq0qLZPDXUE7Q+qijqE2vLxxx87U6dOdbp37+7eA5OSkpyrr77a+dnPfuaUlJRckGP+4Q9/cBYsWODUV02cGPfSSy95yr/73e+cNWvW+Jb36dOnhs8MsWzDhg3Otdde63Tu3Nm57777nLS0NOfAgQPOxo0b3QZj2rRptX2KqANof1BV1CHUhj//+c/OF77wBad58+bOnXfe6fTr188pKytz/vGPfzjf/e53nf/85z/Oc889d0E6zdu3b3e++c1vOvVRzHeav/SlL3nK0umRBkcv106ePOnExcU5dU1xcbETHx9f26dR582ePdtJTk52/vWvfzmtWrXy/Cw3N9dpCOrqZyCW0P6gqqhDqGn79u1zJk6c6L5lXbt2rdOhQ4fyn91///3O3r173U416mF4RjQ+85nPuN+i3n//fWf48OFuQ/PII4+Ud5DuvfdeJzU11X09ccUVVzgvvviiZ3t5LWZ6PRaOO33hhRfKl2VnZzt33323c/HFF7vf4KQyjhs3zl030qpVq5xrrrnGbTwSExOd0aNHu9/sIt11111OQkKC+wrlc5/7nLvepEmTLsBvqOGR32nfvn19HWbRvn378r/L9X3ggQec5cuXu3VIrqls99e//tW33aFDh5x77rnHrUvh9X7729961pFv8j/4wQ+cT33qU26nXa6/1IO33nrLes6hUMj5yle+4jRr1sxZunRp+fKXX37Z3V/Lli2dNm3auI2hPDWP9jOAC4v2B1VFHUJ1euqpp5yioiLnN7/5jafDHJaRkeE8+OCD7t/PnDnjPP74406PHj3c+tC1a1e37pWWlnq2WbFihVsHOnbs6K4n68t2Z8+e9dRj6YxnZWWVhx3J/uqTmH/SHK38/Hxn1KhRbodCvsFLAyMxO3IR5VuVdIy6devmvPrqq+4H/fjx4+WVpjJuvfVWt+GQ1/tSGaRBk6cG+/fvL68c8tpt8uTJzk033eTMnTvXfWLwi1/8whk2bJjzwQcfeCqRVFhZT34mSWF18clCLJJv2P/85z/d10RyMwoir6ukk/r1r3/dbfQXLlzoXme5pikpKe46OTk5zpAhQ8o72e3atXNvKnIzKywsLH8VJX//9a9/7dxxxx1uWMiJEyfchkuu8Xvvvef079/feA7S8EiHfPHixc6yZcvcxin8xPz73/++c9tttzlTpkxx8vLy3JhsubFKXYr8UmD6DKBm0P6gqqhDqC4rV65045iHDh1qXVfuK/IlTPJ/vvOd7zibNm1ynnjiCWfHjh3uvShMvnglJCQ43/72t93/yxNseUAk97x58+a56zz66KNOQUGBc/DgQeenP/2pu0zWrVdCdcz9998f0qc9YsQId9mzzz7rWb5gwQJ3+csvv1y+rKysLHTVVVeFEhISQoWFhe6yt956y11P/h9p37597vLnn3/eLR87dswtz5s3r8LzO3HiRKhVq1ah++67z7M8Ozs7lJyc7Fk+efJkd38PP/zwef0uULE333wz1LhxY/ePXO/p06eHVq9e7V7/SPL7b9asWWjv3r3ly7Zu3eouX7RoUfmye++9N9ShQ4fQkSNHPNtPnDjRva4nT550y2fOnAmVlpZ61pF6k5qaGrrnnnt8dUvq0unTp0O33357qGXLlu45hmVmZrrnP3v2bM/+tm3bFmrSpIlneUWfAVQv2h9UFXUIF1JBQYF7TcaNG2ddd8uWLe66U6ZM8Sx/6KGH3OVr164tXxa+x0WaOnVqKC4uLnTq1KnyZaNHjw516dIlVF/Vi/AMIa8L5JVTpL/85S9uApg89Qtr2rSp841vfMN9dfHOO+9U6hjyelxencsrsGPHjhnXkW/s8gRAjnnkyJHyP40bN3YGDx5sfE3/ta99rVLnATsZJUOeNN98883O1q1b3ddV8jRERtB4/fXXPevecMMN7qumsMsvv9zNMv7vf//rlqVvvWTJEmfs2LHu3yOvq+xTvln/+9//dteV6yx1RJw7d845evSo+yRm0KBB5evocA5J1njjjTfc+jpy5Mjyn8nTb9mHPGWOPKbU6UsuucRXl0yfAdQM2h9UFXUI1UGe/Ap5a2oj9UvI0+NI8sRZRMY9S90JkzeoUickfEfeQuzcudNpKOpNeIZ0hsKdlTCJq5HORaNGjYxZyvLzyjZq8qpKKpS8OpPX9WPGjHEzU6VhE3v27HH/f9111xn3IZ2xSE2aNHFjy1D9rrzySrfjKR1T6TjLqyZ5ZSSvobZs2eJceuml7noywobWunXr8puKhETITUQyjSvKNo5MLpRXXfPnz3cbktOnT5cvl1ermrwGk5ufhHrIa9hIUpekky512ERunrbPAGoG7Q+qijqE6hC+PtKxtZH6I3VLYpwjSV2Q0L/I+iUhPY899pgblhHumIfJg6OGot50miO/BVWWxKmaRAa4h0nsqjxxlMSx1atXu/Gm0vGRijRgwAD3yWA4JizcCOkGRjdiukFE9ZIbkXSg5U/Pnj3dpzkSF/jDH/7Q/bk8QTH5JHrjkyfGQuIMJc7PRJ5Oh5P2JN7wlltucYf1kaRD2b/UEUmW0eRJtSQdypNw6TRLok+YHFfqpnSoTeeoY8Wq8hlA1dD+oKqoQ6iuTrMk60k+T1XrT5g8NBoxYoS77x//+Mfum1m5V8nb0+9973vldaYhqDed5oqSwT788EP3gkZ+qMOvEuTn4aeK4YoRqaJv8VJh5Ju6/JFv5ZLcJU8WpcMUfs0vnSV57Y/YImES4vDhw1FvI0l/8qpLbkC2a/raa6+5CRjyhDuyIQp30DV50vPVr37VfdojYRryNDx8U5K6JB13eUItnX3ULbQ/qCrqEM6H3E/kraiEKF511VUVrif1R+qW1IHIccIl8V3qUrh+STiPJKouXbrUTUKPHNqush3wuq5efz2UIXBkeB0ZkSBM4ktl9AF5SiffnIRUDHmS9+6773q2f+aZZzxlid05deqUZ5k0MNKhCg/PIk8O5dvYnDlzPK/mw+RVPy48ibsLPyk2xXD16tUr6n1J3ZCMc4lrNn17j7ym4SfCkceWbGRpvCoiN6ZXXnnFfeL85S9/ufxb+4QJE9z9zZw50/dvkbI0YohdtD+oKuoQzsf06dPdoQJlZAzpAGvy1lMm+ZL6JfQMfk8//bT7//AoTqb7WllZma9+CTlufQ7XqNdPmmXM21/+8pfu63IZ/1KGyZEngevXr3crSThQXsbTlad80hDJtyRpRCQxS0+CsXv3buf66693E7MkHlaeCMqTQamUMkyQkMZGhuaRzs/AgQPd5fKkUobzkaB6mcLy5z//ea38PhoSGU5JbhDjx493evfu7X7AZZZAuflIPahswtyTTz7pdsQlEUaGkpPrL0l+8nrqb3/7m/v38Dd8+TYux5UGR76JP/vss+76ErtcEQnneP75593YQqlDUm+lHs6aNcuZMWOGO4aqrCN1VvYp9U7q90MPPVTl3xUuDNofVBV1COdDrr/MzHf77be7T5AjZwSU+2B42EIZslBCDuWpdDgEQ4ZGlbwcud/IrLpChq6TtxmTJ092k1Cljkn4junBlMwpIPdZSS6UkEj5cifhQPVGqJ4M19O3b1/j+jk5OaG777471LZtW3doscsuu6x8+J1IeXl5oVtvvdUdPqV169buUCrbt2/3DNcjw43J8Xv37h2Kj493h98ZPHhw6E9/+pNvfzL0z0033eSu06JFi1CPHj1Cd911V2jz5s2e4XpkP6h+q1atcod4k2slQzPJtc/IyAhNmzbNrRNhcn3lmmoyZI5cn0iynazbqVOnUNOmTUNpaWmh66+/PvTcc8+Vr3Pu3LnQnDlz3O2bN28eGjBgQOiNN95w9xU5DE/kkHORnnnmGXe5DPkTtmTJktCwYcPcuiJ/5N8k57Fr166oPgOoPrQ/qCrqEGrK7t273SECu3bt6tadxMTE0NVXX+0OpxoeJk6GPJ05c2aoW7du7n1N7m8zZszwDCMn1q9fHxoyZIg7NGrHjh3Lh3HVQx0WFRWFvvjFL7rDFsrP6tvwcxfJf2q74w4AAADEsnod0wwAAABUBzrNAAAAgAWdZgAAAMCCTjMAAABgQacZAAAAsKDTDAAAAFjQaQYAAACqa0bAujSf+Pz5833L9FSSenjq8NTFFZVNGjXyfudo1qyZb50nnnjCqSsu5JDddan+4Pxc6CHf61Id6t+/v2+ZzKgVqVWrVtb2w/Y70NPVHjhwwLeNaer3WEUbZK4b4pFHHvGUZWbQSDK7X1DZpHnz5p5yRkaG9d756KOPOrGK+hO9lJQUT1lm74u0bt063zbdunXzTZkdadOmTU5dFk394UkzAAAAYEGnGQAAALCIehrtWH41MXbsWE/59ddf962Tl5fnKSckJHjKZ8+etYZn6N/BqVOnPOV27dr5tpkwYYKnvGzZMidW8WoLVdGQwzMWL17sKY8fP963TlFRUeDr88TERE+5sLDQGhJ25swZT7lx48a+bXr27OkpZ2dnO7GKNugTw4YN8y1bsmRJYGhOhw4drOEZur7k5+dbQ4T0NUlPT3diVUOtP/ozPmXKFN86uj4kJycHhl5cfPHF1vqTo0J3SkpKfNtMnz69zoSLEZ4BAAAAVAM6zQAAAIAFnWYAAADAgk4zAAAAUF3jNMeyjh07esqHDx/2rbNjxw5POS4uLnCf0YzTrIPijx8/7lunbdu21v0AqNt0ks3Ro0d96+j2oWXLloHbmJL6dLukE1d0MqFpLF7EPlNS+cmTJz3lY8eOBSYGmhIBdcK7rmOmOmdKCMOFo6+BvmaiV69envLMmTOtn3ldP/RABrq+JCUlWRORS0tLPeW0tDTfNkuXLvWUR44c6SlnZmb6tmnatKmnfPr0aSdW8KQZAAAAsKDTDAAAAFjQaQYAAAAaQkxznz59AmN3TLE4OkZGD1xuiiPS29jKonPnzoHnDqDui4+PD2xvTOuY4kdtkynoGGbdTpniWLt06eIpZ2VlBR4Xte/aa6+1Xntdf3SdM9UvU/0IytMxxdpnZGR4ynv37g3cJyrH1PfQbr755sC8ruLiYt82w4cPD6xPemKbaPK6+vXrZ83r0vXj6aefDpwALpr+2YWeSCsIT5oBAAAACzrNAAAAgAWdZgAAAKAhxDSnpKR4ymVlZb51dEyMjvfS4wKWlJRYj6tjyEzHtY0HDaDu07GiegzmaNuUyh7HFDut0QbVPVdccYVvmb6/6JhTXTdMsbGmOHnbz3v06OEpU59qnx5D+e9//7unnJOT49tm6NChgXHBun3SfSLT+M8n1djhu3fvttapEydOOHUZT5oBAAAACzrNAAAAgAWdZgAAAMCCTjMAAADQEBIBdcKDaVBuvY5tYPhoJhbQZVNSjmmQcQD1SzRJNDZ68hNTO1ZaWho4GYVpG9uEFog96enp1jpmmxzHxHbfi2Zijf3791f6uKheH3/8ceCkImlpab5tli1b5ilPnjzZUz5w4ICnnJub69tHz549PeU333zTU16+fLlvm4EDB3rKa9eudSqrNicz0XjSDAAAAFjQaQYAAAAs6DQDAAAAFvUi2K2goMBTbtasmW8dHeunY7d0DLNtEHgTPfC3OHz4cKX3A6BuxxiOGTPGuk1iYmJgW2FqT1q1ahU4UYApppk2qO4x3cP0RBK2yU1M+9D3NVN9sSFPp2YNGTLEt2zOnDme8vz58wMnOxGbN28OrB8TJ04M7FeZ4upHjRpljWn+/e9/7ylv2rTJU96+fbtvm8suu8yJVTxpBgAAACzoNAMAAAAWdJoBAACAhhDTvG/fPmssoG2cPx0PZhoDUy/TY6a2aNHCt01mZmbgcQHUfdu2bQscN1WcPn3aU05OTvaU582b5ylfeumlvn2MHj068Dz0uM2m9hGxLy4uzrfs2LFjgWOBJyUlecrt27f37UOPxWvL7TGJZixnVJ9Zs2b5lrVu3dpTnjRpkrUvouOEhw4d6inn5eVZ+0DFKp5d14UZM2b4ttH1Misry1Pu2LGjdZzyQ4cOObGCJ80AAACABZ1mAAAAwIJOMwAAAGBBpxkAAABoCImAR44cCUyQMA3irtfR+9ADyZsmFjh16pT1uHv27Ak8d9S8Ro0aVXmAfyDS1q1brXXKlmSltzEl9el96LpcWFjo2+bo0aOBx0XsMSWz62uv10lNTbVOcKGTS/V9znTcyibVo3q1adPGt0z3V9q1a+cp/+hHP/JtoxP7dOJfWVmZdXKcFirBUJ+H6Vz1BEw6edB0nBtvvNFTfuGFF5xYwZNmAAAAwIJOMwAAAGBBpxkAAABoCDHNegIRU2yxnlhAr5Ofn289jo4f1DFC+hhi79691v2iZunYUT2xjSmW1Obyyy/3lH/1q1/51tH1pX///p7yqlWrfNuMHTvWqW76uKZB6fXg+RMmTPBtU1RUVO3nVldt3rw5MI7PVM9KSkoC96lzJkx1V8cDEp9fP+h7jYm+3+iY1NmzZ/u2WbFihbWOabpOEdNcswYMGOBbdvDgwcBtTJOB6Jh4XV90vLIpB+MitUzXDVNOhW73dJtlmiznlltu8ZSJaQYAAADqEDrNAAAAgAWdZgAAAKAhxDS/99571pgrHa+jY5p1fKZe3xSTqveRm5tbibNGZUUTY6WvfTTxd9HEMOsYqzlz5njK8fHx1vFOs7KyPOVNmzYFjgMuVq5c6SmXlpZaY1g7d+7sKXfq1MlTjouL821z7NgxTzklJcVTTk9P922za9cu3zJUHJOqY/t03YxmnGZNxwdu3LixkmeKWKTjTU1tnb72uj7pXB/TeL7Z2dnW+15xcXGUZ43qkJGRYV1Htw3JycmeckFBgW8bXV90ToXuz5iu+znVRtnipE3r6PuPaU6MK6+80olVPGkGAAAALOg0AwAAABZ0mgEAAAALOs0AAABAQ0gE1MHnpgHbdTC6TsrJycmxJmXpZCgdOK+TKlC5RCnbxAympL7qGGj/zjvv9JQXLFjgW0cnVuiJBXRSxeHDh3370OvohIjjx4/7tunTp4+n3L59+8DzMP1OdF03HUcvS0xM9JQ//elP+7YhEbBi77zzjm/ZmDFjAuu7/kyYBv3X7ZjexjRBDuoe08Q3+nOtk/Z27NhhvR+ZkqmDksUqmigDF45O3I4mEVC3A6brrNsT2wQ6pvvxOcs92jSxnO04pnNNS0tzYhVPmgEAAAALOs0AAACABZ1mAAAAoCHENNsmaohmYpITJ05UenITXdaTV6Bittio89WyZUtP+bOf/axvnT/+8Y+ecmFhoad85MgR3zZ68ht97XW8oSm2S8cpJiQkeMpdunTxbbN79+7A+EJTPdUx/jqWLSkpybeNjuHXcWZz5871bfPSSy/5luETr732mm/ZuHHjKvUZME0UoOMD9TpMblJ/72G6TdGf/Xfffde637y8vMAYZp3/ILZt22bdL6pP7969revotkO38aaJkfQ9S19r3Zbo9aM5j0aG+GXbpDym+H29jZ6wa//+/U5t4UkzAAAAYEGnGQAAALCg0wwAAAA0xJhm0xi5pnGXg2KATOP/lpaWBsb81GacTV1zww03+JZNmTLFU05NTQ2MVxatW7cOjNMyxXYdPHgwcIxiU/3R8YRt27YNPDdT/dHr6Dh6PTay6NatW2Dc2cmTJ33btGnTJjCGzBR3psc21zGVenxoBFuzZo11rG99nfR1MdUhHeun69CWLVvO63wRW0z5MT179gysH9HME6DzNXR7aWoboomVRvXR9z0TfZ30eP26ryKaN28eeE/T9cmUc3HWMHa87X6r2yxTDLNN3759PWVimgEAAIAYRqcZAAAAsKDTDAAAADTEmOb//e9/vmXt2rULjLOxjXtoiiPSZcZprtjo0aM95YULF/rW0THiOl7XFOOpY3x1fHJOTo5vG32tU1JSPOXu3bv7ttF1avny5YHbmOKTdQyZjhPWY6iaYvF1XLSux6a4suLiYutYrDoGTp+/aWxnVMwUa67jxHVcvL4u8fHx1s+IjpNG/aBzDKKJP05OTrbuV48Nr+upjnsVBw4csO4X1UePv63nCDC18bou6DwW031P3zt026LjpE3LQuqebDquPo7exnRfP58475rCk2YAAADAgk4zAAAAYEGnGQAAALCg0wwAAAA0xERA0+QU/fv3D5wUQCf+mQYH18H2OrDelICITzzwwAPWRKn8/HzrZCaaTiLQA6fryU9MCVaFhYXWSQJ69+4dmFy3c+fOwPpmSujQSTmmBD1bgqpO3jD9e/Q6pmQNnaSokXBWdbrO6Ouir7Vpogm9jSlhDHXfjh07fMsGDhwYmGC1a9cu637T0tI85X379lm30e0JLiydIG4alEDfK2wTl5i2sSUGmvZxkVpHH1cn5pvut/rfY7v3mPZRm3jSDAAAAFjQaQYAAAAs6DQDAAAADTGmOTMzs9ITk+j4nmhimnVsjimeB+Z4b1PMb1xcXOAA7qb4TdMA7Laf62ur47JMMXwfffSRp9yjR4/A4+j4VdNkFvo89L/XtE40Max6P7qe6t+zKTZcT6qyf/9+63FRueuiY/l0vTNNkGOLS0T9oHNuTPVFx5dec801nvIrr7xS6X2YJpqgjtWsaCYZ0dckmglCTLHRQW2LKcfmrCWnxpSHoZdFcxzb/ag28aQZAAAAsKDTDAAAAFjQaQYAAAAaYkxzVlZWpeNqNFN8qd6Hjrsh9qtiU6dO9ZQXLlxojflNTU0NHGNUtGnTJnCMS9N11HRdSE9P961z/PjxwLjgkSNHesq5ubm+fegY1Wjqi44Zs9VbEz0uczSx0zk5OZ7ynj17fNvoeEhUTTQxzbbcDNQPps+WvtZ6TPpLLrnEU+7UqZP1OPpzb2qTqGM1S8edm37/eh2dT2XKydLzHuh96P6MaQ6ARupc9HH1/dg0J4Mtn8wUO63v67WJTwMAAABgQacZAAAAsKDTDAAAAFjQaQYAAAAaYiKgKQheJ1bYJgnQweumwPhoBhSHOfls2rRpvnUGDRoUmKjQvXt33zY6OVAnE5oSE/RA6fq6JiUlOTYHDx70lN9++21rIo+eREXXOVOCnq6n+lz178i0X50wZJo4QU8+U1RUFDiZi2jdurVvGSpmSqwJutYFBQXWfZquP+o+20QUpnV0/enXr591H9EkZZnup7hwdFusE7lN9xd9bzG1C7r9sd1/TPejppYkRdPkW7qexsfHVzqhPJaSUWPnTAAAAIAYRacZAAAAsKDTDAAAADTEmGZTPJiOm9ExMjreR8d0RhPTfD4TTzRUpmu0adOmwG12797tW6ZjuZKTkz3lhIQE6zbRxKbr+C8d23X69OnAQd9N8V56nWgmFtBlU7yb3o+eNKO4uNi3Tc+ePQP3u2jRIt82qBw9uYCOGezcubP12up61qJFi2o9R8QGUy6Gvr/oWGNdv3Qug4m+L5raQlN+Dy4cPZGWKZ5XtwO23BdTe6O30W1JNNc9pOqL6b5nmxTOdK66XrZr186JFTxpBgAAACzoNAMAAAAWdJoBAAAAi3oZhGsa90/H1djGOczPz7ceR++TmOYLKzc317rOgQMHauRc6pu8vLzaPoV6T8eY6jaoffv2gT83YQzd+mndunW+ZVOmTAmMa9Xjph85csR6HFvOhKBtqFk698V0TXQcsK4Lpth0W3uitzHlS5xRcdE670KfhynOOZo2S/e/ohm3vKbwpBkAAACwoNMMAAAAWNBpBgAAACzoNAMAAAAW9TJzzRQ4bwuC14H10QzSbZvwAgAqSqjSbU40iVu6jSFJq35KSkryLdPJULZk9h07dliPE00CmU4wPHTokHW/OH/6OhYUFPjW0ddeJ+iZJgyJZhKvoH2a9luqkvpM/SydLKgTDE0TkOn+l+nzUFt40gwAAABY0GkGAAAALOg0AwAAAA0xptkUV1PZmGbTYNrRTDYAACbZ2dmBPy8qKgrMmTDJycmp8nkh9kycONEa56nvWXryp2gmhNDxs6Y4VibtqlkfffSRp5yamupb5/jx44FtRzR0/dDXOZpJVRqpdUy5YDpuXk/e8sEHH/i2GTFihKe8YcMGJ1bwpBkAAACwoNMMAAAAWNBpBgAAACzqZbCSHjuwovicSPHx8dbYLh3TrPep9wGgYbCN4S4OHz4cuA/d5ujYPxMd22ii263KjteKmqfHRjbVMT2+7f79+yt9HB3TrMfUFdSXmrVs2bJK51KtW7fOU+7Vq5dvnZKSEk+5U6dOgbHHpjjpc6pd0+cWFxdnPa7uJ40fP963TXFxsROreNIMAAAAWNBpBgAAACzoNAMAAAAWdJoBAACAhpgIaEqg0QHsuqwTIqJJJrQlZgBAWFZWVuDP9cQA0UxYkJeXV+XzQux5//33fcsyMjICE/RMyeva6tWrPeVu3bp5ygUFBZVOYEXt03VD92dMfZrFixd7yunp6Z7ykCFDrO3NaZU8qMuiadOmnnKrVq085euuu863zcqVK51YxZNmAAAAwIJOMwAAAGBBpxkAAACwaDAxzTr+WMd/6UHdbZOhiLNnz573OQKoP6KZgCA7Ozvw5x07dvSUU1JSrPvctWuXdR3dltFuxT5TfszOnTs95cTERE950KBB1v2++uqrnvKDDz7oKa9fv963TW5urnW/qF1jx471lJ966infOjpGWcez60lHMjMzffs4q9oO3W9KTk72baNj7x9++OE6E79swpNmAAAAwIJOMwAAAGBBpxkAAABoiDHNxcXFvmV6XGYdL9ilSxdPuWXLlr59tGjRwlOOi4vzlDt16nRe5wug/jt58mTgzxs3bhzYvpiUlJRU+bxQ+x577DFPuXfv3r519Bi4TZp4b98ffvih9Th6v/qeNmDAAN827du395SJcY49mzdvto59/K1vfctTnjVrlqd84sQJT3nFihXW+jN8+HBPec2aNb5tJk2aVK/GludJMwAAAGBBpxkAAACwoNMMAAAAWNBpBgAAACwuCumRp6sweH8sy8jI8JTvuOMOT3nu3LmecllZmW8fAwcODCy/+OKL1uSNWBZlVTgvdb3+oHbrT6zXIT2BiE48Fl27dvWUN2zY4CnfdtttnnJRUZFvH3oigFGjRnnK27dvP69zixUNtQ1at26dNRE9JyfHUx49enSljzN48ODA+2B+fr5vm8cff9ypKxpq/dHndj6/hyeffNJT3rp1q2+dkNqvngBl48aN1uPohOdYmmwpmt8bT5oBAAAACzrNAAAAgAWdZgAAAKC6YpoBAACAhoonzQAAAIAFnWYAAADAgk4zAAAAYEGnGQAAALCg0wwAAABY0GkGAAAALOg0AwAAABZ0mgEAAAALOs0AAACAE+z/EeI2IZoBJ+kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 900x900 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 1, 5\n",
    "\n",
    "for i in range(1, 6):\n",
    "    idx = random.choice(range(len(train_data)))\n",
    "    \n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(train_data.data[idx], cmap=\"gray\")\n",
    "    plt.title(labels[train_data.targets[idx]])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c4103d",
   "metadata": {},
   "source": [
    "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2707829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "508b98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac74eca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 313)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec95740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10016)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader) * BATCH_SIZE, len(test_dataloader) * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9382531",
   "metadata": {},
   "source": [
    "## 8. Recreate `model_2` used in notebook 03 (the same model from the CNN Explainer website, also known as TinyVGG) capable of fitting on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949d025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FMNISTModelExercise(\n",
       "   (conv_block_1): Sequential(\n",
       "     (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (2): ReLU()\n",
       "     (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (5): ReLU()\n",
       "     (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (conv_block_2): Sequential(\n",
       "     (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (2): ReLU()\n",
       "     (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (5): ReLU()\n",
       "     (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (classifier): Sequential(\n",
       "     (0): Flatten(start_dim=1, end_dim=-1)\n",
       "     (1): Linear(in_features=3136, out_features=10, bias=True)\n",
       "   )\n",
       " ),\n",
       " FMNISTModelExercise(\n",
       "   (conv_block_1): Sequential(\n",
       "     (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (2): ReLU()\n",
       "     (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (5): ReLU()\n",
       "     (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (conv_block_2): Sequential(\n",
       "     (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (2): ReLU()\n",
       "     (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (5): ReLU()\n",
       "     (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (classifier): Sequential(\n",
       "     (0): Flatten(start_dim=1, end_dim=-1)\n",
       "     (1): Linear(in_features=3136, out_features=10, bias=True)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class FMNISTModelExercise(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features: int, out_features: int, hidden_units: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_features,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=1,\n",
    "                padding=1,    \n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(2, 2),\n",
    "                stride=2,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=1,\n",
    "                padding=1,    \n",
    "            ),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=1,\n",
    "                padding=1,    \n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(2, 2),\n",
    "                stride=2,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=hidden_units * 7 * 7,\n",
    "                out_features=out_features,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z1 = self.conv_block_1(x)\n",
    "        z2 = self.conv_block_2(z1)\n",
    "        z3 = self.classifier(z2)\n",
    "        \n",
    "        return z3\n",
    "\n",
    "model_cpu = FMNISTModelExercise(\n",
    "    in_features = 1,\n",
    "    out_features=len(labels),\n",
    "    hidden_units=64,\n",
    ").to(\"cpu\")\n",
    "\n",
    "model_mps = FMNISTModelExercise(\n",
    "    in_features = 1,\n",
    "    out_features=len(labels),\n",
    "    hidden_units=64,\n",
    ").to(\"mps\")\n",
    "\n",
    "model_cpu, model_mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b01a9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates when two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e75077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_cpu = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_cpu = torch.optim.SGD(\n",
    "    params=model_cpu.parameters(),\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40003212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function __main__.accuracy_fn(y_true, y_pred)>,\n",
       " CrossEntropyLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fn, loss_fn_cpu, optimizer_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b0b17d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_mps = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_mps = torch.optim.Adam(\n",
    "    params=model_cpu.parameters(),\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4aad4214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function __main__.accuracy_fn(y_true, y_pred)>,\n",
       " CrossEntropyLoss(),\n",
       " Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     decoupled_weight_decay: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fn, loss_fn_mps, optimizer_mps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834553c3",
   "metadata": {},
   "source": [
    "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64eaab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: nn.Module,\n",
    "    accuracy_fn,\n",
    "    device=\"cpu\"\n",
    ") -> None:\n",
    "    \"\"\"Performs training with model\"\"\"\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Put model on target device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for X_train, y_train in data_loader:\n",
    "        # Put data on target device\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        \n",
    "        # Turn on training mode\n",
    "        model.train()\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X_train)\n",
    "        \n",
    "        # 2.1. Calculate loss\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        train_loss += loss\n",
    "        \n",
    "        # 2.2. Calculate acc\n",
    "        acc = accuracy_fn(\n",
    "            y_true=y_train, \n",
    "            y_pred=y_pred.argmax(dim=1)\n",
    "        )\n",
    "        train_acc += acc\n",
    "        \n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Loss backwards\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()        \n",
    "    \n",
    "    # Divide total train loss and acc by length of train dataloader\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    \n",
    "    # Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.4} | Train acc: {train_acc:.4}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "    model: nn.Module,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    accuracy_fn,\n",
    "    device=\"cpu\"\n",
    ") -> None:\n",
    "    \"\"\"Performs testing with model\"\"\"\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Put model on target device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Turn on evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in data_loader:\n",
    "            # Put data on target device\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "        \n",
    "            # 1. Forward pass\n",
    "            y_pred = model(X_test)\n",
    "            \n",
    "            # 2.1 Calculate loss\n",
    "            test_loss += loss_fn(y_pred, y_test)\n",
    "            \n",
    "            # 2.2 Calculate accuracy\n",
    "            test_acc += accuracy_fn(\n",
    "                y_true=y_test,\n",
    "                y_pred=y_pred.argmax(dim=1) # go from logits -> prediction labels\n",
    "            )\n",
    "\n",
    "        # Divide total train loss and acc by length of train dataloader\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "    \n",
    "    # Print out what's happening\n",
    "    print(f\"\\nTest loss: {test_loss:.4f} | Test acc: {test_acc:.4f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385c124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a0ddafc886437e8e42295f24ba6d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\n",
      "\n",
      "Train loss: 2.303 | Train acc: 9.828%\n",
      "\n",
      "\n",
      "Test loss: 2.3030 | Tests acc: 10.0000%\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "\n",
      "Train loss: 2.303 | Train acc: 10.0%\n",
      "\n",
      "\n",
      "Test loss: 2.3035 | Tests acc: 10.0000%\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "\n",
      "Train loss: 2.303 | Train acc: 9.965%\n",
      "\n",
      "\n",
      "Test loss: 2.3032 | Tests acc: 10.0000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "start_time_cpu = timer()\n",
    "\n",
    "# Set epochs\n",
    "epochs = 3\n",
    "\n",
    "# Create an optimiziation and evaluation loop using train_step() and test_step()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n\")\n",
    "    \n",
    "    train_step(\n",
    "        model=model_cpu,\n",
    "        data_loader=train_dataloader,\n",
    "        loss_fn=loss_fn_cpu,\n",
    "        optimizer=optimizer_cpu,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    "    \n",
    "    test_step(\n",
    "        model=model_cpu,\n",
    "        data_loader=test_dataloader,\n",
    "        loss_fn=loss_fn_cpu,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    "\n",
    "# Measure time\n",
    "end_time_cpu = timer()\n",
    "\n",
    "# Calculate time\n",
    "time_cpu = end_time_cpu - start_time_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e391017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32576337516741079eaeb27e9cfbad0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\n",
      "\n",
      "Train loss: 2.303 | Train acc: 10.0%\n",
      "\n",
      "\n",
      "Test loss: 2.3027 | Tests acc: 10.0140%\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "\n",
      "Train loss: 2.303 | Train acc: 10.0%\n",
      "\n",
      "\n",
      "Test loss: 2.3027 | Tests acc: 10.0140%\n",
      "\n",
      "Epoch: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "start_time_mps = timer()\n",
    "\n",
    "# Set epochs\n",
    "epochs = 3\n",
    "\n",
    "# Create an optimiziation and evaluation loop using train_step() and test_step()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n\")\n",
    "    \n",
    "    train_step(\n",
    "        model=model_mps,\n",
    "        data_loader=train_dataloader,\n",
    "        loss_fn=loss_fn_mps,\n",
    "        optimizer=optimizer_mps,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=\"mps\",\n",
    "    )\n",
    "    \n",
    "    test_step(\n",
    "        model=model_mps,\n",
    "        data_loader=test_dataloader,\n",
    "        loss_fn=loss_fn_mps,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=\"mps\",\n",
    "    )\n",
    "\n",
    "# Measure time\n",
    "end_time_mps = timer()\n",
    "\n",
    "# Calculate time\n",
    "time_cpu = end_time_mps - start_time_mps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92bf128",
   "metadata": {},
   "source": [
    "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6194b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74bc7279",
   "metadata": {},
   "source": [
    "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf05741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37488ddf",
   "metadata": {},
   "source": [
    "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059d6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68ac453f",
   "metadata": {},
   "source": [
    "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test `torchvision.datasets.FashionMNIST` dataset.\n",
    "\n",
    "- Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
    "- After visualing these predictions do you think it's more of a modelling error or a data error?\n",
    "- As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5cb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
